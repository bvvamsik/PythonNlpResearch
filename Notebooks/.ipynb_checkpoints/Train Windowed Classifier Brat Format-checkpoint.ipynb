{
 "metadata": {
  "name": "",
  "signature": "sha256:026f475e18fb37cc86a8982e2c12af9295d51a0fdffa85110896bfda6bb96eff"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train a Window Based Classier on the Coral Bleaching Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup:\n",
      "------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Imports \"\"\"\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "from gensim import matutils\n",
      "from numpy import random\n",
      "\n",
      "from Metrics import rpf1a\n",
      "from Rpfa import rpfa, weighted_mean_rpfa\n",
      "from BrattEssay import load_bratt_essays\n",
      "from WindowSplitter import split_into_windows\n",
      "\n",
      "from IdGenerator import IdGenerator\n",
      "from IterableFP import flatten\n",
      "\n",
      "from nltk import PorterStemmer\n",
      "from stanford_parser import parser\n",
      "\n",
      "\"\"\" TODO \n",
      "    Try dependency parse features from this python dependency parser: https://github.com/syllog1sm/redshift\n",
      "\"\"\"\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Settings \"\"\"\n",
      "\"\"\" Start Script \"\"\"\n",
      "WINDOW_SIZE = 7 #7 is best\n",
      "MID_IX = int(round(WINDOW_SIZE / 2.0) - 1)\n",
      "\n",
      "MIN_SENTENCE_FREQ = 2\n",
      "PCT_VALIDATION  = 0.2\n",
      "MIN_FEAT_FREQ = 5     #15 best so far\n",
      "PCT_VALIDATION = 0.25\n",
      "\n",
      "SENTENCE_START = \"<START>\"\n",
      "SENTENCE_END   = \"<END>\"\n",
      "STEM = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Essays\n",
      "---------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\" Load Essays \"\"\"\n",
      "essays = load_bratt_essays(\"/Users/simon.hughes/Dropbox/Phd/Data/CoralBleaching/BrattData/Merged/\")\n",
      "\n",
      "all_codes = set()\n",
      "all_words = []\n",
      "\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        for w, tags in sentence:\n",
      "            all_words.append(w)\n",
      "            all_codes.update(tags)\n",
      "                \n",
      "# Correct miss-spellings\n",
      "from SpellingCorrector import SpellingCorrector\n",
      "\n",
      "corrector = SpellingCorrector(all_words)\n",
      "corrections = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for i, sentence in enumerate(essay.tagged_sentences):\n",
      "        for j, (w, tags) in enumerate(sentence):\n",
      "            # common error is ..n't and ..nt\n",
      "            if w.endswith(\"n't\") or w.endswith(\"n'\"):\n",
      "                cw = w[:-3] + \"nt\"\n",
      "            elif w.endswith(\"'s\"):\n",
      "                cw = w[:-2]\n",
      "            elif w == \"&\":\n",
      "                cw = \"and\"\n",
      "            else:\n",
      "                cw = corrector.correct(w)\n",
      "            if cw != w:\n",
      "                corrections[(w,cw)] += 1\n",
      "                sentence[j] = (cw, tags)            \n",
      "            \n",
      "wd_sent_freq = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        wds, tag_list = zip(*sentence)\n",
      "        unique_wds = set(wds)\n",
      "        for w in unique_wds: \n",
      "            wd_sent_freq[w] += 1\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "236 files found\n",
        "236 essays processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "cor_srtd = sort_by_value(corrections, reverse = True)\n",
      "cor_srtd[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[((\"it's\", 'it'), 46),\n",
        " ((\"don't\", 'dont'), 30),\n",
        " ((\"that's\", 'that'), 28),\n",
        " (('algea', 'algae'), 20),\n",
        " (('zox', 'zo'), 20),\n",
        " ((\"world's\", 'world'), 17),\n",
        " ((\"can't\", 'cant'), 14),\n",
        " (('&', 'and'), 12),\n",
        " (('bleaches', 'bleached'), 12),\n",
        " (('cloral', 'coral'), 10),\n",
        " ((\"coral's\", 'coral'), 9),\n",
        " ((\"isn't\", 'isnt'), 9),\n",
        " ((\"won't\", 'wont'), 9),\n",
        " ((\"they're\", 'there'), 9),\n",
        " (('tempature', 'temperature'), 8),\n",
        " ((\"doesn't\", 'doesnt'), 8),\n",
        " (('tempeture', 'temperature'), 7),\n",
        " (('varys', 'vary'), 6),\n",
        " (('saclike', 'saline'), 6),\n",
        " ((\"there's\", 'there'), 5)]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Single char words \"\"\"\n",
      "wds = [(w,f) for w,f in wd_sent_freq.items() if len(w.strip()) == 1 and not w[0].isalpha()]\n",
      "print \"\\n\".join(map(str,sorted(wds, key = lambda (w,f): -f)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('.', 2080)\n",
        "(',', 511)\n",
        "('-', 76)\n",
        "('/', 76)\n",
        "('\"', 71)\n",
        "('?', 63)\n",
        "('3', 34)\n",
        "('(', 29)\n",
        "(')', 28)\n",
        "('%', 26)\n",
        "('\\xc2', 24)\n",
        "('\\xb0', 24)\n",
        "('1', 16)\n",
        "('\\\\', 16)\n",
        "('5', 13)\n",
        "('\\x80', 11)\n",
        "('\\xe2', 11)\n",
        "(';', 10)\n",
        "('+', 6)\n",
        "('2', 6)\n",
        "(\"'\", 6)\n",
        "('\\x93', 6)\n",
        "('\\x99', 5)\n",
        "('0', 4)\n",
        "('!', 4)\n",
        "(':', 4)\n",
        "('9', 2)\n",
        "('=', 2)\n",
        "('6', 1)\n",
        "('7', 1)\n",
        "('8', 1)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Windows\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Creating Windows \"\"\"\n",
      "def filter2min_word_freq(sentence):\n",
      "    return filter(lambda (w, tags4word): wd_sent_freq[w] >= MIN_SENTENCE_FREQ, sentence)\n",
      "\n",
      "VALID_CHARS = {\".\", \"?\", \"!\", \"=\", \"/\", \":\", \";\", \"&\", \"+\",  \"-\", \"=\",  \"%\", \"'\", \",\", \"\\\\\", \"(\", \")\", \"\\\"\"}\n",
      "\"\"\" Remove bad chars (see above - e.g. '\\x93') \"\"\"\n",
      "removed = set()\n",
      "def valid_wd(wd):\n",
      "    wd = wd.strip()\n",
      "    if len(wd) != 1:\n",
      "        return True\n",
      "    if wd in removed:\n",
      "        return False\n",
      "    if wd.isalpha() or wd.isdigit() or wd in VALID_CHARS:\n",
      "        return True\n",
      "    removed.add(wd)\n",
      "    return False\n",
      "    \n",
      "def filterout_punctuation(sentence):\n",
      "    return filter(lambda (w, tags4word): valid_wd(w), sentence)\n",
      "\n",
      "def bookend(sentence):\n",
      "    for i in range(MID_IX):\n",
      "        modified_sentence.insert(0, (SENTENCE_START,    set()))\n",
      "        modified_sentence.append(   (SENTENCE_END,      set()))\n",
      "\n",
      "def assert_windows_correct(windows):\n",
      "    lens = map(len, windows)\n",
      "    assert min(lens) == max(lens) == WINDOW_SIZE, \\\n",
      "            \"Windows are not all the correct size\"\n",
      "   \n",
      "ix2windows = {}\n",
      "ix2sents = {}\n",
      "sentences = []\n",
      "tokenized_sentences = []\n",
      "\n",
      "i = 0\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        \n",
      "        modified_sentence = filter2min_word_freq(sentence)\n",
      "        modified_sentence = filterout_punctuation(modified_sentence)\n",
      "        if len(modified_sentence) == 0:\n",
      "            continue\n",
      "        \n",
      "        bookend(modified_sentence)        \n",
      "        new_windows = split_into_windows(modified_sentence, window_size= WINDOW_SIZE)        \n",
      "        assert_windows_correct(new_windows)       \n",
      "        \n",
      "        # tagged words\n",
      "        sentences.append(sentence)\n",
      "        # words only\n",
      "        tokenized_sentences.append(zip(*sentence)[0])\n",
      "        \n",
      "        ix2windows[i] = new_windows\n",
      "        ix2sents[i] = modified_sentence\n",
      "        i += 1\n",
      "        \n",
      "\"\"\" Assert tags set correctly \"\"\"\n",
      "print \"Windows loaded correctly!\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Windows loaded correctly!\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sentence Level Features\n",
      "-----------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from gensim import matutils\n",
      "\n",
      "def filter_words(wd):\n",
      "    return wd.isalnum()\n",
      "\n",
      "docs = map(lambda sen : \" \".join(filter(filter_words,sen)),tokenized_sentences)\n",
      "\n",
      "#Vectorize\n",
      "vectorizer = TfidfVectorizer(use_idf = False, ngram_range = (1, 1), min_df = 5, binary=True)\n",
      "sentence_vectors = vectorizer.fit_transform(docs)\n",
      "sentence_vectors = sentence_vectors.todense()\n",
      "sentence_vectors = map(lambda s: s.tolist()[0], sentence_vectors)\n",
      "ix2vector = dict(enumerate(sentence_vectors))\n",
      "print len(ix2vector[0]), \"features\"\n",
      "ix2vector[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "600 features\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Removed Characters\n",
      "------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(sorted(removed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract Features\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract Features \"\"\"\n",
      "from WindowFeatures import extract_positional_word_features, extract_word_features\n",
      "from NgramGenerator import compute_ngrams\n",
      "\n",
      "def extract_skip_b4_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[:mid_ix]:\n",
      "        feats[\"_BEFORE: \" + wd + \"|\" + target] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_skip_after_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[mid_ix+1:]:\n",
      "        feats[\"_AFTER: \" + target + \"|\" + wd] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_positional_bigram_features(window, mid_ix, feature_val = 1):\n",
      "    bi_grams = compute_ngrams(window, max_len = 2, min_len = 2)\n",
      "    d = {}\n",
      "    for i, bi_gram in enumerate(bi_grams):\n",
      "        d[\"BI\" + \":\" + str(-mid_ix + i) + \" \" + bi_gram[0] + \" | \" + bi_gram[1]] = feature_val\n",
      "    return d\n",
      "\n",
      "def extract_positional_skip_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for i, wd in enumerate(window):\n",
      "        if i == mid_ix:\n",
      "            continue\n",
      "        a,b = wd,target\n",
      "        if i > mid_ix:\n",
      "            a,b = b,a\n",
      "        feats[\"SKIP:\" + str(-mid_ix + i) + \" \" + a + \" | \" + b] = feature_val\n",
      "    return feats\n",
      "\n",
      "\"\"\" TODO:\n",
      "        Extract features for numbers\n",
      "        Extract features for years\n",
      "        Extract features that are temperatures (look for degree\\degrees in subsequent words, along with C or F)\n",
      "\"\"\"\n",
      "idgen = IdGenerator()\n",
      "stemmer = PorterStemmer()\n",
      "\n",
      "def extract_features(words):\n",
      "    \n",
      "    if STEM:\n",
      "        words = [stemmer.stem(w) for w in words]\n",
      "    #Extract features for words\n",
      "    \n",
      "    \"\"\" Try only middle word \"\"\"\n",
      "    features = {}\n",
      "    ###\n",
      "    pos_features = extract_positional_word_features(words, MID_IX, feature_val=1)    \n",
      "    word_features  = extract_word_features(words, feature_val=1)\n",
      "    \n",
      "    #DO NOT HELP\n",
      "    #b4_features    = extract_skip_b4_word_features(words, MID_IX, feature_val=1)\n",
      "    #after_features = extract_skip_after_word_features(words, MID_IX, feature_val=1)\n",
      "    #pos_skip_grams = extract_positional_skip_word_features(words, MID_IX,  feature_val = 1)\n",
      "    pos_bi_grams = extract_positional_bigram_features(words, MID_IX, feature_val = 1)\n",
      "\n",
      "    features.update(pos_features)\n",
      "    features.update(word_features)\n",
      "    #features.update(b4_features)\n",
      "    #features.update(after_features)\n",
      "    #features.update(pos_skip_grams)\n",
      "    features.update(pos_bi_grams)\n",
      "    return features.items()\n",
      "\n",
      "def extract_ys_by_code(tags, ysByCode):\n",
      "    for code in all_codes:\n",
      "        ysByCode[code].append(1 if code in tags else 0 )    \n",
      "\n",
      "ix2ys = {}\n",
      "ix2feats = {}\n",
      "feat_counts = defaultdict(int)\n",
      "def tally_features(feats):\n",
      "    for k,v in feats:\n",
      "        feat_counts[k] += 1\n",
      "\n",
      "for i, windows in ix2windows.items():\n",
      "    feats = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    \n",
      "    ix2feats[i] = feats\n",
      "    ix2ys[i] = ysByCode\n",
      "    for window in windows:\n",
      "        # Get the words minus tags\n",
      "        words, tags = zip(*window)                \n",
      "        feat = extract_features(words)\n",
      "        tally_features(feat)\n",
      "        feats.append(feat)\n",
      "        \n",
      "        #Tags for middle word (target)\n",
      "        tags4word = tags[MID_IX]\n",
      "        extract_ys_by_code(tags4word, ysByCode)\n",
      "    assert len(windows) == len(feats)\n",
      "    assert all(map(lambda (k,v): len(v) == len(feats), ysByCode.items()))\n",
      "        \n",
      "\"\"\" Convert sparse dictionary features to sparse arrays \"\"\"\n",
      "ix2xs = {}\n",
      "for i, feature_lists in ix2feats.items():\n",
      "    xs = []\n",
      "    ix2xs[i] = xs\n",
      "    for feats in feature_lists:\n",
      "        x = [(idgen.get_id(f),v) \n",
      "             for f,v in feats \n",
      "             if feat_counts[f] >= MIN_FEAT_FREQ or f.startswith(\"WD:0\" )]\n",
      "        xs.append(x)        \n",
      "\n",
      "num_features = idgen.max_id() + 1\n",
      "print \"Number of features:\", num_features\n",
      "\n",
      "\"\"\" Convert to dense numpy arrays \"\"\"\n",
      "for i in ix2xs.keys():\n",
      "    xs = ix2xs[i]\n",
      "    xs = np.array([matutils.sparse2full(x, num_features) for x in xs])        \n",
      "    ix2xs[i] = xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 12283\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "\n",
      "def count_above(ft_counts, threshold):\n",
      "    above = [ v for k,v in ft_counts.items() if v >= threshold]\n",
      "    return (sum(above), len(above))\n",
      "\n",
      "total_all, cnt_all = count_above(feat_counts, 0)\n",
      "total_above, cnt_above = count_above(feat_counts, MIN_FEAT_FREQ)\n",
      "\n",
      "print \"Counts\"\n",
      "print \"all:     \", cnt_all\n",
      "print \"above:   \", cnt_above\n",
      "print \"% above: \", str(100.0 * cnt_above / float(cnt_all))+ \"%\"\n",
      "\n",
      "print \"\\nTotal Frequency\"\n",
      "print \"all:     \", total_all\n",
      "print \"above:   \", total_above\n",
      "print \"% above: \", str(100.0 * total_above / float(total_all))+ \"%\"\n",
      "\n",
      "#srtd = sort_by_value(feat_counts, reverse = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counts\n",
        "all:      60563\n",
        "above:    12016\n",
        "% above:  19.8404966729%\n",
        "\n",
        "Total Frequency\n",
        "all:      677609\n",
        "above:    604302\n",
        "% above:  89.1815191357%\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_window(win):\n",
      "    def set2str(st):\n",
      "        return \"{\" + str(t)[5:-2] + \"}\"\n",
      "    \n",
      "    w, tg = zip(*win)\n",
      "    lens = [max(len(wd),len(set2str(t))) for wd,t in win]\n",
      "    \n",
      "    for i, wd in enumerate(w):\n",
      "        print wd.ljust(lens[i]) , \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "    for i, t in enumerate(tg):\n",
      "        print set2str(t).ljust(lens[i]), \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "def extract_features(window, feat_vals):\n",
      "    feats = [idgen.get_key(i) for i,val in enumerate(feat_vals) if val]\n",
      "    \n",
      "    wd_feats = []\n",
      "    for win in window:\n",
      "        wd, tgs = win\n",
      "        if STEM:\n",
      "            match = filter(lambda feat: \" \" + stemmer.stem(wd) + \" \" in \" \" + feat + \" \", feats)\n",
      "        else:\n",
      "            match = filter(lambda feat: \" \" + wd + \" \" in \" \" + feat + \" \", feats)\n",
      "        wd_feats.append((wd, match))\n",
      "    return wd_feats\n",
      "\n",
      "def print_features(wf):\n",
      "    w_f = wf\n",
      "    for w,ft in w_f:\n",
      "        print w.ljust(10), map(lambda s:s.ljust(10), sorted(ft, key=lambda s:(len(s),s)))\n",
      "    print \"\"\n",
      "\n",
      "#uncomment to verify code output\n",
      "\n",
      "sentence_no = 101\n",
      "print \"Tagged Windows\"\n",
      "for win in ix2windows[sentence_no][:5]:\n",
      "    print_window(win)\n",
      "print \"\"    \n",
      "\n",
      "print \"Features\"\n",
      "def prn_sent_features(sentence_num):\n",
      "    win = ix2windows[sentence_num]\n",
      "    for i in range(len(win)):\n",
      "        print \"[%s]\" % str(i)\n",
      "        wf = extract_features(win[i], ix2xs[sentence_num][i])\n",
      "        print_features(wf)\n",
      "\n",
      "prn_sent_features(sentence_no)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tagged Windows\n",
        "<START> | <START> | <START> | the | passage | states | \"  | \n",
        "{}      | {}      | {}      | {}  | {}      | {}     | {} | \n",
        "<START> | <START> | the | passage | states | \"  | they | \n",
        "{}      | {}      | {}  | {}      | {}     | {} | {}   | \n",
        "<START> | the | passage | states | \"  | they | have | \n",
        "{}      | {}  | {}      | {}     | {} | {}   | {}   | \n",
        "the | passage | states | \"  | they | have | know | \n",
        "{}  | {}      | {}     | {} | {}   | {}   | {}   | \n",
        "passage | states | \"  | they | have | know | about | \n",
        "{}      | {}     | {} | {}   | {}   | {}   | {}    | \n",
        "\n",
        "Features\n",
        "[0]\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "the        ['the       ', 'WD:0 the  ', 'BI:-1 <START> | the']\n",
        "passage    ['passag    ']\n",
        "states     ['state     ', 'WD:2 state', 'BI:2 state | \"']\n",
        "\"          ['\"         ', 'WD:3 \"    ', 'BI:2 state | \"']\n",
        "\n",
        "[1]\n",
        "<START>    ['<START>   ', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-2 <START> | the', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-2 <START> | the', 'BI:-3 <START> | <START>']\n",
        "the        ['the       ', 'WD:-1 the ', 'BI:-2 <START> | the']\n",
        "passage    ['passag    ', 'WD:0 passag']\n",
        "states     ['state     ', 'WD:1 state', 'BI:1 state | \"']\n",
        "\"          ['\"         ', 'WD:2 \"    ', 'BI:1 state | \"']\n",
        "they       ['they      ', 'WD:3 they ']\n",
        "\n",
        "[2]\n",
        "<START>    ['<START>   ', 'WD:-3 <START>', 'BI:-3 <START> | the']\n",
        "the        ['the       ', 'WD:-2 the ', 'BI:-3 <START> | the']\n",
        "passage    ['passag    ']\n",
        "states     ['state     ', 'WD:0 state', 'BI:0 state | \"']\n",
        "\"          ['\"         ', 'WD:1 \"    ', 'BI:0 state | \"']\n",
        "they       ['they      ', 'WD:2 they ', 'BI:2 they | have']\n",
        "have       ['have      ', 'WD:3 have ', 'BI:2 they | have']\n",
        "\n",
        "[3]\n",
        "the        ['the       ', 'WD:-3 the ']\n",
        "passage    ['passag    ']\n",
        "states     ['state     ', 'WD:-1 state', 'BI:-1 state | \"']\n",
        "\"          ['\"         ', 'WD:0 \"    ', 'BI:-1 state | \"']\n",
        "they       ['they      ', 'WD:1 they ', 'BI:1 they | have']\n",
        "have       ['have      ', 'WD:2 have ', 'BI:1 they | have']\n",
        "know       ['know      ', 'WD:3 know ']\n",
        "\n",
        "[4]\n",
        "passage    ['passag    ']\n",
        "states     ['state     ', 'WD:-2 state', 'BI:-2 state | \"']\n",
        "\"          ['\"         ', 'WD:-1 \"   ', 'BI:-2 state | \"']\n",
        "they       ['they      ', 'WD:0 they ', 'BI:0 they | have']\n",
        "have       ['have      ', 'WD:1 have ', 'BI:0 they | have']\n",
        "know       ['know      ', 'WD:2 know ']\n",
        "about      ['about     ', 'WD:3 about']\n",
        "\n",
        "[5]\n",
        "states     ['state     ', 'WD:-3 state', 'BI:-3 state | \"']\n",
        "\"          ['\"         ', 'WD:-2 \"   ', 'BI:-3 state | \"']\n",
        "they       ['they      ', 'WD:-1 they', 'BI:-1 they | have']\n",
        "have       ['have      ', 'WD:0 have ', 'BI:-1 they | have']\n",
        "know       ['know      ', 'WD:1 know ']\n",
        "about      ['about     ', 'WD:2 about', 'BI:2 about | chang']\n",
        "changes    ['chang     ', 'WD:3 chang', 'BI:2 about | chang']\n",
        "\n",
        "[6]\n",
        "\"          ['\"         ', 'WD:-3 \"   ']\n",
        "they       ['they      ', 'WD:-2 they', 'BI:-2 they | have']\n",
        "have       ['have      ', 'WD:-1 have', 'BI:-2 they | have']\n",
        "know       ['know      ', 'WD:0 know ']\n",
        "about      ['about     ', 'WD:1 about', 'BI:1 about | chang']\n",
        "changes    ['chang     ', 'WD:2 chang', 'BI:2 chang | in', 'BI:1 about | chang']\n",
        "in         ['in        ', 'WD:3 in   ', 'BI:2 chang | in']\n",
        "\n",
        "[7]\n",
        "they       ['they      ', 'WD:-3 they', 'BI:-3 they | have']\n",
        "have       ['have      ', 'WD:-2 have', 'BI:-3 they | have']\n",
        "know       ['know      ', 'WD:-1 know']\n",
        "about      ['about     ', 'WD:0 about', 'BI:0 about | chang']\n",
        "changes    ['chang     ', 'WD:1 chang', 'BI:1 chang | in', 'BI:0 about | chang']\n",
        "in         ['in        ', 'WD:2 in   ', 'BI:2 in | wind', 'BI:1 chang | in']\n",
        "wind       ['wind      ', 'WD:3 wind ', 'BI:2 in | wind']\n",
        "\n",
        "[8]\n",
        "have      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['have      ', 'WD:-3 have']\n",
        "know       ['know      ', 'WD:-2 know']\n",
        "about      ['about     ', 'WD:-1 about', 'BI:-1 about | chang']\n",
        "changes    ['chang     ', 'WD:0 chang', 'BI:0 chang | in', 'BI:-1 about | chang']\n",
        "in         ['in        ', 'WD:1 in   ', 'BI:1 in | wind', 'BI:0 chang | in']\n",
        "wind       ['wind      ', 'WD:2 wind ', 'BI:2 wind | ,', 'BI:1 in | wind']\n",
        ",          [',         ', 'WD:3 ,    ', 'BI:2 wind | ,']\n",
        "\n",
        "[9]\n",
        "know       ['know      ', 'WD:-3 know']\n",
        "about      ['about     ', 'WD:-2 about', 'BI:-2 about | chang']\n",
        "changes    ['chang     ', 'WD:-1 chang', 'BI:-1 chang | in', 'BI:-2 about | chang']\n",
        "in         ['in        ', 'WD:0 in   ', 'BI:0 in | wind', 'BI:-1 chang | in']\n",
        "wind       ['wind      ', 'WD:1 wind ', 'BI:1 wind | ,', 'BI:0 in | wind']\n",
        ",          [',         ', 'WD:2 ,    ', 'BI:1 wind | ,', 'BI:2 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:3 temperatur', 'BI:2 , | temperatur']\n",
        "\n",
        "[10]\n",
        "about      ['about     ', 'WD:-3 about', 'BI:-3 about | chang']\n",
        "changes    ['chang     ', 'WD:-2 chang', 'BI:-2 chang | in', 'BI:-3 about | chang']\n",
        "in         ['in        ', 'WD:-1 in  ', 'BI:-1 in | wind', 'BI:-2 chang | in']\n",
        "wind       ['wind      ', 'WD:0 wind ', 'BI:0 wind | ,', 'BI:-1 in | wind']\n",
        ",          [',         ', 'WD:1 ,    ', 'BI:0 wind | ,', 'BI:1 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:2 temperatur', 'BI:1 , | temperatur', 'BI:2 temperatur | .']\n",
        ".          ['.         ', 'WD:3 .    ', 'BI:2 temperatur | .']\n",
        "\n",
        "[11]\n",
        "changes    ['chang     ', 'WD:-3 chang', 'BI:-3 chang | in']\n",
        "in         ['in        ', 'WD:-2 in  ', 'BI:-2 in | wind', 'BI:-3 chang | in']\n",
        "wind       ['wind      ', 'WD:-1 wind', 'BI:-1 wind | ,', 'BI:-2 in | wind']\n",
        ",          [',         ', 'WD:0 ,    ', 'BI:-1 wind | ,', 'BI:0 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:1 temperatur', 'BI:0 , | temperatur', 'BI:1 temperatur | .']\n",
        ".          ['.         ', 'WD:2 .    ', 'BI:2 . | \"', 'BI:1 temperatur | .']\n",
        "\"          ['\"         ', 'WD:3 \"    ', 'BI:2 . | \"']\n",
        "\n",
        "[12]\n",
        "in         ['in        ', 'WD:-3 in  ', 'BI:-3 in | wind']\n",
        "wind       ['wind      ', 'WD:-2 wind', 'BI:-2 wind | ,', 'BI:-3 in | wind']\n",
        ",          [',         ', 'WD:-1 ,   ', 'BI:-2 wind | ,', 'BI:-1 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:0 temperatur', 'BI:0 temperatur | .', 'BI:-1 , | temperatur']\n",
        ".          ['.         ', 'WD:1 .    ', 'BI:1 . | \"', 'BI:0 temperatur | .']\n",
        "\"          ['\"         ', 'WD:2 \"    ', 'BI:1 . | \"', 'BI:2 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:3 <END>', 'BI:2 \" | <END>']\n",
        "\n",
        "[13]\n",
        "wind       ['wind      ', 'WD:-3 wind', 'BI:-3 wind | ,']\n",
        ",          [',         ', 'WD:-2 ,   ', 'BI:-3 wind | ,', 'BI:-2 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:-1 temperatur', 'BI:-1 temperatur | .', 'BI:-2 , | temperatur']\n",
        ".          ['.         ', 'WD:0 .    ', 'BI:0 . | \"', 'BI:-1 temperatur | .']\n",
        "\"          ['\"         ', 'WD:1 \"    ', 'BI:0 . | \"', 'BI:1 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:2 <END>', 'WD:3 <END>', 'BI:1 \" | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:2 <END>', 'WD:3 <END>', 'BI:1 \" | <END>', 'BI:2 <END> | <END>']\n",
        "\n",
        "[14]\n",
        ",          [',         ', 'WD:-3 ,   ', 'BI:-3 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:-2 temperatur', 'BI:-2 temperatur | .', 'BI:-3 , | temperatur']\n",
        ".          ['.         ', 'WD:-1 .   ', 'BI:-1 . | \"', 'BI:-2 temperatur | .']\n",
        "\"          ['\"         ', 'WD:0 \"    ', 'BI:-1 . | \"', 'BI:0 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_xs_ys(ixs, ixTOxs, ixTOys, codes):\n",
      "    xs = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    for i in ixs:\n",
      "        xs_tmp = ixTOxs[i]\n",
      "        xs.extend(xs_tmp)\n",
      "        ysByCode_tmp = ixTOys[i]\n",
      "        for code in codes:\n",
      "            ysByCode[code].extend(ysByCode_tmp[code])\n",
      "    return (np.array(xs), ysByCode)\n",
      "\n",
      "num_train = int(len(sentences) * (1.0 - PCT_VALIDATION))\n",
      "\n",
      "ixtest  = ix2sents.keys()[:num_train]\n",
      "ixvalid = ix2sents.keys()[num_train:]\n",
      "\n",
      "# Extract flattened windows for training data as xs and ys\n",
      "x_t, yByCode_t = extract_xs_ys(ixtest,ix2xs, ix2ys, all_codes)\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"#Sentences : \" + str(len(sentences))\n",
      "print \"\"\n",
      "\n",
      "all_codes = sorted(all_codes, key= lambda s :(len(s), s))\n",
      "for code in all_codes:\n",
      "    print code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#Sentences : 2144\n",
        "\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "50\n",
        "5b\n",
        "it\n",
        "other\n",
        "Causer\n",
        "Result\n",
        "Anaphor\n",
        "explicit\n",
        "rhetorical\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train\n",
      "====="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" TRAIN \"\"\"\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "map_svm = lambda y: -1 if y < 0 else 1\n",
      "map_reg = lambda y: y\n",
      "\n",
      "#map_y = map_svm\n",
      "map_y = map_reg\n",
      "\n",
      "#cls = DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, criterion=\"entropy\")\n",
      "#cls = DecisionTreeClassifier(criterion=\"entropy\")\n",
      "#cls = LogisticRegression()\n",
      "#cls = RidgeClassifier()\n",
      "#cls = LinearSVC()\n",
      "#cls = KNeighborsClassifier(n_neighbors=5) # TOO SLOW!\n",
      "#cls = LDA()\n",
      "#cls = SVC()\n",
      "#cls = RandomForestClassifier(n_jobs=-1, max_depth=100, n_estimators=10)\n",
      "#cls = Ridge()\n",
      "#cls = LinearSVC\n",
      "\n",
      "print \"Starting Training\"\n",
      "reg_codes = [c for c in all_codes if c.isdigit() or c == \"explicit\"]\n",
      "\n",
      "def train(codes, xs, yByCode, fn_create_cls):\n",
      "    code2classifier = {}\n",
      "    for code in codes:\n",
      "        print \"Training for :\", code   \n",
      "        cls = fn_create_cls()\n",
      "        code2classifier[code] = cls\n",
      "        ys = np.asarray(yByCode[code])    \n",
      "        ys = map(map_y, ys)\n",
      "        cls.fit(xs, ys)\n",
      "    return code2classifier\n",
      "\n",
      "code2cls = train(all_codes, x_t, yByCode_t, LinearSVC)\n",
      "print cls\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting Training\n",
        "Training for : 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "<class 'sklearn.svm.classes.LinearSVC'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classify\n",
      "--------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Get sentence level classification performance \"\"\"\n",
      "def test_for_code(code, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    cls = codeToClassifier[code]\n",
      "    \n",
      "    try:\n",
      "        cls.n_jobs = 1\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "    act_ys  = []\n",
      "    pred_ys = []\n",
      "    for ix in ixs:\n",
      "        xs = ixToXs[ix]\n",
      "        ysByCode = ixToYs[ix]\n",
      "        \n",
      "        ys = np.asarray(ysByCode[code])\n",
      "        ys = map(map_y, ys)\n",
      "        pred = cls.predict(xs)\n",
      "        \n",
      "        # Flatten predictions to sentence level by taking the max values\n",
      "        # over all windows\n",
      "        act_ys.append(max(ys))\n",
      "        pred_ys.append(max(pred))\n",
      "    \n",
      "    num_codes = len([y for y in act_ys if y == 1])\n",
      "    r,p,f1,a = rpf1a(act_ys, pred_ys)\n",
      "    print \"code:      \", code\n",
      "    print \"recall:    \", r\n",
      "    print \"precision: \", p\n",
      "    print \"f1:        \", f1\n",
      "    print \"accuracy:  \", a\n",
      "    print \"sentences: \", num_codes\n",
      "    print \"\"\n",
      "    return rpfa(r,p,f1,a,num_codes)\n",
      "\n",
      "print \"\"\n",
      "print \"total sent:\", len(ixvalid)\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "total sent: 536\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training Data Performance\n",
      "-------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(codes, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    td_metrics = []\n",
      "    for c in codes:\n",
      "        cls = codeToClassifier[c]\n",
      "        td_metrics.append(test_for_code(c, ixs, ixToXs, ixToYs, codeToClassifier))\n",
      "    td_wt_mn_prfa = weighted_mean_rpfa(td_metrics)\n",
      "    print type(cls), td_wt_mn_prfa\n",
      "    return td_wt_mn_prfa\n",
      "\n",
      "print \"Training Data: \"\n",
      "metrics = test(all_codes, ixtest, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     1.0\n",
        "precision:  0.994011976048\n",
        "f1:         0.996996996997\n",
        "accuracy:   0.999378109453\n",
        "sentences:  166\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.931034482759\n",
        "precision:  0.964285714286\n",
        "f1:         0.947368421053\n",
        "accuracy:   0.998134328358\n",
        "sentences:  29\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.995192307692\n",
        "precision:  0.99043062201\n",
        "f1:         0.992805755396\n",
        "accuracy:   0.998134328358\n",
        "sentences:  208\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  33\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     1.0\n",
        "precision:  0.947368421053\n",
        "f1:         0.972972972973\n",
        "accuracy:   0.997512437811\n",
        "sentences:  72\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  24\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  113\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  42\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  18\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     1.0\n",
        "precision:  0.963636363636\n",
        "f1:         0.981481481481\n",
        "accuracy:   0.998756218905\n",
        "sentences:  53\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     1.0\n",
        "precision:  0.923076923077\n",
        "f1:         0.96\n",
        "accuracy:   0.999378109453\n",
        "sentences:  12\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.99836867863\n",
        "precision:  0.990291262136\n",
        "f1:         0.994313566206\n",
        "accuracy:   0.995646766169\n",
        "sentences:  613\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "recall:     1.0\n",
        "precision:  0.909090909091\n",
        "f1:         0.952380952381\n",
        "accuracy:   0.999378109453\n",
        "sentences:  10\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  1\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "recall:     0.815602836879\n",
        "precision:  1.0\n",
        "f1:         0.8984375\n",
        "accuracy:   0.983830845771\n",
        "sentences:  141\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "recall:     0.972727272727\n",
        "precision:  0.935860058309\n",
        "f1:         0.953937592868\n",
        "accuracy:   0.980721393035\n",
        "sentences:  330\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "recall:     0.901492537313\n",
        "precision:  0.932098765432\n",
        "f1:         0.916540212443\n",
        "accuracy:   0.9657960199\n",
        "sentences:  335\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "recall:     0.95652173913\n",
        "precision:  1.0\n",
        "f1:         0.977777777778\n",
        "accuracy:   0.997512437811\n",
        "sentences:  92\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.973837209302\n",
        "precision:  0.979532163743\n",
        "f1:         0.97667638484\n",
        "accuracy:   0.990049751244\n",
        "sentences:  344\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "recall:     0.990909090909\n",
        "precision:  0.973214285714\n",
        "f1:         0.981981981982\n",
        "accuracy:   0.997512437811\n",
        "sentences:  110\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.9687, Precision: 0.9740, F1: 0.9707, Accuracy: 0.9900, Codes:  2746\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Validation Data Performance\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data: \"\n",
      "test(reg_codes, ixvalid, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     0.879518072289\n",
        "precision:  0.669724770642\n",
        "f1:         0.760416666667\n",
        "accuracy:   0.914179104478\n",
        "sentences:  83\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.605263157895\n",
        "precision:  0.793103448276\n",
        "f1:         0.686567164179\n",
        "accuracy:   0.960820895522\n",
        "sentences:  38\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.817391304348\n",
        "precision:  0.728682170543\n",
        "f1:         0.770491803279\n",
        "accuracy:   0.89552238806\n",
        "sentences:  115\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     0.8\n",
        "precision:  1.0\n",
        "f1:         0.888888888889\n",
        "accuracy:   0.992537313433\n",
        "sentences:  20\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     0.772727272727\n",
        "precision:  0.653846153846\n",
        "f1:         0.708333333333\n",
        "accuracy:   0.94776119403\n",
        "sentences:  44\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     1.0\n",
        "precision:  0.625\n",
        "f1:         0.769230769231\n",
        "accuracy:   0.994402985075\n",
        "sentences:  5\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     0.75\n",
        "precision:  0.555555555556\n",
        "f1:         0.63829787234\n",
        "accuracy:   0.936567164179\n",
        "sentences:  40\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     0.666666666667\n",
        "precision:  1.0\n",
        "f1:         0.8\n",
        "accuracy:   0.992537313433\n",
        "sentences:  12\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     0.545454545455\n",
        "precision:  1.0\n",
        "f1:         0.705882352941\n",
        "accuracy:   0.990671641791\n",
        "sentences:  11\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     0.705882352941\n",
        "precision:  0.75\n",
        "f1:         0.727272727273\n",
        "accuracy:   0.983208955224\n",
        "sentences:  17\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     1.0\n",
        "precision:  0.846153846154\n",
        "f1:         0.916666666667\n",
        "accuracy:   0.996268656716\n",
        "sentences:  11\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.97510373444\n",
        "precision:  0.928853754941\n",
        "f1:         0.951417004049\n",
        "accuracy:   0.955223880597\n",
        "sentences:  241\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "recall:     0.454545454545\n",
        "precision:  0.454545454545\n",
        "f1:         0.454545454545\n",
        "accuracy:   0.977611940299\n",
        "sentences:  11\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "recall:     0.0\n",
        "precision:  0.0\n",
        "f1:         0.0\n",
        "accuracy:   1.0\n",
        "sentences:  0\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "recall:     0.125\n",
        "precision:  0.344827586207\n",
        "f1:         0.183486238532\n",
        "accuracy:   0.833955223881\n",
        "sentences:  80\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "recall:     0.772151898734\n",
        "precision:  0.547085201794\n",
        "f1:         0.640419947507\n",
        "accuracy:   0.744402985075\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "recall:     0.6\n",
        "precision:  0.536312849162\n",
        "f1:         0.566371681416\n",
        "accuracy:   0.725746268657\n",
        "sentences:  160\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "recall:     0.166666666667\n",
        "precision:  0.4\n",
        "f1:         0.235294117647\n",
        "accuracy:   0.902985074627\n",
        "sentences:  48\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.689440993789\n",
        "precision:  0.578125\n",
        "f1:         0.628895184136\n",
        "accuracy:   0.755597014925\n",
        "sentences:  161\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "recall:     0.323529411765\n",
        "precision:  0.6875\n",
        "f1:         0.44\n",
        "accuracy:   0.89552238806\n",
        "sentences:  68\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6961, Precision: 0.6624, F1: 0.6645, Accuracy: 0.8595, Codes:  1323\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "Recall: 0.6961, Precision: 0.6624, F1: 0.6645, Accuracy: 0.8595, Codes:  1323"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Window - 5, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LDA:      Recall: 0.8927, Precision: 0.6974, F1: 0.7675, Accuracy: 0.8823, Codes:   792\n",
      "LinSVC:   Recall: 0.7601, Precision: 0.7655, F1: 0.7563, Accuracy: 0.9048, Codes:   792\n",
      "DT:       Recall: 0.7462, Precision: 0.6890, F1: 0.7063, Accuracy: 0.8766, Codes:   792\n",
      "RidgeClf: Recall: 0.6843, Precision: 0.8359, F1: 0.6874, Accuracy: 0.9036, Codes:   795\n",
      "\n",
      "LinSVC\n",
      "Window - 7, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LinSVC: Recall: 0.7937, Precision: 0.7522, F1: 0.7677, Accuracy: 0.9037, Codes:   795\n",
      "\n",
      "Window - 9, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.7887, Precision: 0.7338, F1: 0.7555, Accuracy: 0.8929, Codes:   795\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.8058, Precision: 0.7559, F1: 0.7756, Accuracy: 0.9046, Codes:   798\n",
      "\n",
      "-- Starting adding new features, messing with feature freq\n",
      "Window - 5, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8008, Precision: 0.7369, F1: 0.7625, Accuracy: 0.9008, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8120, Precision: 0.7535, F1: 0.7779, Accuracy: 0.9066, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - ***15***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8145, Precision: 0.7460, F1: 0.7744, Accuracy: 0.9040, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 20\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7982, Precision: 0.7496, F1: 0.7685, Accuracy: 0.9025, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 25\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8070, Precision: 0.7485, F1: 0.7732, Accuracy: 0.9047, Codes:   798\n",
      "\n",
      "***\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 5 ***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "    + Positional BI-GRAMS ****\n",
      "Recall: 0.8145, Precision: 0.7642, F1: 0.7831, Accuracy: 0.9070, Codes:   798\n",
      "***\n",
      "\n",
      "Logistic Regression\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7306, Precision: 0.8298, F1: 0.7672, Accuracy: 0.9150, Codes:   798\n",
      "\n",
      "Window - 9, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7206, Precision: 0.8232, F1: 0.7580, Accuracy: 0.9121, Codes:   798\n",
      "\n",
      "RF\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit')\n",
      "Recall: 0.6028, Precision: 0.8071, F1: 0.6570, Accuracy: 0.8978, Codes:   798"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train Stacked Classifier\n",
      "========================"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Create Data Using Previous Classifier \"\"\"\n",
      "ix2newxs = {}\n",
      "ix2newys = {} #dict to dict to list\n",
      "\n",
      "CAUSAL_REL = \"CRel\"\n",
      "RESULT_REL = \"RRel\"\n",
      "CAUSE_RESULT = \"C->R\"\n",
      "\n",
      "cr_codes = [CAUSAL_REL, RESULT_REL, CAUSE_RESULT]\n",
      "tally = defaultdict(lambda: defaultdict(int))\n",
      "codes_per_row = []\n",
      "str_codes = []\n",
      "for i,xs in ix2xs.items():\n",
      "    \n",
      "    tmp_xs = []\n",
      "    tmp_ys = []\n",
      "    tmp_ys_by_code = defaultdict(list)\n",
      "\n",
      "    # add BOW features\n",
      "    tmp_xs.extend(ix2vector[i])\n",
      "    \n",
      "    un_codes = set()\n",
      "    un_pred_codes = set()\n",
      "    s_codes = \"|\"\n",
      "    for code in all_codes:\n",
      "        cls = code2cls[code]\n",
      "        pred = cls.decision_function(xs)\n",
      "        # add min and max values\n",
      "        mx = max(pred)\n",
      "        mn = min(pred)\n",
      "        diff = mx - mn\n",
      "        yes_no = max(cls.predict(xs))\n",
      "        \n",
      "        tmp_xs.append(mx)\n",
      "        tmp_xs.append(mn)\n",
      "        #tmp_xs.append(diff)\n",
      "        tmp_xs.append(yes_no)\n",
      "        \n",
      "        y_val = max(ix2ys[i][code])\n",
      "        tmp_ys_by_code[code] = np.array([y_val])\n",
      "        if y_val > 0:\n",
      "            un_codes.add(code)\n",
      "\n",
      "        if yes_no > 0:\n",
      "            un_pred_codes.add(code)\n",
      "            s_codes += code + \"|\"\n",
      "    codes_per_row.append(un_pred_codes)\n",
      "    str_codes.append(s_codes)\n",
      "    \n",
      "    #add 2 way feature combos\n",
      "    for a in all_codes:\n",
      "        for b in all_codes:\n",
      "            if b < a:\n",
      "                if a in un_pred_codes and b in un_pred_codes:\n",
      "                    tmp_xs.append(1)\n",
      "                else:\n",
      "                    tmp_xs.append(0)\n",
      "            #if (\"|%s|%s|\" %(a,b)) in s_codes:\n",
      "            #    tmp_xs.append(1)\n",
      "            #else:\n",
      "            #    tmp_xs.append(0)            \n",
      "            \n",
      "    tmp_ys_by_code[CAUSAL_REL] = np.array([ 1 if \"Causer\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[RESULT_REL] = np.array([ 1 if \"Result\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[CAUSE_RESULT] = np.array([ 1 if (\"Result\" in un_codes and \"explicit\" in un_codes and \"Causer\" in un_codes) else 0 ])\n",
      "    \n",
      "    for k,v in tmp_ys_by_code.items():\n",
      "        tally[k][max(v)] += 1\n",
      "        \n",
      "    ix2newxs[i] = np.array([tmp_xs])\n",
      "    ix2newys[i] = tmp_ys_by_code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,s in enumerate(str_codes):\n",
      "    print str(i).ljust(5), s\n",
      "    if i > 20:\n",
      "        break\n",
      "print ix2newxs[15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     |50|\n",
        "1     |\n",
        "2     |\n",
        "3     |\n",
        "4     |\n",
        "5     |1|\n",
        "6     |\n",
        "7     |\n",
        "8     |\n",
        "9     |\n",
        "10    |\n",
        "11    |\n",
        "12    |\n",
        "13    |\n",
        "14    |\n",
        "15    |7|50|Causer|Result|explicit|\n",
        "16    |50|\n",
        "17    |1|\n",
        "18    |\n",
        "19    |\n",
        "20    |\n",
        "21    |\n",
        "[[ 0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.21876749  0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.14200647  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.20893406  0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.32235263  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.30627657  0.37960612  0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.39641752  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.14907714  0.          0.\n",
        "   0.          0.          0.          0.          0.          0.23265734\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.09796123  0.27227363  0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.15149861\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.35695694  0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.28089935\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.         -1.607557   -3.78311934  0.         -1.89327286 -3.2280134\n",
        "   0.         -1.97324353 -4.29395721  0.         -1.32370628 -2.91728247\n",
        "   0.         -2.06326891 -4.32082896  0.         -1.51309645 -3.34918239\n",
        "   0.          2.54530047 -3.76666809  1.         -1.376584   -2.57434541\n",
        "   0.         -1.30951424 -2.3779126   0.         -1.84973497 -3.41547667\n",
        "   0.         -1.48041572 -2.64712694  0.          1.47445695 -3.82905318\n",
        "   1.         -1.72620069 -3.24943188  0.         -1.43174936 -1.81499119\n",
        "   0.         -0.98062367 -2.82155951  0.          2.22388238 -4.16085729\n",
        "   1.          1.93985936 -3.26953477  1.         -1.1023663  -2.74751965\n",
        "   0.          2.74052041 -3.87392902  1.         -0.90956732 -2.82833001\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          1.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          1.          0.          0.          0.          0.          1.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          1.          0.          0.          0.          0.          1.\n",
        "   0.          1.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          1.          0.          0.          0.          0.          1.\n",
        "   0.          1.          1.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_plus_cr = all_codes + cr_codes\n",
      "newx_t, yByCode_t = extract_xs_ys(ixtest, ix2newxs, ix2newys, all_plus_cr)\n",
      "print newx_t[0].shape, \"features\"\n",
      "\n",
      "# SVM Is best when using joint features\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, sklearn.ensemble.GradientBoostingClassifier)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LDA)\n",
      "new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LinearSVC)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LogisticRegression)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, DecisionTreeClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(250,) features\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct = {}\n",
      "codes = cr_codes + [\"explicit\"] #[CAUSE_RESULT]\n",
      "for c in [1.0, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5]:\n",
      "    print \"C\", c\n",
      "    new_code2cls = train(codes, newx_t, yByCode_t, lambda : LinearSVC(C = float(c)))\n",
      "    dct[c] = test(codes, ixvalid, ix2newxs, ix2newys, new_code2cls)\n",
      "\n",
      "print \"\"\n",
      "for k,v in sorted(dct.items()):\n",
      "    print \"C\", str(k).ljust(5), \"Metric:\",v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C 1.0\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:       CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.634146341463\n",
        "f1:         0.645962732919\n",
        "accuracy:   0.787313432836\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.6875\n",
        "precision:  0.60773480663\n",
        "f1:         0.645161290323\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.677215189873\n",
        "precision:  0.694805194805\n",
        "f1:         0.685897435897\n",
        "accuracy:   0.817164179104\n",
        "sentences:  158\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.683229813665\n",
        "precision:  0.601092896175\n",
        "f1:         0.639534883721\n",
        "accuracy:   0.768656716418\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6766, Precision: 0.6342, F1: 0.6540, Accuracy: 0.7867, Codes:   637\n",
        "C 1.5\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.634146341463\n",
        "f1:         0.645962732919\n",
        "accuracy:   0.787313432836\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.69375\n",
        "precision:  0.606557377049\n",
        "f1:         0.6472303207\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.683544303797\n",
        "precision:  0.687898089172\n",
        "f1:         0.685714285714\n",
        "accuracy:   0.815298507463\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.689440993789\n",
        "precision:  0.603260869565\n",
        "f1:         0.64347826087\n",
        "accuracy:   0.77052238806\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6813, Precision: 0.6327, F1: 0.6555, Accuracy: 0.7867, Codes:   637\n",
        "C 1.6\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.664556962025\n",
        "precision:  0.636363636364\n",
        "f1:         0.650154798762\n",
        "accuracy:   0.789179104478\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.7125\n",
        "precision:  0.606382978723\n",
        "f1:         0.655172413793\n",
        "accuracy:   0.776119402985\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.694267515924\n",
        "f1:         0.692063492063\n",
        "accuracy:   0.819029850746\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6907, Precision: 0.6354, F1: 0.6611, Accuracy: 0.7891, Codes:   637\n",
        "C 1.7\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.634146341463\n",
        "f1:         0.645962732919\n",
        "accuracy:   0.787313432836\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.7\n",
        "precision:  0.605405405405\n",
        "f1:         0.649275362319\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.694267515924\n",
        "f1:         0.692063492063\n",
        "accuracy:   0.819029850746\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6860, Precision: 0.6346, F1: 0.6586, Accuracy: 0.7881, Codes:   637\n",
        "C 1.8\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.634146341463\n",
        "f1:         0.645962732919\n",
        "accuracy:   0.787313432836\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.7\n",
        "precision:  0.608695652174\n",
        "f1:         0.651162790698\n",
        "accuracy:   0.776119402985\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.677215189873\n",
        "precision:  0.685897435897\n",
        "f1:         0.68152866242\n",
        "accuracy:   0.813432835821\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6829, Precision: 0.6333, F1: 0.6565, Accuracy: 0.7872, Codes:   637\n",
        "C 1.9\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.651898734177\n",
        "precision:  0.631901840491\n",
        "f1:         0.641744548287\n",
        "accuracy:   0.785447761194\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.725\n",
        "precision:  0.59793814433\n",
        "f1:         0.655367231638\n",
        "accuracy:   0.772388059701\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.68125\n",
        "f1:         0.685534591195\n",
        "accuracy:   0.813432835821\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6907, Precision: 0.6289, F1: 0.6575, Accuracy: 0.7858, Codes:   637\n",
        "C 2.0\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.664556962025\n",
        "precision:  0.632530120482\n",
        "f1:         0.648148148148\n",
        "accuracy:   0.787313432836\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.7\n",
        "precision:  0.602150537634\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.689873417722\n",
        "f1:         0.689873417722\n",
        "accuracy:   0.817164179104\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6876, Precision: 0.6323, F1: 0.6581, Accuracy: 0.7872, Codes:   637\n",
        "C 2.1\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.630303030303\n",
        "f1:         0.643962848297\n",
        "accuracy:   0.785447761194\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.725\n",
        "precision:  0.60103626943\n",
        "f1:         0.657223796034\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.68125\n",
        "f1:         0.685534591195\n",
        "accuracy:   0.813432835821\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6923, Precision: 0.6293, F1: 0.6585, Accuracy: 0.7863, Codes:   637\n",
        "C 2.2\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:       CRel\n",
        "recall:     0.670886075949\n",
        "precision:  0.634730538922\n",
        "f1:         0.652307692308\n",
        "accuracy:   0.789179104478\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.64375\n",
        "precision:  0.635802469136\n",
        "f1:         0.639751552795\n",
        "accuracy:   0.783582089552\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.685534591195\n",
        "f1:         0.687697160883\n",
        "accuracy:   0.815298507463\n",
        "sentences:  158\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.701863354037\n",
        "precision:  0.60752688172\n",
        "f1:         0.651296829971\n",
        "accuracy:   0.774253731343\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6766, Precision: 0.6407, F1: 0.6577, Accuracy: 0.7905, Codes:   637\n",
        "C 2.3\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.658227848101\n",
        "precision:  0.630303030303\n",
        "f1:         0.643962848297\n",
        "accuracy:   0.785447761194\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.7125\n",
        "precision:  0.603174603175\n",
        "f1:         0.65329512894\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.67701863354\n",
        "f1:         0.683385579937\n",
        "accuracy:   0.811567164179\n",
        "sentences:  158\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.701863354037\n",
        "precision:  0.60752688172\n",
        "f1:         0.651296829971\n",
        "accuracy:   0.774253731343\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6907, Precision: 0.6293, F1: 0.6579, Accuracy: 0.7863, Codes:   637\n",
        "C 2.4\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.677215189873\n",
        "precision:  0.636904761905\n",
        "f1:         0.656441717791\n",
        "accuracy:   0.791044776119\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.725\n",
        "precision:  0.607329842932\n",
        "f1:         0.660968660969\n",
        "accuracy:   0.777985074627\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.683544303797\n",
        "precision:  0.683544303797\n",
        "f1:         0.683544303797\n",
        "accuracy:   0.813432835821\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.695652173913\n",
        "precision:  0.605405405405\n",
        "f1:         0.647398843931\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6954, Precision: 0.6331, F1: 0.6620, Accuracy: 0.7886, Codes:   637\n",
        "C 2.5\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for : C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.677215189873\n",
        "precision:  0.636904761905\n",
        "f1:         0.656441717791\n",
        "accuracy:   0.791044776119\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.70625\n",
        "precision:  0.601063829787\n",
        "f1:         0.649425287356\n",
        "accuracy:   0.772388059701\n",
        "sentences:  160\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.689873417722\n",
        "precision:  0.685534591195\n",
        "f1:         0.687697160883\n",
        "accuracy:   0.815298507463\n",
        "sentences:  158\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.701863354037\n",
        "precision:  0.604278074866\n",
        "f1:         0.649425287356\n",
        "accuracy:   0.772388059701\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6939, Precision: 0.6317, F1: 0.6607, Accuracy: 0.7877, Codes:   637\n",
        "\n",
        "C 1.0   Metric: Recall: 0.6766, Precision: 0.6342, F1: 0.6540, Accuracy: 0.7867, Codes:   637\n",
        "C 1.5   Metric: Recall: 0.6813, Precision: 0.6327, F1: 0.6555, Accuracy: 0.7867, Codes:   637\n",
        "C 1.6   Metric: Recall: 0.6907, Precision: 0.6354, F1: 0.6611, Accuracy: 0.7891, Codes:   637\n",
        "C 1.7   Metric: Recall: 0.6860, Precision: 0.6346, F1: 0.6586, Accuracy: 0.7881, Codes:   637\n",
        "C 1.8   Metric: Recall: 0.6829, Precision: 0.6333, F1: 0.6565, Accuracy: 0.7872, Codes:   637\n",
        "C 1.9   Metric: Recall: 0.6907, Precision: 0.6289, F1: 0.6575, Accuracy: 0.7858, Codes:   637\n",
        "C 2.0   Metric: Recall: 0.6876, Precision: 0.6323, F1: 0.6581, Accuracy: 0.7872, Codes:   637\n",
        "C 2.1   Metric: Recall: 0.6923, Precision: 0.6293, F1: 0.6585, Accuracy: 0.7863, Codes:   637\n",
        "C 2.2   Metric: Recall: 0.6766, Precision: 0.6407, F1: 0.6577, Accuracy: 0.7905, Codes:   637\n",
        "C 2.3   Metric: Recall: 0.6907, Precision: 0.6293, F1: 0.6579, Accuracy: 0.7863, Codes:   637\n",
        "C 2.4   Metric: Recall: 0.6954, Precision: 0.6331, F1: 0.6620, Accuracy: 0.7886, Codes:   637\n",
        "C 2.5   Metric: Recall: 0.6939, Precision: 0.6317, F1: 0.6607, Accuracy: 0.7877, Codes:   637\n"
       ]
      }
     ],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Test Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixtest, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Data #2: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.943396226415\n",
        "precision:  0.961538461538\n",
        "f1:         0.952380952381\n",
        "accuracy:   0.981331673927\n",
        "sentences:  318\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.935384615385\n",
        "precision:  0.947040498442\n",
        "f1:         0.941176470588\n",
        "accuracy:   0.97635345364\n",
        "sentences:  325\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.938511326861\n",
        "precision:  0.935483870968\n",
        "f1:         0.936995153473\n",
        "accuracy:   0.975731176105\n",
        "sentences:  309\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.938775510204\n",
        "precision:  0.955489614243\n",
        "f1:         0.947058823529\n",
        "accuracy:   0.977598008712\n",
        "sentences:  343\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.9390, Precision: 0.9501, F1: 0.9445, Accuracy: 0.9778, Codes:  1295\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixvalid, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data #2: \n",
        "code:       CRel\n",
        "recall:     0.525316455696\n",
        "precision:  0.638461538462\n",
        "f1:         0.576388888889\n",
        "accuracy:   0.772388059701\n",
        "sentences:  158\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.5625\n",
        "precision:  0.63829787234\n",
        "f1:         0.598006644518\n",
        "accuracy:   0.774253731343\n",
        "sentences:  160\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.537974683544\n",
        "precision:  0.6640625\n",
        "f1:         0.594405594406\n",
        "accuracy:   0.783582089552\n",
        "sentences:  158\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.639751552795\n",
        "precision:  0.639751552795\n",
        "f1:         0.639751552795\n",
        "accuracy:   0.783582089552\n",
        "sentences:  161\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.5667, Precision: 0.6451, F1: 0.6023, Accuracy: 0.7785, Codes:   637\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Using Min\\Max Distance from Decision Plane\n",
      "  Single Features\n",
      "***\n",
      "<class 'LDA'> Recall: 0.6797, Precision: 0.6151, F1: 0.6458, Accuracy: 0.7784, Codes:   637\n",
      "***\n",
      "<class 'LinearSVC'> Recall: 0.6562, Precision: 0.6069, F1: 0.6297, Accuracy: 0.7704, Codes:   637\n",
      "<class 'logistic.LogisticRegression'> Recall: 0.6578, Precision: 0.6207, F1: 0.6379, Accuracy: 0.7784, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6185, Precision: 0.6458, F1: 0.6288, Accuracy: 0.7835, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5950, Precision: 0.6334, F1: 0.6118, Accuracy: 0.7755, Codes:   637\n",
      "    \n",
      "  Joint Features\n",
      "<class 'sklearn.lda.LDA'> Recall: 0.5667, Precision: 0.6260, F1: 0.5934, Accuracy: 0.7700, Codes:   637\n",
      "***\n",
      "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6703, Precision: 0.6323, F1: 0.6502, Accuracy: 0.7853, Codes:   637\n",
      "***\n",
      "code:       C->R\n",
      "recall:     0.677215189873\n",
      "precision:  0.685897435897\n",
      "f1:         0.68152866242\n",
      "accuracy:   0.813432835821\n",
      "sentences:  158\n",
      "<class 'LogisticRegression'> Recall: 0.6342, Precision: 0.6539, F1: 0.6424, Accuracy: 0.7900, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6075, Precision: 0.6396, F1: 0.6196, Accuracy: 0.7793, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5651, Precision: 0.6236, F1: 0.5896, Accuracy: 0.7672, Codes:   637"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*** TODO *** - Peter\\Simon 5.14.2014\n",
      "Match Explicit + Cause or Result (or both)\n",
      "Try reading this: http://ceur-ws.org/Vol-1109/paper4.pdf\n",
      "Read Peter's paper\n",
      "\n",
      "1. <s>Try removing commas and '\"''s and other punctuation</s>\n",
      "2. <s>Try skip gram features (Peter)</s>\n",
      "3. Dependency parse \n",
      "    - span of words for the explicit and the concept\n",
      "    - find any depencencies tha join those two groups\n",
      "    - dependency type\n",
      "        - NSUBJ or PREP_TO or CONJ_AND\n",
      "        - OR advmod, conj_and, dobj, prep_of, prep_in\n",
      "        - OR acomp,  advmod\n",
      "4. <s>Read Peter's latest paper </s>\n",
      "5. Read related papers - Semeval 2007 (or close), Rink et al, Girju et al, etc\n",
      "5. <s>Try training a second classifier based on the output of the first including the predictions for the previous and next word</s>\n",
      "6. Add in sentence level features, such as BOW and dependency parse features\n",
      "7. Do some cross validation\n",
      "8. Add in predicted codes from previous \\ next sentence\n",
      "\"\"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}