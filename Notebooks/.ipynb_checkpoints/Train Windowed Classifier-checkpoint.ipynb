{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train a Window Based Classier on the Coral Bleaching Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup:\n",
      "------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Imports \"\"\"\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "from gensim import matutils\n",
      "from numpy import random\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from Metrics import rpf1a\n",
      "from Rpfa import rpfa\n",
      "from Essay import essay_loader\n",
      "from WindowSplitter import split_into_windows\n",
      "from WindowFeatures import extract_positional_word_features, extract_word_features\n",
      "from IdGenerator import IdGenerator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Settings \"\"\"\n",
      "\"\"\" Start Script \"\"\"\n",
      "WINDOW_SIZE = 5\n",
      "MID_IX = int(round(WINDOW_SIZE / 2.0) - 1)\n",
      "\n",
      "MIN_SENTENCE_FREQ = 5\n",
      "PCT_VALIDATION  = 0.2\n",
      "\n",
      "SENTENCE_START = \"<START>\"\n",
      "SENTENCE_END   = \"<END>\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Essays\n",
      "---------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\" Load Essays \"\"\"\n",
      "\n",
      "essays = essay_loader()\n",
      "wd_sent_freq = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        wds = zip(*sentence)[0]\n",
      "        for w in set(wds):\n",
      "            wd_sent_freq[w] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Results Dir: /Users/simon.hughes/Dropbox/Phd/Results/\n",
        "Data Dir:    /Users/simon.hughes/Dropbox/Phd/Data/\n",
        "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
        "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
        "105 files found\n",
        "Processing Essay: EBA1_PRE_CB_Baldwin_9_2_essay_03464_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Baldwin_9_2_Essays_02770_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Baldwin_9_2_Essays_03466_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Baldwin_9_2_Essays_03468_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_4_essay_03808_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_4_Essay_03810_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_4_Essay_03811_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_4_Essay_03812_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_4_essays_3826_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_5_Essay_03801_F.xml\n",
        "Processing Essay: EBA1_Pre_CB_Letizia_7_5_Essay_03803_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_5_essay_03807_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Letizia_7_5_Essay_03830_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_1_essay_03490_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_1_Essays_03489_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_1_Essays_03494_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_1_Essays_03495_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_1_Essays_03496_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_2_essay_3509_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_2_essay_3515_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_2_Essays_03513_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_2_Essays_03516_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_McIntyre_6_2_Essays_03517_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_essay_03280_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_essay_3291_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03278_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03279_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03282_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03283_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03286_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03287_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03288_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03296_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03298_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_316_Essays_03299_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_essay_03235_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_essay_03248_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_essay_03253_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_essay_03256_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_essay_03258_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03237_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03240_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03244_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03245_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03247_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03252_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_317_Essays_03257_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_essay_03300_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_essay_03302_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03301_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03303_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03305_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03308_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03310_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03311_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03312_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarb_6_321_Essays_03313_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_5_essay_03339_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_5_essay_03342_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_5_essay_03348_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_5_Essays_03344_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_5_Essays_03345_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_essay_03363_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03355_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03356_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03357_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03358_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03359_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03360_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sarna_9_7_Essays_03362_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_3_7_essay_03434_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03399_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_essay_03400_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03402_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03405_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_essay_03406_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03407_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03409_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03410_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03412_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_2_Essay_03415_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_3_Essay_03418_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_3_Essay_03426_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_3_Essay_03428_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_3_essay_03429_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03377_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_Essay_03378_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03380_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03382_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_Essay_03383_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03385_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03388_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_Essay_03391_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_essay_03394_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Sjoholm_7_4_Essay_03396_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_essay_03444_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_essay_03451_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_essay_03487_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03448_F.xml"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03452_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03453_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03456_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03458_F.xml\n",
        "Processing Essay: EBA1_PRE_CB_Stites_11_2_Essays_03459_F.xml\n",
        "Processing Essay: EBA1_Pre_CB_Stites_11_8_Essays_03442_F.xml\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Windows\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Creating Windows \"\"\"\n",
      "\n",
      "def filter2min_word_freq(sentence):\n",
      "    return filter(lambda (w, tags4word): wd_sent_freq[w] >= MIN_SENTENCE_FREQ, sentence)\n",
      "    \n",
      "def bracket_sentence(sentence):\n",
      "    # pad the start so features before the target word\n",
      "    # also ensure that sentence is at least window size long\n",
      "    for i in range(MID_IX):\n",
      "        sentence.insert(0, (SENTENCE_START,    set()))\n",
      "        sentence.append(   (SENTENCE_END,      set()))\n",
      "\n",
      "def assert_window_lengths(windows):\n",
      "    lens = map(len, windows)\n",
      "    assert min(lens) == max(lens) == WINDOW_SIZE, \"Windows are not all the correct size\"\n",
      "\n",
      "def add_words_tags(sentence):\n",
      "    for wd, tags4word in sentence:\n",
      "        all_wds.add(wd)\n",
      "        if len(tags4word) > 0:\n",
      "            all_codes.update(tags4word)\n",
      "\n",
      "all_wds = set([SENTENCE_START, SENTENCE_END])\n",
      "all_codes = set()\n",
      "windows = []\n",
      "\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        add_words_tags(sentence)\n",
      "        modified_sentence = filter2min_word_freq(sentence)\n",
      "        if len(modified_sentence) == 0:\n",
      "            continue\n",
      "        \n",
      "        bracket_sentence(modified_sentence)\n",
      "        new_windows = split_into_windows(modified_sentence, window_size= WINDOW_SIZE)\n",
      "        \n",
      "        assert_window_lengths(new_windows)\n",
      "        windows.extend(new_windows)\n",
      "\n",
      "\"\"\" Assert tags set correctly \"\"\"\n",
      "assert all(map(lambda win: all(map(lambda (wd, tags): len(tags) <=1, win)), windows)), \"More than one tag per word\"\n",
      "print \"Tags set correctly!\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tags set correctly!\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract Features\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract Features \"\"\"\n",
      "def extract_tags(window):\n",
      "    target_wd, tags = window[MID_IX]\n",
      "    return tags\n",
      "\n",
      "idgen = IdGenerator()\n",
      "ysByCode = defaultdict(list)\n",
      "xs = []\n",
      "\n",
      "for window in windows:\n",
      "    # Get the words minus tags\n",
      "    words, _ = zip(*window)\n",
      "\n",
      "    #Extract features for words\n",
      "    features = extract_positional_word_features(words, MID_IX, feature_val=1)\n",
      "    word_features = extract_word_features(words, feature_val=1)\n",
      "    #Merge\n",
      "    features.update(word_features)\n",
      "\n",
      "    #Tags for middle word (target)\n",
      "    tags4word = extract_tags(window)\n",
      "\n",
      "    x = [ (idgen.get_id(feat), val) for feat, val in features.items()]\n",
      "    xs.append(x)\n",
      "\n",
      "    for code in all_codes:\n",
      "        ysByCode[code].append(1 if code in tags4word else 0 )\n",
      "\n",
      "\"\"\" Make numpy arrays \"\"\"\n",
      "num_features = idgen.max_id() + 1\n",
      "\n",
      "\"\"\" Sparse to full \"\"\"\n",
      "xs = [matutils.sparse2full(x, num_features) for x in xs]\n",
      "xs = np.asarray(xs)\n",
      "\n",
      "for k, v in ysByCode.items():\n",
      "    ysByCode[k] = np.asarray(v)\n",
      "\n",
      "print \"Number of windows: \", len(xs)\n",
      "print \"Number of features:\", num_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of windows:  14764\n",
        "Number of features: 2469\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Assert ys set correctly \"\"\"\n",
      "assert all(map(lambda ys: len(ys) == len(xs), ysByCode.values()))\n",
      "print \"Passed. All ys are the right length\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Passed. All ys are the right length\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_window(win):\n",
      "    def set2str(st):\n",
      "        return \"{\" + str(t)[5:-2] + \"}\"\n",
      "    \n",
      "    w, tg = zip(*win)\n",
      "    lens = [max(len(wd),len(set2str(t))) for wd,t in win]\n",
      "    \n",
      "    for i, wd in enumerate(w):\n",
      "        print wd.ljust(lens[i]) , \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "    for i, t in enumerate(tg):\n",
      "        print set2str(t).ljust(lens[i]), \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "def extract_features(window, feat_vals):\n",
      "    ix = 100\n",
      "    feats = [idgen.get_key(w) for w,v in feat_vals]\n",
      "    \n",
      "    wd_feats = []\n",
      "    for win in window:\n",
      "        wd, tgs = win\n",
      "        match = filter(lambda k: wd in k, feats)\n",
      "        wd_feats.append((wd, match))\n",
      "    return wd_feats\n",
      "\n",
      "def print_features(wf):\n",
      "    w_f = wf\n",
      "    for w,ft in w_f:\n",
      "        print w.ljust(10), sorted(ft, key=lambda s:len(s))\n",
      "    print \"\"\n",
      "\n",
      "print \"Tagged Windows\"\n",
      "for i in range(100,106,1):\n",
      "    print_window(windows[i])\n",
      "print \"\"    \n",
      "\n",
      "print \"Features\"\n",
      "ix - 100\n",
      "wf = extract_features(windows[ix], xs[ix])\n",
      "print_features(wf)\n",
      "\n",
      "ix = 200\n",
      "wf = extract_features(windows[ix], xs[ix])\n",
      "print_features(wf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tagged Windows\n",
        "is | called | coral  | bleaching | ,      | \n",
        "{} | {}     | {'50'} | {'50'}    | {'50'} | \n",
        "called | coral  | bleaching | ,      | and | \n",
        "{}     | {'50'} | {'50'}    | {'50'} | {}  | \n",
        "coral  | bleaching | ,      | and | coral  | \n",
        "{'50'} | {'50'}    | {'50'} | {}  | {'50'} | \n",
        "bleaching | ,      | and | coral  | bleaching | \n",
        "{'50'}    | {'50'} | {}  | {'50'} | {'50'}    | \n",
        ",      | and | coral  | bleaching | happens | \n",
        "{'50'} | {}  | {'50'} | {'50'}    | {}      | \n",
        "and | coral  | bleaching | happens | most | \n",
        "{}  | {'50'} | {'50'}    | {}      | {}   | \n",
        "\n",
        "Features\n",
        "<START>    ['<START>', 'WD:-2 <START>']\n",
        "the        ['the', 'WD:-1 the']\n",
        "coral      ['coral', 'WD:0 coral']\n",
        "polyps     ['polyps', 'WD:1 polyps']\n",
        "give       ['give', 'WD:2 give']\n",
        "\n",
        "<START>    ['<START>', 'WD:-2 <START>']\n",
        "the        ['the', 'WD:-1 the']\n",
        "coral      ['coral', 'WD:0 coral']\n",
        "polyps     ['polyps', 'WD:1 polyps']\n",
        "give       ['give', 'WD:2 give']\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    }
   ],
   "metadata": {}
  }
 ]
}