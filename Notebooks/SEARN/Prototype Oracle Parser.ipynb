{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack(object):\n",
    "    def __init__(self, verbose=False):    \n",
    "        self.stack = []\n",
    "        self.verbose = verbose\n",
    "    def tos(self):\n",
    "        if self.len() == 0:\n",
    "            return None\n",
    "        #assert self.len() > 0, \"Can't peek when stack is empty\"\n",
    "        return self.stack[-1]\n",
    "    def pop(self):\n",
    "        assert self.len() > 0, \"Can't pop when stack is empty\"\n",
    "        item = self.stack.pop()\n",
    "        if self.verbose:\n",
    "            print(\"POPPING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "        return item\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "        if self.verbose:\n",
    "            print(\"PUSHING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "    def len(self):\n",
    "        return len(self.stack)\n",
    "    def __repr__(self):\n",
    "        return \"|\".join(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = \"root\"\n",
    "\n",
    "def norm_arc(arc):\n",
    "    return tuple(sorted(arc))\n",
    "\n",
    "def norm_arcs(arcs):\n",
    "    return set(map(norm_arc, arcs))\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self, stack):\n",
    "        self.stack = stack\n",
    "        self.arcs = []\n",
    "        self.normed_arcs = set()\n",
    "        # nodes with heads\n",
    "        self.children = set()\n",
    "        self.actions = []\n",
    "        \n",
    "    def get_dependencies(self):\n",
    "        return [(l,r) for (l,r) in self.arcs if r != ROOT and l != ROOT]\n",
    "        \n",
    "    def left_arc(self, buffer):\n",
    "        tos = self.stack.pop()\n",
    "        arc = (tos,buffer)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(arc)\n",
    "        self.children.add(tos)\n",
    "        self.actions.append(\"L ARC   : \" + tos + \"->\" + buffer)\n",
    "        \n",
    "    def right_arc(self, buffer):\n",
    "        tos = self.stack.tos()\n",
    "        #normalize arc\n",
    "        arc = (buffer,tos)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(n_arc)\n",
    "        self.actions.append(\"R ARC   : \" + tos + \"<-\" + buffer)\n",
    "        self.children.add(buffer)\n",
    "        self.stack.push(buffer)\n",
    "        \n",
    "    def reduce(self):\n",
    "        tos = self.stack.pop()\n",
    "        self.actions.append(\"REDUCE  : Pop  %s\" % tos)\n",
    "        \n",
    "    def shift(self, buffer):\n",
    "        self.stack.push(buffer)\n",
    "        self.actions.append(\"SHIFT   : Push %s\" % buffer)\n",
    "        \n",
    "    def has_head(self, item):\n",
    "        return item in self.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def build_mappings_directional(pairs):\n",
    "    causers = defaultdict(set)\n",
    "    results = defaultdict(set)\n",
    "    for c,res in pairs:\n",
    "        causers[c].add(res)\n",
    "        results[res].add(c)\n",
    "    return causers, results\n",
    "\n",
    "def build_mappings(pairs):\n",
    "    mapping = defaultdict(set)\n",
    "    for c,res in pairs:\n",
    "        mapping[c].add(res)\n",
    "        mapping[res].add(c)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHIFT = \"Shift\"\n",
    "REDUCE = \"Reduce\"\n",
    "LARC = \"LArc\"\n",
    "RARC = \"Rarc\"\n",
    "\n",
    "class Oracle(object):    \n",
    "    def __init__(self, crels, parser):\n",
    "        self.crels = crels\n",
    "        self.parser = parser\n",
    "        self.mapping = self.build_mappings(crels)\n",
    "    \n",
    "    def build_mappings(self, pairs):\n",
    "        mapping = defaultdict(set)\n",
    "        for c,res in pairs:\n",
    "            mapping[c].add(res)\n",
    "            mapping[res].add(c)\n",
    "        return mapping\n",
    "\n",
    "    def cont(self, action):\n",
    "        if action in (SHIFT,RARC):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def remove_relation(self, a,b):\n",
    "        self.mapping[a].remove(b)\n",
    "        if len(self.mapping[a]) == 0:\n",
    "            del self.mapping[a]\n",
    "        self.mapping[b].remove(a)\n",
    "        if len(self.mapping[b]) == 0:\n",
    "            del self.mapping[b]\n",
    "    \n",
    "    def consult(self, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        action = None\n",
    "        parser = self.parser\n",
    "        \n",
    "        if tos == ROOT:\n",
    "            if buffer not in self.mapping:\n",
    "                # map to root\n",
    "                parser.right_arc(buffer)\n",
    "                #then reduce?\n",
    "                return self.cont(RARC)\n",
    "            else:\n",
    "                parser.shift(buffer)\n",
    "                return self.cont(SHIFT)\n",
    "            \n",
    "        if (tos,buffer) in self.crels:\n",
    "            # no other relations then discard\n",
    "            if len(self.mapping[tos]) == 1:\n",
    "                #LEFT ARC (tos not root, and tos not have a head)\n",
    "                assert not parser.has_head(tos),  \"%s already has a head\"\n",
    "                # tos is child of head code\n",
    "                parser.left_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(LARC)\n",
    "            else:\n",
    "                parser.right_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(RARC)\n",
    "        elif (buffer, tos) in self.crels:        \n",
    "            parser.right_arc(buffer)  \n",
    "            self.remove_relation(tos, buffer)\n",
    "            return self.cont(RARC)\n",
    "        else:\n",
    "            if tos not in self.mapping:\n",
    "                parser.reduce()\n",
    "                return self.cont(REDUCE)\n",
    "            elif parser.has_head(stack.tos()) and stack.len() > 1:\n",
    "                parser.reduce()\n",
    "                return self.cont(REDUCE)\n",
    "            else:\n",
    "                parser.shift(buffer)\n",
    "                return self.cont(SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'B')\n",
      "\t('A', 'C')\n",
      "\t('D', 'A')\n",
      "\n",
      "---------------------------------\n",
      "A\n",
      "---------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "---------------------------------\n",
      "B\n",
      "---------------------------------\n",
      "R ARC   : A<-B       || STACK : root|A|B\n",
      "---------------------------------\n",
      "C\n",
      "---------------------------------\n",
      "REDUCE  : Pop  B     || STACK : root|A\n",
      "R ARC   : A<-C       || STACK : root|A|C\n",
      "---------------------------------\n",
      "D\n",
      "---------------------------------\n",
      "REDUCE  : Pop  C     || STACK : root|A\n",
      "R ARC   : A<-D       || STACK : root|A|D\n",
      "\n",
      "*********************************\n",
      "Stack\n",
      "\troot|A|D\n",
      "DEPS Actual\n",
      "\t('A', 'B')\n",
      "\t('A', 'C')\n",
      "\t('D', 'A')\n",
      "DEPS Pred\n",
      "\t('B', 'A')\n",
      "\t('C', 'A')\n",
      "\t('D', 'A')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tR ARC   : A<-B\n",
      "\tREDUCE  : Pop  B\n",
      "\tR ARC   : A<-C\n",
      "\tREDUCE  : Pop  C\n",
      "\tR ARC   : A<-D\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? True\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#INPUTS\n",
    "###################\n",
    "codes = \"ABCD\"\n",
    "crels = set([\n",
    "    (\"A\",\"B\"),\n",
    "    (\"A\",\"C\"),\n",
    "    (\"D\",\"A\"),\n",
    "    #(\"C\",\"B\"),\n",
    "    #(\"C\",\"D\")\n",
    "])\n",
    "\n",
    "###################\n",
    "\n",
    "stack = Stack(False)\n",
    "stack.push(ROOT)\n",
    "parser = Parser(stack)\n",
    "oracle = Oracle(crels, parser)\n",
    "\n",
    "print(\"DEPS\")\n",
    "for crel in sorted(crels):\n",
    "    print(\"\\t\" + str(crel))\n",
    "print()\n",
    "\n",
    "PAD = 20\n",
    "LINE = PAD + len(ROOT) + 2 * len(codes) + 1\n",
    "\n",
    "for buffer in list(codes):\n",
    "    print(\"-\" * LINE)\n",
    "    print(buffer)\n",
    "    print(\"-\" * LINE)\n",
    "        \n",
    "    while True:\n",
    "        tos = stack.tos()\n",
    "        if not oracle.consult(tos, buffer):\n",
    "            print(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "            break\n",
    "\n",
    "        print(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "        if stack.len() == 0:\n",
    "            print(\"Empty stack, stopping\")\n",
    "            break\n",
    "    #print(\"\\t\" + str(sorted(parser.arcs, reverse=True, key=lambda arc: (arc[1],arc[0]))))\n",
    "\n",
    "print()\n",
    "print(\"*\" * LINE)\n",
    "print(\"Stack\")\n",
    "print(\"\\t\" + str(stack))\n",
    "deps = parser.get_dependencies()\n",
    "print(\"DEPS Actual\")\n",
    "for crel in sorted(crels):\n",
    "    print(\"\\t\" + str(crel))\n",
    "print(\"DEPS Pred\")\n",
    "for dep in sorted(deps):\n",
    "    print(\"\\t\" + str(dep))\n",
    "print(\"Actions\")\n",
    "for a in parser.actions:\n",
    "    print(\"\\t\" + a)\n",
    "print()\n",
    "print(\"Ordered Match?    \" + str(set(deps) == crels))\n",
    "print(\"Un Ordered Match? \" + str(norm_arcs(deps) == norm_arcs(crels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
