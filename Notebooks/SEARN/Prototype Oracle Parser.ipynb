{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack(object):\n",
    "    def __init__(self, verbose=False):    \n",
    "        self.stack = []\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def tos(self):\n",
    "        if self.len() == 0:\n",
    "            return None\n",
    "        #assert self.len() > 0, \"Can't peek when stack is empty\"\n",
    "        return self.stack[-1]\n",
    "    \n",
    "    def pop(self):\n",
    "        assert self.len() > 0, \"Can't pop when stack is empty\"\n",
    "        item = self.stack.pop()\n",
    "        if self.verbose:\n",
    "            print(\"POPPING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "        return item\n",
    "    \n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "        if self.verbose:\n",
    "            print(\"PUSHING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.stack)\n",
    "\n",
    "    def contains(self, item):\n",
    "        return item in self.stack\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"|\".join(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = \"root\"\n",
    "\n",
    "def norm_arc(arc):\n",
    "    return tuple(sorted(arc))\n",
    "\n",
    "def norm_arcs(arcs):\n",
    "    return set(map(norm_arc, arcs))\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self, stack):\n",
    "        self.stack = stack\n",
    "        self.arcs = []\n",
    "        self.normed_arcs = set()\n",
    "        # nodes with heads\n",
    "        self.children = set()\n",
    "        self.actions = []\n",
    "        \n",
    "    def get_dependencies(self):\n",
    "        return [(l,r) for (l,r) in self.arcs if r != ROOT and l != ROOT]\n",
    "        \n",
    "    def left_arc(self, buffer):\n",
    "        tos = self.stack.pop()\n",
    "        arc = (tos,buffer)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(arc)\n",
    "        self.children.add(tos)\n",
    "        self.actions.append(\"L ARC   : \" + tos + \"->\" + buffer)\n",
    "        \n",
    "    def right_arc(self, buffer):\n",
    "        tos = self.stack.tos()\n",
    "        #normalize arc\n",
    "        arc = (buffer,tos)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(n_arc)\n",
    "        self.actions.append(\"R ARC   : \" + tos + \"<-\" + buffer)\n",
    "        self.children.add(buffer)\n",
    "        self.stack.push(buffer)\n",
    "        \n",
    "    def reduce(self):\n",
    "        tos = self.stack.pop()\n",
    "        self.actions.append(\"REDUCE  : Pop  %s\" % tos)\n",
    "        \n",
    "    def shift(self, buffer):\n",
    "        self.stack.push(buffer)\n",
    "        self.actions.append(\"SHIFT   : Push %s\" % buffer)\n",
    "        \n",
    "    def has_head(self, item):\n",
    "        return item in self.children\n",
    "    \n",
    "    def in_stack(self, item):\n",
    "        return self.stack.contains(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SHIFT = \"Shift\"\n",
    "REDUCE = \"Reduce\"\n",
    "LARC = \"LArc\"\n",
    "RARC = \"Rarc\"\n",
    "\n",
    "class Oracle(object):    \n",
    "    def __init__(self, crels, parser):\n",
    "        self.crels = crels\n",
    "        self.parser = parser\n",
    "        self.mapping = self.build_mappings(crels)\n",
    "    \n",
    "    def build_mappings(self, pairs):\n",
    "        mapping = defaultdict(set)\n",
    "        for c,res in pairs:\n",
    "            mapping[c].add(res)\n",
    "            mapping[res].add(c)\n",
    "        return mapping\n",
    "\n",
    "    def cont(self, action):\n",
    "        if action in (SHIFT,RARC):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def remove_relation(self, a,b):\n",
    "        self.mapping[a].remove(b)\n",
    "        if len(self.mapping[a]) == 0:\n",
    "            del self.mapping[a]\n",
    "        self.mapping[b].remove(a)\n",
    "        if len(self.mapping[b]) == 0:\n",
    "            del self.mapping[b]\n",
    "    \n",
    "    def consult(self, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        action = None\n",
    "        parser = self.parser\n",
    "        \n",
    "        if tos == ROOT:\n",
    "            if buffer not in self.mapping:\n",
    "                # map to root\n",
    "                parser.right_arc(buffer)\n",
    "                #then reduce?\n",
    "                return self.cont(RARC)\n",
    "            else:\n",
    "                parser.shift(buffer)\n",
    "                return self.cont(SHIFT)\n",
    "            \n",
    "        if (tos,buffer) in self.crels:\n",
    "            # no other relations then discard\n",
    "            if len(self.mapping[tos]) == 1:\n",
    "                #LEFT ARC (tos not root, and tos not have a head)\n",
    "                assert not parser.has_head(tos),  \"%s already has a head #1\" % tos\n",
    "                # tos is child of head code\n",
    "                parser.left_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(LARC)\n",
    "            else:\n",
    "                parser.right_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(RARC)\n",
    "        elif (buffer, tos) in self.crels:\n",
    "            # if the buffer has multiple relations, and one or more in in the stack, we need a left arc\n",
    "            if len(self.mapping[buffer]) > 1:\n",
    "                for item in self.mapping[buffer]:\n",
    "                    if item == tos:\n",
    "                        continue\n",
    "                    if self.parser.in_stack(item):\n",
    "                        assert not parser.has_head(tos),  \"%s already has a head #2\" % tos\n",
    "                        parser.left_arc(buffer)\n",
    "                        self.remove_relation(tos, buffer)\n",
    "                        return self.cont(LARC)\n",
    "            \n",
    "            parser.right_arc(buffer)  \n",
    "            self.remove_relation(tos, buffer)\n",
    "            return self.cont(RARC)\n",
    "        else:\n",
    "            if tos not in self.mapping:\n",
    "                parser.reduce()\n",
    "                return self.cont(REDUCE)\n",
    "            elif parser.has_head(stack.tos()):\n",
    "                parser.reduce()\n",
    "                return self.cont(REDUCE)\n",
    "            else:\n",
    "                parser.shift(buffer)\n",
    "                return self.cont(SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'D')\n",
      "\t('C', 'B')\n",
      "\t('D', 'C')\n",
      "\n",
      "---------------------------------\n",
      "A\n",
      "---------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "---------------------------------\n",
      "B\n",
      "---------------------------------\n",
      "SHIFT   : Push B     || STACK : root|A|B\n",
      "---------------------------------\n",
      "C\n",
      "---------------------------------\n",
      "R ARC   : B<-C       || STACK : root|A|B|C\n",
      "---------------------------------\n",
      "D\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "C already has a head #2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-92044269a128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" || STACK : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-32b157c9f5e3>\u001b[0m in \u001b[0;36mconsult\u001b[0;34m(self, tos, buffer)\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"%s already has a head #2\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: C already has a head #2"
     ]
    }
   ],
   "source": [
    "###################\n",
    "#INPUTS\n",
    "###################\n",
    "codes = \"ABCD\"\n",
    "crels = set([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"C\",\"B\"),\n",
    "    (\"D\",\"C\"),\n",
    "    #(\"A\",\"E\"),\n",
    "    #(\"E\",\"G\"),\n",
    "    #(\"G\",\"F\"),\n",
    "    #(\"D\",\"A\"),\n",
    "    #(\"C\",\"B\"),\n",
    "    #(\"C\",\"D\")\n",
    "])\n",
    "\n",
    "###################\n",
    "\n",
    "stack = Stack(False)\n",
    "stack.push(ROOT)\n",
    "parser = Parser(stack)\n",
    "oracle = Oracle(crels, parser)\n",
    "\n",
    "print(\"DEPS\")\n",
    "for crel in sorted(crels):\n",
    "    print(\"\\t\" + str(crel))\n",
    "print()\n",
    "\n",
    "PAD = 20\n",
    "LINE = PAD + len(ROOT) + 2 * len(codes) + 1\n",
    "\n",
    "for buffer in list(codes):\n",
    "    print(\"-\" * LINE)\n",
    "    print(buffer)\n",
    "    print(\"-\" * LINE)\n",
    "        \n",
    "    while True:\n",
    "        tos = stack.tos()\n",
    "        if not oracle.consult(tos, buffer):\n",
    "            print(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "            break\n",
    "\n",
    "        print(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "        if stack.len() == 0:\n",
    "            print(\"Empty stack, stopping\")\n",
    "            break\n",
    "\n",
    "print()\n",
    "print(\"*\" * LINE)\n",
    "print(\"Stack\")\n",
    "print(\"\\t\" + str(stack))\n",
    "deps = parser.get_dependencies()\n",
    "print(\"DEPS Actual\")\n",
    "for crel in sorted(crels):\n",
    "    print(\"\\t\" + str(crel))\n",
    "print(\"DEPS Pred\")\n",
    "for dep in sorted(deps):\n",
    "    print(\"\\t\" + str(dep))\n",
    "print(\"Actions\")\n",
    "for a in parser.actions:\n",
    "    print(\"\\t\" + a)\n",
    "print()\n",
    "print(\"Ordered Match?    \" + str(set(deps) == crels))\n",
    "\n",
    "ndeps = norm_arcs(deps)\n",
    "ncrels = norm_arcs(crels)\n",
    "diff = (ndeps - ncrels).union(ncrels - ndeps)\n",
    "print(\"Un Ordered Match? \" + str(len(diff) == 0))\n",
    "if diff:\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'C'), ('A', 'D'), ('A', 'E'), ('B', 'C'), ('E', 'G'), ('F', 'G')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'C'), ('A', 'D'), ('A', 'E'), ('B', 'C'), ('F', 'G')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'A': {'C', 'D', 'E'},\n",
       "             'B': {'C'},\n",
       "             'C': {'A', 'B'},\n",
       "             'D': {'A'},\n",
       "             'E': {'A', 'G'},\n",
       "             'F': {'G'},\n",
       "             'G': {'E', 'F'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Oracle(crels, None).build_mappings(crels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
