{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "1107 files found\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_BGJD_1_SC_ES-05728.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_BGJD_1_SC_ES-5726_9.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_KYLS_6_SC_ES-05674.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_LRJE_7_SC_ES-05142.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_RDCS_1_SC_ES-04696.ann file as .txt file is no essay//'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SVJJ_2_SC_ES-05617.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWAF_1_SC_ES-04832.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWAF_1_SC_ES-04834.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SWSP_1_SC_ES-04853.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SYMS_3_SC_ES-05900.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_SYMS_4_SC_ES-05980.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TFHC_1_SC_ES-05937.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TRDJ_11_SC_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TRKM_1_SC_ES-05026.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TTKP_4-5_SC_ES-04924.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWDG_11_SC_ES-05463.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWJB_7_SC_ES-05897.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_TWNB_2_SC_ES-04977.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/EBA1415_Merged/EBA1415_WSAL_2_SC_ES-05361.ann file as .txt file is no essay'\n",
      "1088 essays processed\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "essays = load_bratt_essays(settings.data_directory + \"SkinCancer/EBA1415_Merged/\")\n",
    "\n",
    "wd_sent_freq = defaultdict(int)\n",
    "all_codes = set()\n",
    "#Stores all words for the spelling corrector\n",
    "words = []\n",
    "all_sentences = []\n",
    "sentencesForCode = defaultdict(list)\n",
    "for essay in essays:\n",
    "    for sentence in essay.tagged_sentences:\n",
    "        wdsInSent = set()\n",
    "        codes4sentence = set()\n",
    "        sent = []\n",
    "        for w, tags in sentence:\n",
    "            words.append(w)\n",
    "            all_codes.update(tags)\n",
    "            codes4sentence.update(tags)\n",
    "            if w not in wdsInSent:\n",
    "                wdsInSent.add(w)\n",
    "                wd_sent_freq[w] += 1\n",
    "            sent.append(w)\n",
    "        all_sentences.append(sent)\n",
    "        for code in codes4sentence:\n",
    "            sentencesForCode[code].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stats over the Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd_counts = []\n",
    "sent_counts = []\n",
    "concept_codes = []\n",
    "cr_concept_codes = []\n",
    "sent_multi_word_tags = {}\n",
    "sent_codes = []\n",
    "num_sents = 0\n",
    "un_wd_counts = []\n",
    "for e_ix, essay in enumerate(essays):\n",
    "    wds = 0\n",
    "    un_words = set()\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        num_sents += 1\n",
    "        sent_tags = set()\n",
    "        for w, tags in sentence:\n",
    "            un_words.add(w)\n",
    "            wds += 1\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                sent_tags.update(ccodes)\n",
    "                concept_codes.append(ccodes)\n",
    "                if len(ccodes) > 1:\n",
    "                    sent_multi_word_tags[(e_ix, i)] = [(w,[tag for tag in t if tag[0].isdigit()]) for w,t in sentence]\n",
    "            cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            if cr_codes:\n",
    "                cr_concept_codes.append(cr_codes)\n",
    "        if len(sent_tags) > 0:\n",
    "            sent_codes.append(sent_tags)\n",
    "    un_wd_counts.append(len(un_words))\n",
    "    sent_counts.append(len(essay.tagged_sentences))\n",
    "    wd_counts.append(wds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Length Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 479 166.267463235 157.0 82.449645775\n",
      "1 36 9.80698529412 9.0 5.02616928448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.min(wd_counts), np.max(wd_counts), np.mean(wd_counts), np.median(wd_counts), np.std(wd_counts)\n",
    "print np.min(sent_counts), np.max(sent_counts), np.mean(sent_counts), np.median(sent_counts), np.std(sent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 215, 90.163602941176464, 88.0, 36.152364440875424)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(un_wd_counts), np.max(un_wd_counts), np.mean(un_wd_counts), np.median(un_wd_counts), np.std(un_wd_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '11', '12', '2', '3', '4', '5', '50', '6'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IterableFP import flatten\n",
    "unique = set(flatten(concept_codes))\n",
    "# should be 9\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43024 180899 0.24\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['6', '4'], ['6', '4']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(concept_codes), sum(wd_counts), round(len(concept_codes) / float(sum(wd_counts)),2)\n",
    "multiple = [tags for tags in concept_codes if len(tags) > 1]\n",
    "print len(multiple)\n",
    "multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
