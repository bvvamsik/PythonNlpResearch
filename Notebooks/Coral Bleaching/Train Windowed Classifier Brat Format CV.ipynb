{
 "metadata": {
  "name": "",
  "signature": "sha256:eea5a6fc8395920a5acd1b2f796ec7e78b71c277c989e83b1c6c196dea8d3c7c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train a Window Based Classier on the Coral Bleaching Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup:\n",
      "------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Imports \"\"\"\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "from gensim import matutils\n",
      "from numpy import random\n",
      "\n",
      "from Metrics import rpf1a\n",
      "from Rpfa import rpfa, weighted_mean_rpfa, mean_rpfa\n",
      "from BrattEssay import load_bratt_essays\n",
      "from WindowSplitter import split_into_windows\n",
      "\n",
      "from IdGenerator import IdGenerator\n",
      "from IterableFP import flatten\n",
      "\n",
      "from nltk import PorterStemmer\n",
      "from stanford_parser import parser\n",
      "\n",
      "\"\"\" TODO \n",
      "    Try dependency parse features from this python dependency parser: https://github.com/syllog1sm/redshift\n",
      "\"\"\"\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Settings \"\"\"\n",
      "\"\"\" Start Script \"\"\"\n",
      "WINDOW_SIZE = 7 #7 is best\n",
      "MID_IX = int(round(WINDOW_SIZE / 2.0) - 1)\n",
      "\n",
      "MIN_SENTENCE_FREQ = 2\n",
      "PCT_VALIDATION  = 0.2\n",
      "MIN_FEAT_FREQ = 5     #15 best so far\n",
      "PCT_VALIDATION = 0.25\n",
      "\n",
      "SENTENCE_START = \"<START>\"\n",
      "SENTENCE_END   = \"<END>\"\n",
      "STEM = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Essays\n",
      "---------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\" Load Essays \"\"\"\n",
      "essays = load_bratt_essays(\"/Users/simon.hughes/Dropbox/Phd/Data/CoralBleaching/BrattData/Merged/\")\n",
      "\n",
      "all_codes = set()\n",
      "all_words = []\n",
      "\n",
      "CAUSAL_REL = \"CRel\"\n",
      "RESULT_REL = \"RRel\"\n",
      "CAUSE_RESULT = \"C->R\"\n",
      "\n",
      "cr_codes = [CAUSAL_REL, RESULT_REL, CAUSE_RESULT]\n",
      "\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        for w, tags in sentence:\n",
      "            all_words.append(w)\n",
      "            all_codes.update(tags)\n",
      "                \n",
      "# Correct miss-spellings\n",
      "from SpellingCorrector import SpellingCorrector\n",
      "\n",
      "corrector = SpellingCorrector(all_words)\n",
      "corrections = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for i, sentence in enumerate(essay.tagged_sentences):\n",
      "        for j, (w, tags) in enumerate(sentence):\n",
      "            # common error is ..n't and ..nt\n",
      "            if w.endswith(\"n't\") or w.endswith(\"n'\"):\n",
      "                cw = w[:-3] + \"nt\"\n",
      "            elif w.endswith(\"'s\"):\n",
      "                cw = w[:-2]\n",
      "            elif w == \"&\":\n",
      "                cw = \"and\"\n",
      "            else:\n",
      "                cw = corrector.correct(w)\n",
      "            if cw != w:\n",
      "                corrections[(w,cw)] += 1\n",
      "                sentence[j] = (cw, tags)            \n",
      "            \n",
      "wd_sent_freq = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        wds, tag_list = zip(*sentence)\n",
      "        unique_wds = set(wds)\n",
      "        for w in unique_wds: \n",
      "            wd_sent_freq[w] += 1\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "236 files found\n",
        "236 essays processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Windows\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Creating Windows \"\"\"\n",
      "def filter2min_word_freq(sentence):\n",
      "    return filter(lambda (w, tags4word): wd_sent_freq[w] >= MIN_SENTENCE_FREQ, sentence)\n",
      "\n",
      "VALID_CHARS = {\".\", \"?\", \"!\", \"=\", \"/\", \":\", \";\", \"&\", \"+\",  \"-\", \"=\",  \"%\", \"'\", \",\", \"\\\\\", \"(\", \")\", \"\\\"\"}\n",
      "\"\"\" Remove bad chars (see above - e.g. '\\x93') \"\"\"\n",
      "removed = set()\n",
      "def valid_wd(wd):\n",
      "    wd = wd.strip()\n",
      "    if len(wd) != 1:\n",
      "        return True\n",
      "    if wd in removed:\n",
      "        return False\n",
      "    if wd.isalpha() or wd.isdigit() or wd in VALID_CHARS:\n",
      "        return True\n",
      "    removed.add(wd)\n",
      "    return False\n",
      "    \n",
      "def filterout_punctuation(sentence):\n",
      "    return filter(lambda (w, tags4word): valid_wd(w), sentence)\n",
      "\n",
      "def bookend(sentence):\n",
      "    for i in range(MID_IX):\n",
      "        modified_sentence.insert(0, (SENTENCE_START,    set()))\n",
      "        modified_sentence.append(   (SENTENCE_END,      set()))\n",
      "\n",
      "def assert_windows_correct(windows):\n",
      "    lens = map(len, windows)\n",
      "    assert min(lens) == max(lens) == WINDOW_SIZE, \\\n",
      "            \"Windows are not all the correct size\"\n",
      "   \n",
      "ix2windows = {}\n",
      "ix2sents = {}\n",
      "ix2sentTags = {}\n",
      "\n",
      "sentences = []\n",
      "tokenized_sentences = []\n",
      "\n",
      "i = 0\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        \n",
      "        modified_sentence = filter2min_word_freq(sentence)\n",
      "        modified_sentence = filterout_punctuation(modified_sentence)\n",
      "        if len(modified_sentence) == 0:\n",
      "            continue\n",
      "        \n",
      "        bookend(modified_sentence)        \n",
      "        new_windows = split_into_windows(modified_sentence, window_size= WINDOW_SIZE)        \n",
      "        assert_windows_correct(new_windows)       \n",
      "        \n",
      "        # tagged words\n",
      "        sentences.append(sentence)\n",
      "        # words only\n",
      "        wds, tags = zip(*sentence)\n",
      "        tokenized_sentences.append(wds)\n",
      "        ix2sentTags[i] = set(flatten(tags))\n",
      "    \n",
      "        ix2windows[i] = new_windows\n",
      "        ix2sents[i] = modified_sentence\n",
      "        i += 1\n",
      "        \n",
      "\"\"\" Assert tags set correctly \"\"\"\n",
      "print \"Windows loaded correctly!\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Windows loaded correctly!\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Removed Characters\n",
      "------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(sorted(removed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract Features\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract Features \"\"\"\n",
      "from WindowFeatures import extract_positional_word_features, extract_word_features\n",
      "from NgramGenerator import compute_ngrams\n",
      "\n",
      "def extract_positional_bigram_features(window, mid_ix, feature_val = 1):\n",
      "    bi_grams = compute_ngrams(window, max_len = 2, min_len = 2)\n",
      "    d = {}\n",
      "    for i, bi_gram in enumerate(bi_grams):\n",
      "        d[\"BI\" + \":\" + str(-mid_ix + i) + \" \" + bi_gram[0] + \" | \" + bi_gram[1]] = feature_val\n",
      "    return d\n",
      "\n",
      "\"\"\" TODO:\n",
      "        Extract features for numbers\n",
      "        Extract features for years\n",
      "        Extract features that are temperatures (look for degree\\degrees in subsequent words, along with C or F)\n",
      "\"\"\"\n",
      "idgen = IdGenerator()\n",
      "stemmer = PorterStemmer()\n",
      "\n",
      "def extract_features(words):\n",
      "    \n",
      "    if STEM:\n",
      "        words = [stemmer.stem(w) for w in words]\n",
      "    \n",
      "    #Extract features for words\n",
      "    features = {}\n",
      "    pos_features = extract_positional_word_features(words, MID_IX, feature_val=1)    \n",
      "    word_features  = extract_word_features(words, feature_val=1)\n",
      "    pos_bi_grams = extract_positional_bigram_features(words, MID_IX, feature_val = 1)\n",
      "    \n",
      "    features.update(pos_features)\n",
      "    features.update(word_features)\n",
      "    features.update(pos_bi_grams)\n",
      "    return features\n",
      "\n",
      "def extract_ys_by_code(tags, ysByCode):\n",
      "    for code in all_codes:\n",
      "        ysByCode[code].append(1 if code in tags else 0 )\n",
      "    \n",
      "    ysByCode[CAUSAL_REL].append(  1 if  \"Causer\" in tags and \"explicit\" in tags else 0)\n",
      "    ysByCode[RESULT_REL].append(  1 if  \"Result\" in tags and \"explicit\" in tags else 0)\n",
      "    ysByCode[CAUSE_RESULT].append(1 if (\"Result\" in tags and \"explicit\" in tags and \"Causer\" in tags) else 0)\n",
      "\n",
      "def sentence2feats(sentence):\n",
      "    d = {}\n",
      "    for wd in sentence:\n",
      "        d[\"BOW:\" + wd] = 1\n",
      "    return d\n",
      "    \n",
      "ix2ys = {}\n",
      "ix2feats = {}\n",
      "feat_counts = defaultdict(int)\n",
      "def tally_features(feats):\n",
      "    for k,v in feats.items():\n",
      "        feat_counts[k] += 1\n",
      "\n",
      "for i, windows in ix2windows.items():\n",
      "    feats = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    \n",
      "    ix2feats[i] = feats\n",
      "    ix2ys[i] = ysByCode\n",
      "    \n",
      "    #bow = sentence2feats(tokenized_sentences[i])\n",
      "    for window in windows:\n",
      "        # Get the words minus tags\n",
      "        words, tags = zip(*window)                \n",
      "        feat = extract_features(words)\n",
      "        # Add bow for sentence\n",
      "        #feat.update(bow)\n",
      "\n",
      "        tally_features(feat)\n",
      "        feats.append(feat.items())\n",
      "        \n",
      "        #Tags for middle word (target)\n",
      "        tags4word = tags[MID_IX]\n",
      "        extract_ys_by_code(tags4word, ysByCode)\n",
      "    assert len(windows) == len(feats)\n",
      "    assert all(map(lambda (k,v): len(v) == len(feats), ysByCode.items()))\n",
      "        \n",
      "\"\"\" Convert sparse dictionary features to sparse arrays \"\"\"\n",
      "ix2xs = {}\n",
      "for i, feature_lists in ix2feats.items():\n",
      "    xs = []\n",
      "    ix2xs[i] = xs\n",
      "    for feats in feature_lists:\n",
      "        x = [(idgen.get_id(f),v) \n",
      "             for f,v in feats \n",
      "             if feat_counts[f] >= MIN_FEAT_FREQ or f.startswith(\"WD:0\" )] #above min freq or is word\n",
      "        xs.append(x)        \n",
      "\n",
      "num_features = idgen.max_id() + 1\n",
      "print \"Number of features:\", num_features\n",
      "\n",
      "\"\"\" Convert to dense numpy arrays \"\"\"\n",
      "for i in ix2xs.keys():\n",
      "    xs = ix2xs[i]\n",
      "    xs = np.array([matutils.sparse2full(x, num_features) for x in xs])        \n",
      "    ix2xs[i] = xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 12283\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "\n",
      "def count_above(ft_counts, threshold):\n",
      "    above = [ v for k,v in ft_counts.items() if v >= threshold]\n",
      "    return (len(above), len(ft_counts))\n",
      "\n",
      "cnt_above, cnt_all = count_above(feat_counts, MIN_FEAT_FREQ)\n",
      "\n",
      "print \"Counts\"\n",
      "print \"all:     \", cnt_all\n",
      "print \"above:   \", cnt_above\n",
      "print \"% above: \", str(100.0 * cnt_above / float(cnt_all))+ \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counts\n",
        "all:      60563\n",
        "above:    12016\n",
        "% above:  19.8404966729%\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract ys for sentence (including causal codes) \"\"\"\n",
      "ix2ys_sent = {}\n",
      "for i, tags in ix2sentTags.items():\n",
      "    ix2ys_sent[i] = defaultdict(list)\n",
      "    extract_ys_by_code(tags, ix2ys_sent[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Create Data Using Previous Classifier \"\"\"\n",
      "\n",
      "def to_sentence_level_predictions(ix2xs, code2cls, codes):\n",
      "    ix2newxs = {}\n",
      "    \n",
      "    for i, xs in ix2xs.items():\n",
      "        tmp_xs = []\n",
      "        tmp_ys = []\n",
      "        tmp_ys_by_code = defaultdict(list)\n",
      "\n",
      "        un_codes = set()\n",
      "        un_pred_codes = set()\n",
      "        for code in codes:\n",
      "            cls = code2cls[code]\n",
      "\n",
      "            #SVM\n",
      "            pred = cls.decision_function(xs)\n",
      "            \n",
      "            #Probabilistic classifier\n",
      "            #pred = cls.predict_proba(xs)\n",
      "            # add min and max values\n",
      "            mx = np.max(pred, axis=0)\n",
      "            mn = np.min(pred, axis=0)\n",
      "        \n",
      "            tmp_xs.append(mx)\n",
      "            tmp_xs.append(mn)\n",
      "            #for val in mx:\n",
      "                #tmp_xs.append(val)\n",
      "            #tmp_xs.append(mx[-1])\n",
      "            \n",
      "            #for val in mn:\n",
      "                #tmp_xs.append(val)\n",
      "            #tmp_xs.append(mn[-1])\n",
      "\n",
      "            yes_no = np.max(cls.predict(xs))\n",
      "            tmp_xs.append(yes_no)\n",
      "\n",
      "            if yes_no > 0.0:\n",
      "                un_pred_codes.add(code)\n",
      "\n",
      "        #add 2 way feature combos\n",
      "        for a in all_codes:\n",
      "            for b in all_codes:\n",
      "                if b < a:\n",
      "                    if a in un_pred_codes and b in un_pred_codes:\n",
      "                        tmp_xs.append(1)\n",
      "                    else:\n",
      "                        tmp_xs.append(0)\n",
      "\n",
      "        ix2newxs[i] = np.array([tmp_xs])\n",
      "    return ix2newxs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Get sentence level classification performance \"\"\"\n",
      "def test_for_code(code, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    cls = codeToClassifier[code]\n",
      "    \n",
      "    act_ys  = []\n",
      "    pred_ys = []\n",
      "    for ix in ixs:\n",
      "        xs = ixToXs[ix]\n",
      "        ysByCode = ixToYs[ix]\n",
      "        \n",
      "        ys = np.asarray(ysByCode[code])\n",
      "        pred = cls.predict(xs)\n",
      "        \n",
      "        # Flatten predictions to sentence level by taking the max values\n",
      "        # over all windows\n",
      "        act_ys.append(max(ys))\n",
      "        pred_ys.append(max(pred))\n",
      "    \n",
      "    num_codes = len([y for y in act_ys if y == 1])\n",
      "    r,p,f1,a = rpf1a(act_ys, pred_ys)\n",
      "    return rpfa(r,p,f1,a,num_codes)\n",
      "\n",
      "def test(codes, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    td_metrics = []\n",
      "    for c in codes:\n",
      "        cls = codeToClassifier[c]\n",
      "        td_metrics.append(test_for_code(c, ixs, ixToXs, ixToYs, codeToClassifier))\n",
      "    td_wt_mn_prfa = weighted_mean_rpfa(td_metrics)\n",
      "    print type(cls), td_wt_mn_prfa\n",
      "    return td_wt_mn_prfa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_xs_ys(ixs, ixTOxs, ixTOys, codes):\n",
      "    xs = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    for i in ixs:\n",
      "        xs_tmp = ixTOxs[i]\n",
      "        xs.extend(xs_tmp)\n",
      "        ysByCode_tmp = ixTOys[i]\n",
      "        for code in codes:\n",
      "            ysByCode[code].extend(ysByCode_tmp[code])\n",
      "    return (np.array(xs), ysByCode)\n",
      "\n",
      "def train(codes, xs, yByCode, fn_create_cls):\n",
      "    code2classifier = {}\n",
      "    for code in codes:\n",
      "        print \"Training for :\", code   \n",
      "        cls = fn_create_cls()\n",
      "        code2classifier[code] = cls\n",
      "        ys = np.asarray(yByCode[code])\n",
      "        cls.fit(xs, ys)\n",
      "    return code2classifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from CrossValidation import cross_validation\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "#fn_classifier1 = LinearSVC\n",
      "fn_classifier1 = LogisticRegression\n",
      "fn_classifier2 = LogisticRegression\n",
      "\n",
      "SPLITS = 10\n",
      "#causal_codes = cr_codes + [\"explicit\"]\n",
      "causal_codes = [CAUSE_RESULT]\n",
      "\n",
      "ixs = range(len(sentences))\n",
      "np.random.shuffle(ixs)\n",
      "\n",
      "folds = cross_validation(ixs, SPLITS)\n",
      "win_td_metrics = []\n",
      "win_vd_metrics = []\n",
      "\n",
      "td_metrics = []\n",
      "vd_metrics = []\n",
      "\n",
      "#TODO try with these codes (it and other) but for 10 or more folds\n",
      "train_codes = [c for c in all_codes if c != \"it\"]\n",
      "reg_codes = [c for c in all_codes if c.isdigit() or c == \"explicit\"]\n",
      "\n",
      "for num, (ix_train, ix_valid) in enumerate(folds):\n",
      "    print \"Fold:\", num + 1\n",
      "    \n",
      "    # Train sequential classifier\n",
      "    xs_t, yByCode_t = extract_xs_ys(ix_train, ix2xs, ix2ys, all_codes)\n",
      "    \n",
      "    print \"Training Window Tagger\"\n",
      "    code2cls = train(train_codes, xs_t, yByCode_t, fn_classifier1)\n",
      "    print \"Training performance\"\n",
      "    win_td_metrics.append(test(reg_codes, ix_train, ix2xs, ix2ys, code2cls))\n",
      "    print \"Validation performance\"\n",
      "    win_vd_metrics.append(test(reg_codes, ix_valid, ix2xs, ix2ys, code2cls))\n",
      "    \n",
      "    print \"Training Sentence Classifier\"\n",
      "    # Extract new data points and target classes\n",
      "    ix2xs_sent = to_sentence_level_predictions(ix2xs, code2cls, train_codes)\n",
      "    newxs_t, newyByCode_t = extract_xs_ys(ix_train, ix2xs_sent, ix2ys_sent, causal_codes)\n",
      "    \n",
      "    new_code2cls = train(causal_codes, newxs_t, newyByCode_t, fn_classifier2)\n",
      "    # Evaluate\n",
      "    print \"Training performance\"\n",
      "    td_metrics.append(test(causal_codes, ix_train, ix2xs_sent, ix2ys_sent, new_code2cls))\n",
      "    print \"Validation performance\"\n",
      "    vd_metrics.append(test(causal_codes, ix_valid, ix2xs_sent, ix2ys_sent, new_code2cls))\n",
      "\n",
      "print \"\\NFinished\\n\"\n",
      "print \"Word Tagger:\"\n",
      "print \"MEAN Test Performance      \", mean_rpfa(win_td_metrics)\n",
      "print \"MEAN Validation Performance\", mean_rpfa(win_vd_metrics)\n",
      "\n",
      "print \"Sentence Classifier:\"\n",
      "print \"MEAN Test Performance      \", mean_rpfa(td_metrics)\n",
      "print \"MEAN Validation Performance\", mean_rpfa(vd_metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold: 1\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9112, Precision: 0.9528, F1: 0.9284, Accuracy: 0.9745, Codes:  2276\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7390, Precision: 0.8290, F1: 0.7639, Accuracy: 0.9332, Codes:   249\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9468, Precision: 0.9534, F1: 0.9501, Accuracy: 0.9777, Codes:   432\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.5814, Precision: 0.5814, F1: 0.5814, Accuracy: 0.8326, Codes:    43\n",
        "Fold: 2\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9062, Precision: 0.9481, F1: 0.9229, Accuracy: 0.9726, Codes:  2270\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7490, Precision: 0.8174, F1: 0.7703, Accuracy: 0.9274, Codes:   255\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9509, Precision: 0.9465, F1: 0.9487, Accuracy: 0.9772, Codes:   428\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.5532, Precision: 0.6341, F1: 0.5909, Accuracy: 0.8326, Codes:    47\n",
        "Fold: 3\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9080, Precision: 0.9509, F1: 0.9253, Accuracy: 0.9740, Codes:  2240\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7649, Precision: 0.8604, F1: 0.7981, Accuracy: 0.9272, Codes:   285\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9325, Precision: 0.9462, F1: 0.9393, Accuracy: 0.9741, Codes:   415\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.5833, Precision: 0.7778, F1: 0.6667, Accuracy: 0.8372, Codes:    60\n",
        "Fold: 4\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9060, Precision: 0.9481, F1: 0.9228, Accuracy: 0.9726, Codes:  2276\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7510, Precision: 0.8294, F1: 0.7782, Accuracy: 0.9210, Codes:   249\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9602, Precision: 0.9469, F1: 0.9535, Accuracy: 0.9793, Codes:   427\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.6250, Precision: 0.7317, F1: 0.6742, Accuracy: 0.8651, Codes:    48\n",
        "Fold: 5\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9125, Precision: 0.9481, F1: 0.9260, Accuracy: 0.9738, Codes:  2275\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7520, Precision: 0.8310, F1: 0.7785, Accuracy: 0.9271, Codes:   250\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9484, Precision: 0.9506, F1: 0.9495, Accuracy: 0.9777, Codes:   426\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.5102, Precision: 0.7353, F1: 0.6024, Accuracy: 0.8458, Codes:    49\n",
        "Fold: 6\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9107, Precision: 0.9492, F1: 0.9262, Accuracy: 0.9732, Codes:  2306\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7671, Precision: 0.7910, F1: 0.7732, Accuracy: 0.9327, Codes:   219\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9538, Precision: 0.9451, F1: 0.9494, Accuracy: 0.9772, Codes:   433\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.7143, Precision: 0.7692, F1: 0.7407, Accuracy: 0.9019, Codes:    42\n",
        "Fold: 7\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9043, Precision: 0.9532, F1: 0.9243, Accuracy: 0.9732, Codes:  2258\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.8052, Precision: 0.8606, F1: 0.8215, Accuracy: 0.9430, Codes:   267\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9410, Precision: 0.9366, F1: 0.9388, Accuracy: 0.9731, Codes:   424\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.6275, Precision: 0.6531, F1: 0.6400, Accuracy: 0.8318, Codes:    51\n",
        "Fold: 8\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9073, Precision: 0.9491, F1: 0.9242, Accuracy: 0.9729, Codes:  2255\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7889, Precision: 0.8190, F1: 0.7970, Accuracy: 0.9322, Codes:   270\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9412, Precision: 0.9524, F1: 0.9467, Accuracy: 0.9767, Codes:   425\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.7200, Precision: 0.7347, F1: 0.7273, Accuracy: 0.8738, Codes:    50\n",
        "Fold: 9\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9067, Precision: 0.9484, F1: 0.9235, Accuracy: 0.9727, Codes:  2294\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.8225, Precision: 0.8567, F1: 0.8294, Accuracy: 0.9519, Codes:   231\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9405, Precision: 0.9384, F1: 0.9394, Accuracy: 0.9725, Codes:   437\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.6053, Precision: 0.6389, F1: 0.6216, Accuracy: 0.8692, Codes:    38\n",
        "Fold: 10\n",
        "Training Window Tagger"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training performance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9125, Precision: 0.9489, F1: 0.9269, Accuracy: 0.9737, Codes:  2275\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.7440, Precision: 0.8195, F1: 0.7706, Accuracy: 0.9316, Codes:   250\n",
        "Training Sentence Classifier\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Recall: 0.9463, Precision: 0.9463, F1: 0.9463, Accuracy: 0.9762, Codes:   428\n",
        "Validation performance\n",
        "<class 'sklearn.linear_model.logistic.LogisticRegression'> Recall: 0.5532, Precision: 0.8125, F1: 0.6582, Accuracy: 0.8738, Codes:    47\n",
        "\\NFinished\n",
        "\n",
        "Word Tagger:\n",
        "MEAN Test Performance       Recall: 0.9086, Precision: 0.9497, F1: 0.9250, Accuracy: 0.9733, Codes:    10\n",
        "MEAN Validation Performance Recall: 0.7684, Precision: 0.8314, F1: 0.7881, Accuracy: 0.9327, Codes:    10\n",
        "Sentence Classifier:\n",
        "MEAN Test Performance       Recall: 0.9462, Precision: 0.9462, F1: 0.9462, Accuracy: 0.9762, Codes:    10\n",
        "MEAN Validation Performance Recall: 0.6073, Precision: 0.7069, F1: 0.6503, Accuracy: 0.8564, Codes:    10\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = []\n",
      "code = \"CRel\"\n",
      "for i in ix2ys_sent.keys()[:400]:\n",
      "    l.append(ix2ys_sent[i][code][0])\n",
      "print min(l), max(l), len([1 for i in l if i > 0.0]), len(l)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 1 46 400\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Logistic Regression - Min and Max + 2 way features\n",
      "\n",
      "Word Tagger:\n",
      "MEAN Test Performance       Recall: 0.9058, Precision: 0.9513, F1: 0.9240, Accuracy: 0.9734, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.7663, Precision: 0.8257, F1: 0.7840, Accuracy: 0.9333, Codes:    10\n",
      "Sentence Classifier:\n",
      "MEAN Test Performance       Recall: 0.9021, Precision: 0.9317, F1: 0.9166, Accuracy: 0.9642, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.6291, Precision: 0.7314, F1: 0.6735, Accuracy: 0.8693, Codes:    10\n",
      "\n",
      "Newer Data - Log Reg (Window) SVM (Sentence) - Min and Max + 2 way features\n",
      "Word Tagger:\n",
      "MEAN Test Performance       Recall: 0.9085, Precision: 0.9491, F1: 0.9247, Accuracy: 0.9733, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.7738, Precision: 0.8326, F1: 0.7912, Accuracy: 0.9338, Codes:    10\n",
      "Sentence Classifier:\n",
      "MEAN Test Performance       Recall: 0.9340, Precision: 0.9496, F1: 0.9417, Accuracy: 0.9744, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.6140, Precision: 0.7129, F1: 0.6578, Accuracy: 0.8596, Codes:    10\n",
      "\n",
      "Newer Data - SVM (Window) Log Reg (Sentence) - Min and Max + 2 way features\n",
      "Word Tagger:\n",
      "MEAN Test Performance       Recall: 0.9902, Precision: 0.9815, F1: 0.9856, Accuracy: 0.9954, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.8301, Precision: 0.7422, F1: 0.7756, Accuracy: 0.9187, Codes:    10\n",
      "Sentence Classifier:\n",
      "MEAN Test Performance       Recall: 0.9873, Precision: 0.9872, F1: 0.9872, Accuracy: 0.9944, Codes:    10\n",
      "MEAN Validation Performance Recall: 0.6617, Precision: 0.6400, F1: 0.6497, Accuracy: 0.8438, Codes:    10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    }
   ],
   "metadata": {}
  }
 ]
}