{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Settings\n",
    "from model_store import ModelStore\n",
    "from window_based_tagger_config import get_config\n",
    "from processessays import process_essays, build_spelling_corrector\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import defaultdict\n",
    "from BrattEssay import Essay, load_bratt_essays\n",
    "\n",
    "from featureextractortransformer import FeatureExtractorTransformer\n",
    "from sent_feats_for_stacking import *\n",
    "from load_data import load_process_essays_without_annotations\n",
    "\n",
    "from featureextractionfunctions import *\n",
    "from wordtagginghelper import *\n",
    "\n",
    "from traceback import format_exc\n",
    "\n",
    "import logging\n",
    "\n",
    "def onlyascii(s):\n",
    "    out = \"\"\n",
    "    for char in s:\n",
    "        if ord(char) > 127:\n",
    "            out += \"\"\n",
    "        else:\n",
    "            out += char\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Annotator(object):\n",
    "\n",
    "    def __init__(self, models_folder, temp_folder, essays_folder):\n",
    "\n",
    "        logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "        if not models_folder.endswith(\"/\"):\n",
    "            models_folder += \"/\"\n",
    "        if not temp_folder.endswith(\"/\"):\n",
    "            temp_folder += \"/\"\n",
    "        if not essays_folder.endswith(\"/\"):\n",
    "            essays_folder += \"/\"\n",
    "\n",
    "        self.logger = logging.getLogger()\n",
    "        self.temp_folder = temp_folder\n",
    "        cfg = get_config(temp_folder)\n",
    "        self.config = cfg\n",
    "        self.essays_folder = essays_folder\n",
    "\n",
    "        #Create spell checker\n",
    "        # directory = None, include_vague = True, include_normal = True, load_annotations = True\n",
    "        tagged_essays = load_bratt_essays(essays_folder, include_vague=cfg[\"include_vague\"], include_normal=cfg[\"include_normal\"], load_annotations=True)\n",
    "        self.__set_tags_(tagged_essays)\n",
    "        self.wd_sent_freq = defaultdict(int)\n",
    "        self.spelling_corrector = build_spelling_corrector(tagged_essays, self.config[\"lower_case\"], self.wd_sent_freq)\n",
    "\n",
    "        offset = (self.config[\"window_size\"] - 1) / 2\n",
    "\n",
    "        unigram_window_stemmed = fact_extract_positional_word_features_stemmed(offset)\n",
    "        biigram_window_stemmed = fact_extract_ngram_features_stemmed(offset, 2)\n",
    "\n",
    "        extractors = [unigram_window_stemmed, biigram_window_stemmed]\n",
    "\n",
    "        # most params below exist ONLY for the purposes of the hashing to and from disk\n",
    "        self.feature_extractor = FeatureExtractorTransformer(extractors)\n",
    "\n",
    "        # load models\n",
    "        self.logger.info(\"Loading pickled models\")\n",
    "        store = ModelStore(models_folder=models_folder)\n",
    "\n",
    "        self.feature_transformer =  store.get_transformer()\n",
    "        self.logger.info(\"Loaded Transformer\")\n",
    "        self.tag_2_wd_classifier = store.get_tag_2_wd_classifier()\n",
    "        self.logger.info(\"Loaded word tagging model\")\n",
    "        self.tag_2_sent_classifier = store.get_tag_2_sent_classifier()\n",
    "        self.logger.info(\"Loaded sentence classifier\")\n",
    "\n",
    "    def __set_tags_(self, tagged_essays):\n",
    "\n",
    "        MIN_TAG_FREQ = 5\n",
    "\n",
    "        tag_freq = defaultdict(int)\n",
    "        for essay in tagged_essays:\n",
    "            for sentence in essay.tagged_sentences:\n",
    "                un_tags = set()\n",
    "                for word, tags in sentence:\n",
    "                    for tag in tags:\n",
    "                        if \"5b\" in tag:\n",
    "                            continue\n",
    "                        if      (tag[-1].isdigit() or tag in {\"Causer\", \"explicit\", \"Result\"} \\\n",
    "                                    or tag.startswith(\"Causer\") or tag.startswith(\"Result\") \\\n",
    "                                    or tag.startswith(\"explicit\") or \"->\" in tag) \\\n",
    "                                and not (\"Anaphor\" in tag or \"rhetorical\" in tag or \"other\" in tag):\n",
    "                            # if not (\"Anaphor\" in tag or \"rhetorical\" in tag or \"other\" in tag):\n",
    "                            un_tags.add(tag)\n",
    "                for tag in un_tags:\n",
    "                    tag_freq[tag] += 1\n",
    "\n",
    "        all_tags = list(tag_freq.keys())\n",
    "        freq_tags = list(set((tag for tag, freq in tag_freq.items() if freq >= MIN_TAG_FREQ)))\n",
    "        non_causal = [t for t in freq_tags if \"->\" not in t]\n",
    "        only_causal = [t for t in freq_tags if \"->\" in t]\n",
    "\n",
    "        CAUSE_TAGS = [\"Causer\", \"Result\", \"explicit\"]\n",
    "        CAUSAL_REL_TAGS = [CAUSAL_REL, CAUSE_RESULT, RESULT_REL]  # + [\"explicit\"]\n",
    "\n",
    "        \"\"\" works best with all the pair-wise causal relation codes \"\"\"\n",
    "        # Include all tags for the output\n",
    "        self.wd_test_tags = list(set(all_tags + CAUSE_TAGS))\n",
    "\n",
    "        # tags from tagging model used to train the stacked model\n",
    "        self.sent_input_feat_tags = list(set(freq_tags + CAUSE_TAGS))\n",
    "        # find interactions between these predicted tags from the word tagger to feed to the sentence tagger\n",
    "        self.sent_input_interaction_tags = list(set(non_causal + CAUSE_TAGS))\n",
    "        # tags to train (as output) for the sentence based classifier\n",
    "        self.sent_output_train_test_tags = list(set(all_tags + CAUSE_TAGS + CAUSAL_REL_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "1154 files found\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05571.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05904.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_BGJD_1_CB_ES-05733.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_ERSK_7_CB_ES-05798.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_KYLS_5_CB_ES-05671.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_LRJE_5_CB_ES-05128.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05612.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05617.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05632.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05640.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SWSP_4_CB_ES-05459.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05484.ann file as .txt file is no essay. //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05485.ann file as .txt file is no essay.  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_2_CB_ES-05548.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFMV_3_CB_ES-05845.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05715.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06128.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06132.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05025.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05030.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_2_CB_ES-06140.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06149.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06153.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTKP_7-8_CB_ES-06174.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415post_TWNB_2_CB_ES-04948.ann file as .txt file is no essay.'\n",
      "1128 essays processed\n",
      "Loading models from /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/API/Models/CB/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/API\"\n",
    "\n",
    "settings = Settings.Settings()\n",
    "folder = settings.data_directory + \"CoralBleaching/BrattData/EBA1415_Merged/\"\n",
    "\n",
    "annotator = Annotator(models_folder= cwd +\"/Models/CB/\", temp_folder=cwd+\"/temp/\", essays_folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_text = \"\"\"\n",
    "Corals are living animals in the ocean.\n",
    "Corals live in one place and dont really move alot.\n",
    "Some corals have white on them and that is called \"coral bleaching.\"\n",
    "Coral Bleaching means that the coral is unhealthy and is trusting into a white color.\n",
    "Normal water tempatures that the coral live in are 70-80 degrees.\n",
    "But some of the waters are too cool like 3 to 10 degrees F.\n",
    "Corals are also affected by storms because corals rely on the amounts of salt in the waters.\n",
    "So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral.\n",
    "The storms have to be very extreme to make corals sick or unhealthy.\n",
    "In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy.\n",
    "The water tempatures coral usally build their reefs in are 70-85 degrees F.\n",
    "So those are the tempature range to keep them healthy.\n",
    "Corals and zooanthellae algae have a relatioship together.\n",
    "Most zooanthellae can not live without outside the corals bodies.\n",
    "It is because there isnt enough nutrience to have the ocean do photosynthesis.\n",
    "The zooanthellae rely on the coral to stay healthy, but the coral can get physical damage.\n",
    "Coral bleaching is a physical damage to the corals.\n",
    "Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae. //\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "self = annotator\n",
    "# expects a new line per sentence\n",
    "sentences = sent_tokenize(essay_text.strip())\n",
    "contents = \"\\n\".join(sentences)\n",
    "\n",
    "fname = self.temp_folder + \"essay.txt\"\n",
    "with open(fname, 'w\"') as f:\n",
    "    f.write(contents)\n",
    "\n",
    "essay = Essay(fname, include_vague=self.config[\"include_vague\"], include_normal=self.config[\"include_normal\"], load_annotations=False)\n",
    "processed_essays = process_essays(essays=[essay],\n",
    "                                  spelling_corrector=self.spelling_corrector,\n",
    "                                  wd_sent_freq=self.wd_sent_freq,\n",
    "                                  remove_infrequent=self.config[\"remove_infrequent\"],\n",
    "                                  spelling_correct=self.config[\"spelling_correct\"],\n",
    "                                  replace_nums=self.config[\"replace_nums\"],\n",
    "                                  stem=self.config[\"stem\"],\n",
    "                                  remove_stop_words=self.config[\"remove_stop_words\"],\n",
    "                                  remove_punctuation=self.config[\"remove_punctuation\"],\n",
    "                                  lower_case=self.config[\"lower_case\"])\n",
    "\n",
    "self.logger.info(\"Essay loaded successfully\")\n",
    "essays_TD = self.feature_extractor.transform(processed_essays)\n",
    "\n",
    "td_feats, _ = flatten_to_wordlevel_feat_tags(essays_TD)\n",
    "td_X = self.feature_transformer.transform(td_feats)\n",
    "td_wd_predictions_by_code = test_classifier_per_code(td_X, self.tag_2_wd_classifier, self.wd_test_tags)\n",
    "\n",
    "dummy_wd_td_ys_bytag = defaultdict(lambda: np.asarray([0.0] * td_X.shape[0]))\n",
    "sent_td_xs, sent_td_ys_bycode = get_sent_feature_for_stacking_from_tagging_model(self.sent_input_feat_tags,\n",
    "                                                                                 self.sent_input_interaction_tags,\n",
    "                                                                                 essays_TD, td_X,\n",
    "                                                                                 dummy_wd_td_ys_bytag,\n",
    "                                                                                 self.tag_2_wd_classifier,\n",
    "                                                                                 sparse=True,\n",
    "                                                                                 look_back=0)\n",
    "\n",
    "\"\"\" Test Stack Classifier \"\"\"\n",
    "td_sent_predictions_by_code \\\n",
    "    = test_classifier_per_code(sent_td_xs, self.tag_2_sent_classifier, self.sent_output_train_test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18\n"
     ]
    }
   ],
   "source": [
    "print len(td_sent_predictions_by_code.values()[0]), len(essay.tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Corals are living animals in the ocean .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Corals live in one place and dont really move alot .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Some corals have white on them and that is called \" coral bleaching . \"',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Coral Bleaching means that the coral is unhealthy and is trusting into a white color .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Normal water tempatures that the coral live in are 70 - 80 degrees .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('But some of the waters are too cool like 3 to 10 degrees F .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Corals are also affected by storms because corals rely on the amounts of salt in the waters .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('The storms have to be very extreme to make corals sick or unhealthy .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('The water tempatures coral usally build their reefs in are 70 - 85 degrees F .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('So those are the tempature range to keep them healthy .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Corals and zooanthellae algae have a relatioship together .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Most zooanthellae can not live without outside the corals bodies .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('It is because there isnt enough nutrience to have the ocean do photosynthesis .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('The zooanthellae rely on the coral to stay healthy , but the coral can get physical damage .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Coral bleaching is a physical damage to the corals .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit'),\n",
       " ('Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae .',\n",
       "  '11,13,3,4,50,Causer,11,11->13,11->14,11->3,11->50,3,3->4,Result,13,4,50,_C->R,_CRel,_RRel,explicit')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = []\n",
    "for i, sent in enumerate(essay.tagged_sentences):\n",
    "    wds, _ = zip(*sent)\n",
    "    str_sent = \" \".join(wds)\n",
    "    pred_tags = set()\n",
    "    for tag, array in td_sent_predictions_by_code.items():\n",
    "        #if tag[0].isdigit() or (\"->\" in tag and \"Causer\")\n",
    "        if np.max(array) == 1:\n",
    "            pred_tags.add(tag)\n",
    "    tagged_sents.append((str_sent, \",\".join(sorted(pred_tags)).replace(\"Causer:\",\"\").replace(\"Result:\",\"\") ))\n",
    "tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_wd_predictions_by_code[\"5\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "print sum([len(sent) for sent in essay.tagged_sentences])\n",
    "print sum([len(sent) for sent in essays_TD[0].sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(td_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essays_TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Corals->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  living->([]) - 13 feats,\n",
       "  animals->([]) - 13 feats,\n",
       "  in->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  ocean->([]) - 13 feats],\n",
       " [Corals->([]) - 13 feats,\n",
       "  live->([]) - 13 feats,\n",
       "  in->([]) - 13 feats,\n",
       "  one->([]) - 13 feats,\n",
       "  place->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  dont->([]) - 13 feats,\n",
       "  really->([]) - 13 feats,\n",
       "  move->([]) - 13 feats,\n",
       "  alot->([]) - 13 feats],\n",
       " [Some->([]) - 13 feats,\n",
       "  corals->([]) - 13 feats,\n",
       "  have->([]) - 13 feats,\n",
       "  white->([]) - 13 feats,\n",
       "  on->([]) - 13 feats,\n",
       "  them->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  that->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  called->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  bleaching->([]) - 13 feats],\n",
       " [Coral->([]) - 13 feats,\n",
       "  Bleaching->([]) - 13 feats,\n",
       "  means->([]) - 13 feats,\n",
       "  that->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  unhealthy->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  INFREQUENT->([]) - 13 feats,\n",
       "  into->([]) - 13 feats,\n",
       "  a->([]) - 13 feats,\n",
       "  white->([]) - 13 feats,\n",
       "  color->([]) - 13 feats],\n",
       " [Normal->([]) - 13 feats,\n",
       "  water->([]) - 13 feats,\n",
       "  temperatures->([]) - 13 feats,\n",
       "  that->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  live->([]) - 13 feats,\n",
       "  in->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  00->([]) - 13 feats,\n",
       "  00->([]) - 13 feats,\n",
       "  degrees->([]) - 13 feats],\n",
       " [But->([]) - 13 feats,\n",
       "  some->([]) - 13 feats,\n",
       "  of->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  waters->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  too->([]) - 13 feats,\n",
       "  cool->([]) - 13 feats,\n",
       "  like->([]) - 13 feats,\n",
       "  0->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  00->([]) - 13 feats,\n",
       "  degrees->([]) - 13 feats,\n",
       "  F->([]) - 13 feats],\n",
       " [Corals->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  also->([]) - 13 feats,\n",
       "  affected->([]) - 13 feats,\n",
       "  by->([]) - 13 feats,\n",
       "  storms->([]) - 13 feats,\n",
       "  because->([]) - 13 feats,\n",
       "  corals->([]) - 13 feats,\n",
       "  rely->([]) - 13 feats,\n",
       "  on->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  amounts->([]) - 13 feats,\n",
       "  of->([]) - 13 feats,\n",
       "  salt->([]) - 13 feats,\n",
       "  in->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  waters->([]) - 13 feats],\n",
       " [So->([]) - 13 feats,\n",
       "  when->([]) - 13 feats,\n",
       "  it->([]) - 13 feats,\n",
       "  storms->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  water->([]) - 13 feats,\n",
       "  temperatures->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  levels->([]) - 13 feats,\n",
       "  of->([]) - 13 feats,\n",
       "  salt->([]) - 13 feats,\n",
       "  will->([]) - 13 feats,\n",
       "  be->([]) - 13 feats,\n",
       "  all->([]) - 13 feats,\n",
       "  most->([]) - 13 feats,\n",
       "  up->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  bad->([]) - 13 feats,\n",
       "  for->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats],\n",
       " [The->([]) - 13 feats,\n",
       "  storms->([]) - 13 feats,\n",
       "  have->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  be->([]) - 13 feats,\n",
       "  very->([]) - 13 feats,\n",
       "  extreme->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  make->([]) - 13 feats,\n",
       "  corals->([]) - 13 feats,\n",
       "  sick->([]) - 13 feats,\n",
       "  or->([]) - 13 feats,\n",
       "  unhealthy->([]) - 13 feats],\n",
       " [In->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  water->([]) - 13 feats,\n",
       "  if->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  temperature->([]) - 13 feats,\n",
       "  increases->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  amounts->([]) - 13 feats,\n",
       "  of->([]) - 13 feats,\n",
       "  dioxide->([]) - 13 feats,\n",
       "  will->([]) - 13 feats,\n",
       "  drop->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  INFREQUENT->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  unhealthy->([]) - 13 feats],\n",
       " [The->([]) - 13 feats,\n",
       "  water->([]) - 13 feats,\n",
       "  temperatures->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  usually->([]) - 13 feats,\n",
       "  build->([]) - 13 feats,\n",
       "  their->([]) - 13 feats,\n",
       "  reefs->([]) - 13 feats,\n",
       "  in->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  00->([]) - 13 feats,\n",
       "  00->([]) - 13 feats,\n",
       "  degrees->([]) - 13 feats,\n",
       "  F->([]) - 13 feats],\n",
       " [So->([]) - 13 feats,\n",
       "  those->([]) - 13 feats,\n",
       "  are->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  temperature->([]) - 13 feats,\n",
       "  range->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  keep->([]) - 13 feats,\n",
       "  them->([]) - 13 feats,\n",
       "  healthy->([]) - 13 feats],\n",
       " [Corals->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  zooanthellae->([]) - 13 feats,\n",
       "  algae->([]) - 13 feats,\n",
       "  have->([]) - 13 feats,\n",
       "  a->([]) - 13 feats,\n",
       "  relationship->([]) - 13 feats,\n",
       "  together->([]) - 13 feats],\n",
       " [Most->([]) - 13 feats,\n",
       "  zooanthellae->([]) - 13 feats,\n",
       "  can->([]) - 13 feats,\n",
       "  not->([]) - 13 feats,\n",
       "  live->([]) - 13 feats,\n",
       "  without->([]) - 13 feats,\n",
       "  outside->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  corals->([]) - 13 feats,\n",
       "  bodies->([]) - 13 feats],\n",
       " [It->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  because->([]) - 13 feats,\n",
       "  there->([]) - 13 feats,\n",
       "  int->([]) - 13 feats,\n",
       "  enough->([]) - 13 feats,\n",
       "  nutrients->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  have->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  ocean->([]) - 13 feats,\n",
       "  do->([]) - 13 feats,\n",
       "  photosynthesis->([]) - 13 feats],\n",
       " [The->([]) - 13 feats,\n",
       "  zooanthellae->([]) - 13 feats,\n",
       "  rely->([]) - 13 feats,\n",
       "  on->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  stay->([]) - 13 feats,\n",
       "  healthy->([]) - 13 feats,\n",
       "  but->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  can->([]) - 13 feats,\n",
       "  get->([]) - 13 feats,\n",
       "  physical->([]) - 13 feats,\n",
       "  damage->([]) - 13 feats],\n",
       " [Coral->([]) - 13 feats,\n",
       "  bleaching->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  a->([]) - 13 feats,\n",
       "  physical->([]) - 13 feats,\n",
       "  damage->([]) - 13 feats,\n",
       "  to->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  corals->([]) - 13 feats],\n",
       " [Coral->([]) - 13 feats,\n",
       "  bleaching->([]) - 13 feats,\n",
       "  is->([]) - 13 feats,\n",
       "  also->([]) - 13 feats,\n",
       "  an->([]) - 13 feats,\n",
       "  example->([]) - 13 feats,\n",
       "  how->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  environmental->([]) - 13 feats,\n",
       "  stressors->([]) - 13 feats,\n",
       "  can->([]) - 13 feats,\n",
       "  affect->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  relationships->([]) - 13 feats,\n",
       "  between->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  coral->([]) - 13 feats,\n",
       "  and->([]) - 13 feats,\n",
       "  the->([]) - 13 feats,\n",
       "  algae->([]) - 13 feats]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_TD[0].sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
