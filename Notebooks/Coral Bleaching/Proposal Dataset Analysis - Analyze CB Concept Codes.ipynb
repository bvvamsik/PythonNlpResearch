{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "1154 files found\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05571.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05904.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_BGJD_1_CB_ES-05733.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_ERSK_7_CB_ES-05798.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_KYLS_5_CB_ES-05671.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_LRJE_5_CB_ES-05128.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05612.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05617.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05632.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05640.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SWSP_4_CB_ES-05459.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05484.ann file as .txt file is no essay. //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05485.ann file as .txt file is no essay.  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_2_CB_ES-05548.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFMV_3_CB_ES-05845.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05715.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06128.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06132.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05025.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05030.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_2_CB_ES-06140.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06149.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06153.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTKP_7-8_CB_ES-06174.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415post_TWNB_2_CB_ES-04948.ann file as .txt file is no essay.'\n",
      "1128 essays processed\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "#essays = load_bratt_essays(settings.data_directory + \"SkinCancer/EBA1415_Merged/\")\n",
    "folder = settings.data_directory + \"CoralBleaching/BrattData/EBA1415_Merged/\"\n",
    "essays = load_bratt_essays(folder)\n",
    "\n",
    "wd_sent_freq = defaultdict(int)\n",
    "all_codes = set()\n",
    "#Stores all words for the spelling corrector\n",
    "words = []\n",
    "all_sentences = []\n",
    "sentencesForCode = defaultdict(list)\n",
    "for essay in essays:\n",
    "    for sentence in essay.tagged_sentences:\n",
    "        wdsInSent = set()\n",
    "        codes4sentence = set()\n",
    "        sent = []\n",
    "        for w, tags in sentence:\n",
    "            words.append(w)\n",
    "            all_codes.update(tags)\n",
    "            codes4sentence.update(tags)\n",
    "            if w not in wdsInSent:\n",
    "                wdsInSent.add(w)\n",
    "                wd_sent_freq[w] += 1\n",
    "            sent.append(w)\n",
    "        all_sentences.append(sent)\n",
    "        for code in codes4sentence:\n",
    "            sentencesForCode[code].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stats over the Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd_counts = []\n",
    "sent_counts = []\n",
    "concept_codes = []\n",
    "cr_concept_codes = []\n",
    "sent_multi_word_tags = {}\n",
    "sent_codes = []\n",
    "sent_cr_codes = []\n",
    "\n",
    "num_sents = 0\n",
    "un_wd_counts = []\n",
    "for e_ix, essay in enumerate(essays):\n",
    "    wds = 0\n",
    "    un_words = set()\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        num_sents += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        for w, tags in sentence:\n",
    "            un_words.add(w)\n",
    "            wds += 1\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                sent_tags.update(ccodes)\n",
    "                concept_codes.append(ccodes)\n",
    "                if len(ccodes) > 1:\n",
    "                    sent_multi_word_tags[(e_ix, i)] = [(w,[tag for tag in t if tag[0].isdigit()]) for w,t in sentence]\n",
    "            cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            if cr_codes:\n",
    "                cr_concept_codes.append(cr_codes)\n",
    "                sent_cr_tags.update(cr_codes)\n",
    "        if len(sent_tags) > 0:\n",
    "            sent_codes.append(sent_tags)\n",
    "            if len(sent_cr_tags) > 0:\n",
    "                sent_cr_codes.append(sent_cr_tags)\n",
    "                \n",
    "    un_wd_counts.append(len(un_words))\n",
    "    sent_counts.append(len(essay.tagged_sentences))\n",
    "    wd_counts.append(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10210.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((138, 5),\n",
       " [('The', []),\n",
       "  ('strength', ['1', '3']),\n",
       "  ('of', ['1', '3']),\n",
       "  ('the', ['3']),\n",
       "  ('water', ['3']),\n",
       "  ('and', []),\n",
       "  ('wind', ['1']),\n",
       "  ('get', []),\n",
       "  ('algae', ['7']),\n",
       "  ('out', ['7']),\n",
       "  ('of', ['7']),\n",
       "  ('control', ['7']),\n",
       "  ('and', []),\n",
       "  ('turns', ['50']),\n",
       "  ('coral', ['50']),\n",
       "  ('white', ['50']),\n",
       "  ('.', [])])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(sent_multi_word_tags), num_sents\n",
    "sent_multi_word_tags.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7094, 3138)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_codes), len([tags for tags in sent_codes if len(tags) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640, 0),\n",
       " [('Corals', ['50']),\n",
       "  ('get', ['50']),\n",
       "  ('there', ['50']),\n",
       "  ('color', ['50']),\n",
       "  ('by', ['50']),\n",
       "  ('the', ['50']),\n",
       "  ('different', ['50']),\n",
       "  ('types', ['50']),\n",
       "  ('of', ['50']),\n",
       "  ('algae', ['50', '7']),\n",
       "  ('that', ['7']),\n",
       "  ('live', ['7']),\n",
       "  ('with', ['7']),\n",
       "  ('the', ['7']),\n",
       "  ('coral', ['7']),\n",
       "  ('.', [])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_multi_word_tags.items()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Length Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.824468085 142.0 1 461 81.6952326181\n",
      "9.05141843972 8.0 1 31 5.16578158718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.mean(wd_counts), np.median(wd_counts), np.min(wd_counts), np.max(wd_counts), np.std(wd_counts)\n",
    "print np.mean(sent_counts), np.median(sent_counts), np.min(sent_counts), np.max(sent_counts), np.std(sent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 226, 83.875, 83.5, 37.813481392223068)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(un_wd_counts), np.max(un_wd_counts), np.mean(un_wd_counts), np.median(un_wd_counts), np.std(un_wd_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '11', '12', '13', '14', '2', '3', '4', '5', '50', '5b', '6', '7'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IterableFP import flatten\n",
    "unique = set(flatten(concept_codes))\n",
    "unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Tagged Words Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52084 167874 0.31\n",
      "12 0.000230397050918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['50', '5b'],\n",
       " ['50', '5b'],\n",
       " ['1', '3'],\n",
       " ['1', '3'],\n",
       " ['50', '7'],\n",
       " ['7', '14'],\n",
       " ['7', '14'],\n",
       " ['50', '7'],\n",
       " ['13', '4'],\n",
       " ['13', '4'],\n",
       " ['13', '4'],\n",
       " ['14', '50']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(concept_codes), sum(wd_counts), round(len(concept_codes) / float(sum(wd_counts)),2)\n",
    "multiple = [tags for tags in concept_codes if len(tags) > 1]\n",
    "print len(multiple), len(multiple) / float(len(concept_codes))\n",
    "multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '5b',\n",
       " '6',\n",
       " '7',\n",
       " 'Causer',\n",
       " 'Result',\n",
       " 'explicit'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cr = set(flatten(cr_concept_codes))\n",
    "unique_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57535 167874 0.34\n",
      "28007 0.486781958808\n"
     ]
    }
   ],
   "source": [
    "print len(cr_concept_codes), sum(wd_counts), round(len(cr_concept_codes) / float(sum(wd_counts)),2)\n",
    "multiple = [tags for tags in cr_concept_codes if len(tags) > 1]\n",
    "print len(multiple), len(multiple) / float(len(cr_concept_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Proportion of Sentences With Codes Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694809010774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44234564420637157"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents = float(num_sents)\n",
    "print len(sent_codes) / num_sents\n",
    "num_multiple_codes = len([tags for tags in sent_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_cr_codes) / num_sents\n",
    "num_multiple_codes = len([tags for tags in sent_cr_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_cr_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probabilities of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "priors = defaultdict(float)\n",
    "joints = defaultdict(float)\n",
    "\n",
    "for sent in sent_codes:\n",
    "    for a in sorted(sent):\n",
    "        priors[a] += 1\n",
    "        for b in sorted(sent):\n",
    "            if b >= a:\n",
    "                break\n",
    "            joints[(b,a)] +=1\n",
    "\n",
    "conditional = {}\n",
    "for a, cnt in priors.items():\n",
    "    for b in priors.keys():\n",
    "        if a == b:\n",
    "            continue\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) / p(B) \"\"\"\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) \"\"\"\n",
    "        if a < b:\n",
    "            joint = joints[(a,b)]\n",
    "        else:\n",
    "            joint = joints[(b,a)]\n",
    "        conditional[(a,b)] = joint / priors[b]\n",
    "    \n",
    "lifts = {}\n",
    "total = float(sum(joints.values()))\n",
    "totalPrior = float(sum(priors.values()))\n",
    "for (a,b),cnt in joints.items():\n",
    "    joint = cnt / total\n",
    "    pA = priors[a] / totalPrior\n",
    "    pB = priors[b] / totalPrior\n",
    "    lift = joint / (pA * pB)\n",
    "    if lift:\n",
    "        lifts[(a,b)] = lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 1     & 2     &  2.23 \\\\\n",
      "& 2     & 3     &  1.53 \\\\\n",
      "& 3     & 4     &  1.73 \\\\\n",
      "& 4     & 5     &  2.11 \\\\\n",
      "& 5b    & 14    & -0.69 \\\\\n",
      "& 5     & 5b    &  2.11 \\\\\n",
      "& 6     & 7     &  2.24 \\\\\n",
      "& 6     & 14    &  2.34 \\\\\n",
      "& 7     & 50    &   1.2 \\\\\n",
      "& 11    & 12    &  3.93 \\\\\n",
      "& 12    & 13    &  3.58 \\\\\n",
      "& 13    & 14    &  2.59 \\\\\n"
     ]
    }
   ],
   "source": [
    "def get_num(a):\n",
    "    s = \"\"\n",
    "    for c in a:\n",
    "        if c.isdigit():\n",
    "            s += c\n",
    "    return int(s)\n",
    "\n",
    "consec_pmi = {}\n",
    "for (a,b), lift in lifts.items():\n",
    "    ia = get_num(a)\n",
    "    ib = get_num(b)\n",
    "    diff = abs(ia-ib)\n",
    "    pmi = np.log(lift)\n",
    "    if \"Coral\" in folder:\n",
    "        if diff == 1 and b != \"6\" and b != \"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"5\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"50\" and b ==\"7\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "    elif \"Skin\" in folder:\n",
    "        if diff == 1:\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"12\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"50\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi        \n",
    "            \n",
    "for k,v in sorted(consec_pmi.items(), key = lambda (k,v): (min(int(k[0]),int(k[1].replace(\"b\",\"\"))))):\n",
    "    a = k[0]\n",
    "    b = k[1]\n",
    "    if len(a) > len(b.replace(\"b\",\"\")):\n",
    "        a,b = b,a\n",
    "    print \"&\", str(a).ljust(5), \"&\", str(b).ljust(5), \"&\", str(round(v,2)).rjust(5), \"\\\\\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8575045329169773"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lifts.values())\n",
    "#sorted(lifts.items(), key=lambda (tpl,p):-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.400765095332002"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(map(lambda l: np.log(l), lifts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
