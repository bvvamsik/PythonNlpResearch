{
 "metadata": {
  "name": "",
  "signature": "sha256:ebd4c8360859f55e642826513b64f3d43200e906187c7cbd4f0539f499953e78"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train a Window Based Classier on the Coral Bleaching Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup:\n",
      "------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Imports \"\"\"\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "from gensim import matutils\n",
      "from numpy import random\n",
      "\n",
      "from Metrics import rpf1a\n",
      "from Rpfa import rpfa, weighted_mean_rpfa\n",
      "from BrattEssay import load_bratt_essays\n",
      "from WindowSplitter import split_into_windows\n",
      "\n",
      "from IdGenerator import IdGenerator\n",
      "from IterableFP import flatten\n",
      "\n",
      "from nltk import PorterStemmer\n",
      "from stanford_parser import parser\n",
      "\n",
      "\"\"\" TODO \n",
      "    Try dependency parse features from this python dependency parser: https://github.com/syllog1sm/redshift\n",
      "\"\"\"\n",
      "\n",
      "\"\"\" Settings \"\"\"\n",
      "\"\"\" Start Script \"\"\"\n",
      "WINDOW_SIZE = 7 #7 is best\n",
      "MID_IX = int(round(WINDOW_SIZE / 2.0) - 1)\n",
      "\n",
      "MIN_SENTENCE_FREQ = 2\n",
      "PCT_VALIDATION  = 0.2\n",
      "MIN_FEAT_FREQ = 5     #15 best so far\n",
      "PCT_VALIDATION = 0.25\n",
      "\n",
      "SENTENCE_START = \"<START>\"\n",
      "SENTENCE_END   = \"<END>\"\n",
      "STEM = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Essays\n",
      "---------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\" Load Essays \"\"\"\n",
      "essays = load_bratt_essays(\"/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/Merged/\")\n",
      "\n",
      "all_codes = set()\n",
      "all_words = []\n",
      "\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        for w, tags in sentence:\n",
      "            all_words.append(w)\n",
      "            all_codes.update(tags)\n",
      "                \n",
      "# Correct miss-spellings\n",
      "from SpellingCorrector import SpellingCorrector\n",
      "\n",
      "corrector = SpellingCorrector(all_words)\n",
      "corrections = defaultdict(int)\n",
      "\n",
      "for essay in essays:\n",
      "    for i, sentence in enumerate(essay.tagged_sentences):\n",
      "        for j, (w, tags) in enumerate(sentence):\n",
      "            # common error is ..n't and ..nt\n",
      "            if w.endswith(\"n't\") or w.endswith(\"n'\"):\n",
      "                cw = w[:-3] + \"nt\"\n",
      "            elif w.endswith(\"'s\"):\n",
      "                cw = w[:-2]\n",
      "            elif w == \"&\":\n",
      "                cw = \"and\"\n",
      "            else:\n",
      "                cw = corrector.correct(w)\n",
      "            if cw != w:\n",
      "                corrections[(w,cw)] += 1\n",
      "                sentence[j] = (cw, tags)            \n",
      "            \n",
      "wd_sent_freq = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        wds, tag_list = zip(*sentence)\n",
      "        unique_wds = set(wds)\n",
      "        for w in unique_wds: \n",
      "            wd_sent_freq[w] += 1\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "297 files found\n",
        "297 essays processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "cor_srtd = sort_by_value(corrections, reverse = True)\n",
      "cor_srtd[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[((\"it's\", 'it'), 52),\n",
        " (('zox', 'zo'), 41),\n",
        " ((\"don't\", 'dont'), 31),\n",
        " ((\"that's\", 'that'), 29),\n",
        " (('algea', 'algae'), 26),\n",
        " ((\"world's\", 'world'), 20),\n",
        " (('&', 'and'), 17),\n",
        " ((\"can't\", 'cant'), 14),\n",
        " (('bleaches', 'bleached'), 13),\n",
        " (('cloral', 'coral'), 11),\n",
        " ((\"they're\", 'there'), 11),\n",
        " ((\"coral's\", 'coral'), 11),\n",
        " ((\"isn't\", 'isnt'), 11),\n",
        " (('tempeture', 'temperature'), 9),\n",
        " ((\"won't\", 'wont'), 9),\n",
        " (('alge', 'algae'), 9),\n",
        " (('tiems', 'times'), 8),\n",
        " ((\"doesn't\", 'doesnt'), 8),\n",
        " (('tempature', 'temperature'), 8),\n",
        " (('varys', 'vary'), 7)]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Single char words \"\"\"\n",
      "wds = [(w,f) for w,f in wd_sent_freq.items() if len(w.strip()) == 1 and not w[0].isalpha()]\n",
      "print \"\\n\".join(map(str,sorted(wds, key = lambda (w,f): -f)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('.', 2551)\n",
        "(',', 675)\n",
        "('/', 118)\n",
        "('-', 104)\n",
        "('\"', 100)\n",
        "('?', 67)\n",
        "('(', 43)\n",
        "(')', 42)\n",
        "('3', 40)\n",
        "('%', 36)\n",
        "('\\xc2', 27)\n",
        "('\\xb0', 27)\n",
        "('\\x80', 17)\n",
        "('\\xe2', 17)\n",
        "('1', 17)\n",
        "('\\\\', 16)\n",
        "('5', 15)\n",
        "(';', 12)\n",
        "(':', 9)\n",
        "('\\x99', 8)\n",
        "('+', 7)\n",
        "('2', 7)\n",
        "('\\x93', 7)\n",
        "(\"'\", 6)\n",
        "('0', 4)\n",
        "('6', 4)\n",
        "('!', 4)\n",
        "('8', 2)\n",
        "('9', 2)\n",
        "('\\xa6', 2)\n",
        "('=', 2)\n",
        "('7', 1)\n",
        "('4', 1)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Windows\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Creating Windows \"\"\"\n",
      "def filter2min_word_freq(sentence):\n",
      "    return filter(lambda (w, tags4word): wd_sent_freq[w] >= MIN_SENTENCE_FREQ, sentence)\n",
      "\n",
      "VALID_CHARS = {\".\", \"?\", \"!\", \"=\", \"/\", \":\", \";\", \"&\", \"+\",  \"-\", \"=\",  \"%\", \"'\", \",\", \"\\\\\", \"(\", \")\", \"\\\"\"}\n",
      "\"\"\" Remove bad chars (see above - e.g. '\\x93') \"\"\"\n",
      "removed = set()\n",
      "def valid_wd(wd):\n",
      "    wd = wd.strip()\n",
      "    if len(wd) != 1:\n",
      "        return True\n",
      "    if wd in removed:\n",
      "        return False\n",
      "    if wd.isalpha() or wd.isdigit() or wd in VALID_CHARS:\n",
      "        return True\n",
      "    removed.add(wd)\n",
      "    return False\n",
      "    \n",
      "def filterout_punctuation(sentence):\n",
      "    return filter(lambda (w, tags4word): valid_wd(w), sentence)\n",
      "\n",
      "def bookend(sentence):\n",
      "    for i in range(MID_IX):\n",
      "        modified_sentence.insert(0, (SENTENCE_START,    set()))\n",
      "        modified_sentence.append(   (SENTENCE_END,      set()))\n",
      "\n",
      "def assert_windows_correct(windows):\n",
      "    lens = map(len, windows)\n",
      "    assert min(lens) == max(lens) == WINDOW_SIZE, \\\n",
      "            \"Windows are not all the correct size\"\n",
      "   \n",
      "ix2windows = {}\n",
      "ix2sents = {}\n",
      "sentences = []\n",
      "tokenized_sentences = []\n",
      "\n",
      "i = 0\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        \n",
      "        modified_sentence = filter2min_word_freq(sentence)\n",
      "        modified_sentence = filterout_punctuation(modified_sentence)\n",
      "        if len(modified_sentence) == 0:\n",
      "            continue\n",
      "        \n",
      "        bookend(modified_sentence)        \n",
      "        new_windows = split_into_windows(modified_sentence, window_size= WINDOW_SIZE)        \n",
      "        assert_windows_correct(new_windows)       \n",
      "        \n",
      "        # tagged words\n",
      "        sentences.append(sentence)\n",
      "        # words only\n",
      "        tokenized_sentences.append(zip(*sentence)[0])\n",
      "        \n",
      "        ix2windows[i] = new_windows\n",
      "        ix2sents[i] = modified_sentence\n",
      "        i += 1\n",
      "        \n",
      "\"\"\" Assert tags set correctly \"\"\"\n",
      "print \"Windows loaded correctly!\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Windows loaded correctly!\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sentence Level Features\n",
      "-----------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from gensim import matutils\n",
      "\n",
      "def filter_words(wd):\n",
      "    return wd.isalnum()\n",
      "\n",
      "docs = map(lambda sen : \" \".join(filter(filter_words,sen)),tokenized_sentences)\n",
      "\n",
      "#Vectorize\n",
      "vectorizer = TfidfVectorizer(use_idf = False, ngram_range = (1, 1), min_df = 5, binary=True)\n",
      "sentence_vectors = vectorizer.fit_transform(docs)\n",
      "sentence_vectors = sentence_vectors.todense()\n",
      "sentence_vectors = map(lambda s: s.tolist()[0], sentence_vectors)\n",
      "ix2vector = dict(enumerate(sentence_vectors))\n",
      "print len(ix2vector[0]), \"features\"\n",
      "ix2vector[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "662 features\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.4472135954999579,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0,\n",
        " 0.0]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Removed Characters\n",
      "------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(sorted(removed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract Features\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract Features \"\"\"\n",
      "from WindowFeatures import extract_positional_word_features, extract_word_features\n",
      "from NgramGenerator import compute_ngrams\n",
      "\n",
      "def extract_skip_b4_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[:mid_ix]:\n",
      "        feats[\"_BEFORE: \" + wd + \"|\" + target] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_skip_after_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[mid_ix+1:]:\n",
      "        feats[\"_AFTER: \" + target + \"|\" + wd] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_positional_bigram_features(window, mid_ix, feature_val = 1):\n",
      "    bi_grams = compute_ngrams(window, max_len = 2, min_len = 2)\n",
      "    d = {}\n",
      "    for i, bi_gram in enumerate(bi_grams):\n",
      "        d[\"BI\" + \":\" + str(-mid_ix + i) + \" \" + bi_gram[0] + \" | \" + bi_gram[1]] = feature_val\n",
      "    return d\n",
      "\n",
      "def extract_positional_skip_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for i, wd in enumerate(window):\n",
      "        if i == mid_ix:\n",
      "            continue\n",
      "        a,b = wd,target\n",
      "        if i > mid_ix:\n",
      "            a,b = b,a\n",
      "        feats[\"SKIP:\" + str(-mid_ix + i) + \" \" + a + \" | \" + b] = feature_val\n",
      "    return feats\n",
      "\n",
      "\"\"\" TODO:\n",
      "        Extract features for numbers\n",
      "        Extract features for years\n",
      "        Extract features that are temperatures (look for degree\\degrees in subsequent words, along with C or F)\n",
      "\"\"\"\n",
      "idgen = IdGenerator()\n",
      "stemmer = PorterStemmer()\n",
      "\n",
      "def extract_features(words):\n",
      "    \n",
      "    if STEM:\n",
      "        words = [stemmer.stem(w) for w in words]\n",
      "    #Extract features for words\n",
      "    \n",
      "    \"\"\" Try only middle word \"\"\"\n",
      "    features = {}\n",
      "    ###\n",
      "    pos_features = extract_positional_word_features(words, MID_IX, feature_val=1)    \n",
      "    word_features  = extract_word_features(words, feature_val=1)\n",
      "    \n",
      "    #DO NOT HELP\n",
      "    #b4_features    = extract_skip_b4_word_features(words, MID_IX, feature_val=1)\n",
      "    #after_features = extract_skip_after_word_features(words, MID_IX, feature_val=1)\n",
      "    #pos_skip_grams = extract_positional_skip_word_features(words, MID_IX,  feature_val = 1)\n",
      "    pos_bi_grams = extract_positional_bigram_features(words, MID_IX, feature_val = 1)\n",
      "\n",
      "    features.update(pos_features)\n",
      "    features.update(word_features)\n",
      "    #features.update(b4_features)\n",
      "    #features.update(after_features)\n",
      "    #features.update(pos_skip_grams)\n",
      "    features.update(pos_bi_grams)\n",
      "    return features.items()\n",
      "\n",
      "def extract_ys_by_code(tags, ysByCode):\n",
      "    for code in all_codes:\n",
      "        ysByCode[code].append(1 if code in tags else 0 )    \n",
      "\n",
      "ix2ys = {}\n",
      "ix2feats = {}\n",
      "feat_counts = defaultdict(int)\n",
      "def tally_features(feats):\n",
      "    for k,v in feats:\n",
      "        feat_counts[k] += 1\n",
      "\n",
      "for i, windows in ix2windows.items():\n",
      "    feats = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    \n",
      "    ix2feats[i] = feats\n",
      "    ix2ys[i] = ysByCode\n",
      "    for window in windows:\n",
      "        # Get the words minus tags\n",
      "        words, tags = zip(*window)                \n",
      "        feat = extract_features(words)\n",
      "        tally_features(feat)\n",
      "        feats.append(feat)\n",
      "        \n",
      "        #Tags for middle word (target)\n",
      "        tags4word = tags[MID_IX]\n",
      "        extract_ys_by_code(tags4word, ysByCode)\n",
      "    assert len(windows) == len(feats)\n",
      "    assert all(map(lambda (k,v): len(v) == len(feats), ysByCode.items()))\n",
      "        \n",
      "\"\"\" Convert sparse dictionary features to sparse arrays \"\"\"\n",
      "ix2xs = {}\n",
      "for i, feature_lists in ix2feats.items():\n",
      "    xs = []\n",
      "    ix2xs[i] = xs\n",
      "    for feats in feature_lists:\n",
      "        x = [(idgen.get_id(f),v) \n",
      "             for f,v in feats \n",
      "             if feat_counts[f] >= MIN_FEAT_FREQ or f.startswith(\"WD:0\" )]\n",
      "        xs.append(x)        \n",
      "\n",
      "num_features = idgen.max_id() + 1\n",
      "print \"Number of features:\", num_features\n",
      "\n",
      "\"\"\" Convert to dense numpy arrays \"\"\"\n",
      "for i in ix2xs.keys():\n",
      "    xs = ix2xs[i]\n",
      "    xs = np.array([matutils.sparse2full(x, num_features) for x in xs])        \n",
      "    ix2xs[i] = xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 14289\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "\n",
      "def count_above(ft_counts, threshold):\n",
      "    above = [ v for k,v in ft_counts.items() if v >= threshold]\n",
      "    return (sum(above), len(above))\n",
      "\n",
      "total_all, cnt_all = count_above(feat_counts, 0)\n",
      "total_above, cnt_above = count_above(feat_counts, MIN_FEAT_FREQ)\n",
      "\n",
      "print \"Counts\"\n",
      "print \"all:     \", cnt_all\n",
      "print \"above:   \", cnt_above\n",
      "print \"% above: \", str(100.0 * cnt_above / float(cnt_all))+ \"%\"\n",
      "\n",
      "print \"\\nTotal Frequency\"\n",
      "print \"all:     \", total_all\n",
      "print \"above:   \", total_above\n",
      "print \"% above: \", str(100.0 * total_above / float(total_all))+ \"%\"\n",
      "\n",
      "#srtd = sort_by_value(feat_counts, reverse = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counts\n",
        "all:      69544\n",
        "above:    13985\n",
        "% above:  20.1095709191%\n",
        "\n",
        "Total Frequency\n",
        "all:      850041\n",
        "above:    766231\n",
        "% above:  90.1404755771%\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_window(win):\n",
      "    def set2str(st):\n",
      "        return \"{\" + str(t)[5:-2] + \"}\"\n",
      "    \n",
      "    w, tg = zip(*win)\n",
      "    lens = [max(len(wd),len(set2str(t))) for wd,t in win]\n",
      "    \n",
      "    for i, wd in enumerate(w):\n",
      "        print wd.ljust(lens[i]) , \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "    for i, t in enumerate(tg):\n",
      "        print set2str(t).ljust(lens[i]), \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "def extract_features(window, feat_vals):\n",
      "    feats = [idgen.get_key(i) for i,val in enumerate(feat_vals) if val]\n",
      "    \n",
      "    wd_feats = []\n",
      "    for win in window:\n",
      "        wd, tgs = win\n",
      "        if STEM:\n",
      "            match = filter(lambda feat: \" \" + stemmer.stem(wd) + \" \" in \" \" + feat + \" \", feats)\n",
      "        else:\n",
      "            match = filter(lambda feat: \" \" + wd + \" \" in \" \" + feat + \" \", feats)\n",
      "        wd_feats.append((wd, match))\n",
      "    return wd_feats\n",
      "\n",
      "def print_features(wf):\n",
      "    w_f = wf\n",
      "    for w,ft in w_f:\n",
      "        print w.ljust(10), map(lambda s:s.ljust(10), sorted(ft, key=lambda s:(len(s),s)))\n",
      "    print \"\"\n",
      "\n",
      "#uncomment to verify code output\n",
      "\n",
      "sentence_no = 101\n",
      "print \"Tagged Windows\"\n",
      "for win in ix2windows[sentence_no][:5]:\n",
      "    print_window(win)\n",
      "print \"\"    \n",
      "\n",
      "print \"Features\"\n",
      "def prn_sent_features(sentence_num):\n",
      "    win = ix2windows[sentence_num]\n",
      "    for i in range(len(win)):\n",
      "        print \"[%s]\" % str(i)\n",
      "        wf = extract_features(win[i], ix2xs[sentence_num][i])\n",
      "        print_features(wf)\n",
      "\n",
      "prn_sent_features(sentence_no)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tagged Windows\n",
        "<START> | <START> | <START> | the | passage | states | \"  | \n",
        "{}      | {}      | {}      | {}  | {}      | {}     | {} | \n",
        "<START> | <START> | the | passage | states | \"  | they | \n",
        "{}      | {}      | {}  | {}      | {}     | {} | {}   | \n",
        "<START> | the | passage | states | \"  | they | have | \n",
        "{}      | {}  | {}      | {}     | {} | {}   | {}   | \n",
        "the | passage | states | \"  | they | have | know | \n",
        "{}  | {}      | {}     | {} | {}   | {}   | {}   | \n",
        "passage | states | \"  | they | have | know | about | \n",
        "{}      | {}     | {} | {}   | {}   | {}   | {}    | \n",
        "\n",
        "Features\n",
        "[0]\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-1 <START>', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-1 <START> | the', 'BI:-2 <START> | <START>', 'BI:-3 <START> | <START>']\n",
        "the        ['the       ', 'WD:0 the  ', 'BI:-1 <START> | the']\n",
        "passage    ['passag    ', 'WD:1 passag']\n",
        "states     ['state     ', 'WD:2 state', 'BI:2 state | \"']\n",
        "\"          ['\"         ', 'WD:3 \"    ', 'BI:2 state | \"']\n",
        "\n",
        "[1]\n",
        "<START>    ['<START>   ', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-2 <START> | the', 'BI:-3 <START> | <START>']\n",
        "<START>    ['<START>   ', 'WD:-2 <START>', 'WD:-3 <START>', 'BI:-2 <START> | the', 'BI:-3 <START> | <START>']\n",
        "the        ['the       ', 'WD:-1 the ', 'BI:-2 <START> | the']\n",
        "passage    ['passag    ', 'WD:0 passag']\n",
        "states     ['state     ', 'WD:1 state', 'BI:1 state | \"']\n",
        "\"          ['\"         ', 'WD:2 \"    ', 'BI:1 state | \"']\n",
        "they       ['they      ', 'WD:3 they ']\n",
        "\n",
        "[2]\n",
        "<START>    ['<START>   ', 'WD:-3 <START>', 'BI:-3 <START> | the']\n",
        "the        ['the       ', 'WD:-2 the ', 'BI:-3 <START> | the']\n",
        "passage    ['passag    ', 'WD:-1 passag']\n",
        "states     ['state     ', 'WD:0 state', 'BI:0 state | \"']\n",
        "\"          ['\"         ', 'WD:1 \"    ', 'BI:0 state | \"']\n",
        "they       ['they      ', 'WD:2 they ', 'BI:2 they | have']\n",
        "have       ['have      ', 'WD:3 have ', 'BI:2 they | have']\n",
        "\n",
        "[3]\n",
        "the        ['the       ', 'WD:-3 the ']\n",
        "passage    ['passag    ', 'WD:-2 passag']\n",
        "states     ['state     ', 'WD:-1 state', 'BI:-1 state | \"']\n",
        "\"          ['\"         ', 'WD:0 \"    ', 'BI:-1 state | \"']\n",
        "they       ['they      ', 'WD:1 they ', 'BI:1 they | have']\n",
        "have       ['have      ', 'WD:2 have ', 'BI:1 they | have']\n",
        "know       ['know      ', 'WD:3 know ']\n",
        "\n",
        "[4]\n",
        "passage    ['passag    ', 'WD:-3 passag']\n",
        "states     ['state     ', 'WD:-2 state', 'BI:-2 state | \"']\n",
        "\"          ['\"         ', 'WD:-1 \"   ', 'BI:-2 state | \"']\n",
        "they       ['they      ', 'WD:0 they ', 'BI:0 they | have']\n",
        "have       ['have      ', 'WD:1 have ', 'BI:0 they | have']\n",
        "know       ['know      ', 'WD:2 know ']\n",
        "about      ['about     ', 'WD:3 about']\n",
        "\n",
        "[5]\n",
        "states     ['state     ', 'WD:-3 state', 'BI:-3 state | \"']\n",
        "\"          ['\"         ', 'WD:-2 \"   ', 'BI:-3 state | \"']\n",
        "they       ['they      ', 'WD:-1 they', 'BI:-1 they | have']\n",
        "have       ['have      ', 'WD:0 have ', 'BI:-1 they | have']\n",
        "know       ['know      ', 'WD:1 know ']\n",
        "about      ['about     ', 'WD:2 about', 'BI:2 about | chang']\n",
        "changes    ['chang     ', 'WD:3 chang', 'BI:2 about | chang']\n",
        "\n",
        "[6]\n",
        "\"          ['\"         ', 'WD:-3 \"   ']\n",
        "they       ['they      ', 'WD:-2 they', 'BI:-2 they | have']\n",
        "have       ['have      ', 'WD:-1 have', 'BI:-2 they | have']\n",
        "know       ['know      ', 'WD:0 know ']\n",
        "about      ['about     ', 'WD:1 about', 'BI:1 about | chang']\n",
        "changes    ['chang     ', 'WD:2 chang', 'BI:2 chang | in', 'BI:1 about | chang']\n",
        "in         ['in        ', 'WD:3 in   ', 'BI:2 chang | in']\n",
        "\n",
        "[7]\n",
        "they       ['they      ', 'WD:-3 they', 'BI:-3 they | have']\n",
        "have       ['have      ', 'WD:-2 have', 'BI:-3 they | have']\n",
        "know       ['know      ', 'WD:-1 know']\n",
        "about      ['about     ', 'WD:0 about', 'BI:0 about | chang']\n",
        "changes    ['chang     ', 'WD:1 chang', 'BI:1 chang | in', 'BI:0 about | chang']\n",
        "in         ['in        ', 'WD:2 in   ', 'BI:2 in | wind', 'BI:1 chang | in']\n",
        "wind       ['wind      ', 'WD:3 wind ', 'BI:2 in | wind']\n",
        "\n",
        "[8]\n",
        "have       ['have      ', 'WD:-3 have']\n",
        "know       ['know      ', 'WD:-2 know']\n",
        "about      ['about     ', 'WD:-1 about', 'BI:-1 about | chang']\n",
        "changes    ['chang     ', 'WD:0 chang', 'BI:0 chang | in', 'BI:-1 about | chang']\n",
        "in         ['in        ', 'WD:1 in   ', 'BI:1 in | wind', 'BI:0 chang | in']\n",
        "wind       ['wind      ', 'WD:2 wind ', 'BI:2 wind | ,', 'BI:1 in | wind']\n",
        ",          [',         ', 'WD:3 ,    ', 'BI:2 wind | ,']\n",
        "\n",
        "[9]\n",
        "know       ['know      ', 'WD:-3 know']\n",
        "about      ['about     ', 'WD:-2 about', 'BI:-2 about | chang']\n",
        "changes    ['chang     ', 'WD:-1 chang', 'BI:-1 chang | in', 'BI:-2 about | chang']\n",
        "in         ['in        ', 'WD:0 in   ', 'BI:0 in | wind', 'BI:-1 chang | in']\n",
        "wind       ['wind      ', 'WD:1 wind ', 'BI:1 wind | ,', 'BI:0 in | wind']\n",
        ",          [',         ', 'WD:2 ,    ', 'BI:1 wind | ,', 'BI:2 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:3 temperatur', 'BI:2 , | temperatur']\n",
        "\n",
        "[10]\n",
        "about      ['about     ', 'WD:-3 about', 'BI:-3 about | chang']\n",
        "changes    ['chang     ', 'WD:-2 chang', 'BI:-2 chang | in', 'BI:-3 about | chang']\n",
        "in         ['in        ', 'WD:-1 in  ', 'BI:-1 in | wind', 'BI:-2 chang | in']\n",
        "wind       ['wind      ', 'WD:0 wind ', 'BI:0 wind | ,', 'BI:-1 in | wind']\n",
        ",          [',         ', 'WD:1 ,    ', 'BI:0 wind | ,', 'BI:1 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:2 temperatur', 'BI:1 , | temperatur', 'BI:2 temperatur | .']\n",
        ".          ['.         ', 'WD:3 .    ', 'BI:2 temperatur | .']\n",
        "\n",
        "[11]\n",
        "changes    ['chang     ', 'WD:-3 chang', 'BI:-3 chang | in']\n",
        "in         ['in        ', 'WD:-2 in  ', 'BI:-2 in | wind', 'BI:-3 chang | in']\n",
        "wind       ['wind      ', 'WD:-1 wind', 'BI:-1 wind | ,', 'BI:-2 in | wind']\n",
        ",          [',         ', 'WD:0 ,    ', 'BI:-1 wind | ,', 'BI:0 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:1 temperatur', 'BI:0 , | temperatur', 'BI:1 temperatur | .']\n",
        ".          ['.         ', 'WD:2 .    ', 'BI:2 . | \"', 'BI:1 temperatur | .']\n",
        "\"          ['\"         ', 'WD:3 \"    ', 'BI:2 . | \"']\n",
        "\n",
        "[12]\n",
        "in        "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ['in        ', 'WD:-3 in  ', 'BI:-3 in | wind']\n",
        "wind       ['wind      ', 'WD:-2 wind', 'BI:-2 wind | ,', 'BI:-3 in | wind']\n",
        ",          [',         ', 'WD:-1 ,   ', 'BI:-2 wind | ,', 'BI:-1 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:0 temperatur', 'BI:0 temperatur | .', 'BI:-1 , | temperatur']\n",
        ".          ['.         ', 'WD:1 .    ', 'BI:1 . | \"', 'BI:0 temperatur | .']\n",
        "\"          ['\"         ', 'WD:2 \"    ', 'BI:1 . | \"', 'BI:2 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:3 <END>', 'BI:2 \" | <END>']\n",
        "\n",
        "[13]\n",
        "wind       ['wind      ', 'WD:-3 wind', 'BI:-3 wind | ,']\n",
        ",          [',         ', 'WD:-2 ,   ', 'BI:-3 wind | ,', 'BI:-2 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:-1 temperatur', 'BI:-1 temperatur | .', 'BI:-2 , | temperatur']\n",
        ".          ['.         ', 'WD:0 .    ', 'BI:0 . | \"', 'BI:-1 temperatur | .']\n",
        "\"          ['\"         ', 'WD:1 \"    ', 'BI:0 . | \"', 'BI:1 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:2 <END>', 'WD:3 <END>', 'BI:1 \" | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:2 <END>', 'WD:3 <END>', 'BI:1 \" | <END>', 'BI:2 <END> | <END>']\n",
        "\n",
        "[14]\n",
        ",          [',         ', 'WD:-3 ,   ', 'BI:-3 , | temperatur']\n",
        "temperatures ['temperatur', 'WD:-2 temperatur', 'BI:-2 temperatur | .', 'BI:-3 , | temperatur']\n",
        ".          ['.         ', 'WD:-1 .   ', 'BI:-1 . | \"', 'BI:-2 temperatur | .']\n",
        "\"          ['\"         ', 'WD:0 \"    ', 'BI:-1 . | \"', 'BI:0 \" | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "<END>      ['<END>     ', 'WD:1 <END>', 'WD:2 <END>', 'WD:3 <END>', 'BI:0 \" | <END>', 'BI:1 <END> | <END>', 'BI:2 <END> | <END>']\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_xs_ys(ixs, ixTOxs, ixTOys, codes):\n",
      "    xs = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    for i in ixs:\n",
      "        xs_tmp = ixTOxs[i]\n",
      "        xs.extend(xs_tmp)\n",
      "        ysByCode_tmp = ixTOys[i]\n",
      "        for code in codes:\n",
      "            ysByCode[code].extend(ysByCode_tmp[code])\n",
      "    return (np.array(xs), ysByCode)\n",
      "\n",
      "num_train = int(len(sentences) * (1.0 - PCT_VALIDATION))\n",
      "\n",
      "ixtest  = ix2sents.keys()[:num_train]\n",
      "ixvalid = ix2sents.keys()[num_train:]\n",
      "\n",
      "# Extract flattened windows for training data as xs and ys\n",
      "x_t, yByCode_t = extract_xs_ys(ixtest,ix2xs, ix2ys, all_codes)\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"#Sentences : \" + str(len(sentences))\n",
      "print \"\"\n",
      "\n",
      "all_codes = sorted(all_codes, key= lambda s :(len(s), s))\n",
      "for code in all_codes:\n",
      "    print code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#Sentences : 2624\n",
        "\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "50\n",
        "5b\n",
        "it\n",
        "other\n",
        "Causer\n",
        "Result\n",
        "Anaphor\n",
        "explicit\n",
        "rhetorical\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train\n",
      "====="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" TRAIN \"\"\"\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "map_svm = lambda y: -1 if y < 0 else 1\n",
      "map_reg = lambda y: y\n",
      "\n",
      "#map_y = map_svm\n",
      "map_y = map_reg\n",
      "\n",
      "#cls = DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, criterion=\"entropy\")\n",
      "#cls = DecisionTreeClassifier(criterion=\"entropy\")\n",
      "#cls = LogisticRegression()\n",
      "#cls = RidgeClassifier()\n",
      "#cls = LinearSVC()\n",
      "#cls = KNeighborsClassifier(n_neighbors=5) # TOO SLOW!\n",
      "#cls = LDA()\n",
      "#cls = SVC()\n",
      "#cls = RandomForestClassifier(n_jobs=-1, max_depth=100, n_estimators=10)\n",
      "#cls = Ridge()\n",
      "cls = LinearSVC\n",
      "\n",
      "print \"Starting Training\"\n",
      "reg_codes = [c for c in all_codes if c.isdigit() or c == \"explicit\"]\n",
      "\n",
      "def train(codes, xs, yByCode, fn_create_cls):\n",
      "    code2classifier = {}\n",
      "    for code in codes:\n",
      "        print \"Training for :\", code   \n",
      "        cls = fn_create_cls()\n",
      "        code2classifier[code] = cls\n",
      "        ys = np.asarray(yByCode[code])    \n",
      "        ys = map(map_y, ys)\n",
      "        cls.fit(xs, ys)\n",
      "    return code2classifier\n",
      "\n",
      "code2cls = train(all_codes, x_t, yByCode_t, cls)\n",
      "print cls\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting Training\n",
        "Training for : 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "<class 'sklearn.svm.classes.LinearSVC'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classify\n",
      "--------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Get sentence level classification performance \"\"\"\n",
      "def test_for_code(code, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    cls = codeToClassifier[code]\n",
      "    \n",
      "    try:\n",
      "        cls.n_jobs = 1\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "    act_ys  = []\n",
      "    pred_ys = []\n",
      "    for ix in ixs:\n",
      "        xs = ixToXs[ix]\n",
      "        ysByCode = ixToYs[ix]\n",
      "        \n",
      "        ys = np.asarray(ysByCode[code])\n",
      "        ys = map(map_y, ys)\n",
      "        pred = cls.predict(xs)\n",
      "        \n",
      "        # Flatten predictions to sentence level by taking the max values\n",
      "        # over all windows\n",
      "        act_ys.append(max(ys))\n",
      "        pred_ys.append(max(pred))\n",
      "    \n",
      "    num_codes = len([y for y in act_ys if y == 1])\n",
      "    r,p,f1,a = rpf1a(act_ys, pred_ys)\n",
      "    print \"code:      \", code\n",
      "    print \"recall:    \", r\n",
      "    print \"precision: \", p\n",
      "    print \"f1:        \", f1\n",
      "    print \"accuracy:  \", a\n",
      "    print \"sentences: \", num_codes\n",
      "    print \"\"\n",
      "    return rpfa(r,p,f1,a,num_codes)\n",
      "\n",
      "print \"\"\n",
      "print \"total sent:\", len(ixvalid)\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "total sent: 656\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training Data Performance\n",
      "-------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(codes, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    td_metrics = []\n",
      "    for c in codes:\n",
      "        cls = codeToClassifier[c]\n",
      "        td_metrics.append(test_for_code(c, ixs, ixToXs, ixToYs, codeToClassifier))\n",
      "    td_wt_mn_prfa = weighted_mean_rpfa(td_metrics)\n",
      "    print type(cls), td_wt_mn_prfa\n",
      "    return td_wt_mn_prfa\n",
      "\n",
      "print \"Training Data: \"\n",
      "metrics = test(all_codes, ixtest, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     0.995475113122\n",
        "precision:  0.990990990991\n",
        "f1:         0.993227990971\n",
        "accuracy:   0.998475609756\n",
        "sentences:  221\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.901960784314\n",
        "precision:  0.901960784314\n",
        "f1:         0.901960784314\n",
        "accuracy:   0.994918699187\n",
        "sentences:  51\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.996428571429\n",
        "precision:  0.975524475524\n",
        "f1:         0.985865724382\n",
        "accuracy:   0.99593495935\n",
        "sentences:  280\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  47\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     0.989690721649\n",
        "precision:  0.923076923077\n",
        "f1:         0.955223880597\n",
        "accuracy:   0.995426829268\n",
        "sentences:  97\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  27\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     1.0\n",
        "precision:  0.992248062016\n",
        "f1:         0.996108949416\n",
        "accuracy:   0.999491869919\n",
        "sentences:  128\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  50\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  23\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     0.967213114754\n",
        "precision:  0.983333333333\n",
        "f1:         0.97520661157\n",
        "accuracy:   0.998475609756\n",
        "sentences:  61\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     1.0\n",
        "precision:  0.846153846154\n",
        "f1:         0.916666666667\n",
        "accuracy:   0.997967479675\n",
        "sentences:  22\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.997385620915\n",
        "precision:  0.98962386511\n",
        "f1:         0.993489583333\n",
        "accuracy:   0.994918699187\n",
        "sentences:  765\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "recall:     0.909090909091\n",
        "precision:  1.0\n",
        "f1:         0.952380952381\n",
        "accuracy:   0.999491869919\n",
        "sentences:  11\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  1\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "recall:     0.827777777778\n",
        "precision:  0.980263157895\n",
        "f1:         0.897590361446\n",
        "accuracy:   0.982723577236\n",
        "sentences:  180\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "recall:     0.974117647059\n",
        "precision:  0.930337078652\n",
        "f1:         0.951724137931\n",
        "accuracy:   0.978658536585\n",
        "sentences:  425\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "recall:     0.893518518519\n",
        "precision:  0.919047619048\n",
        "f1:         0.906103286385\n",
        "accuracy:   0.959349593496\n",
        "sentences:  432\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "recall:     0.962264150943\n",
        "precision:  1.0\n",
        "f1:         0.980769230769\n",
        "accuracy:   0.997967479675\n",
        "sentences:  106\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.975113122172\n",
        "precision:  0.981776765376\n",
        "f1:         0.978433598184\n",
        "accuracy:   0.990345528455\n",
        "sentences:  442\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "recall:     0.986111111111\n",
        "precision:  0.965986394558\n",
        "f1:         0.975945017182\n",
        "accuracy:   0.996443089431\n",
        "sentences:  144\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.9664, Precision: 0.9671, F1: 0.9662, Accuracy: 0.9883, Codes:  3513\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Validation Data Performance\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data: \"\n",
      "test(reg_codes, ixvalid, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     0.94623655914\n",
        "precision:  0.752136752137\n",
        "f1:         0.838095238095\n",
        "accuracy:   0.948170731707\n",
        "sentences:  93\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.516129032258\n",
        "precision:  0.615384615385\n",
        "f1:         0.561403508772\n",
        "accuracy:   0.961890243902\n",
        "sentences:  31\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.856\n",
        "precision:  0.66049382716\n",
        "f1:         0.745644599303\n",
        "accuracy:   0.888719512195\n",
        "sentences:  125\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     0.913043478261\n",
        "precision:  0.7\n",
        "f1:         0.792452830189\n",
        "accuracy:   0.983231707317\n",
        "sentences:  23\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     0.818181818182\n",
        "precision:  0.514285714286\n",
        "f1:         0.631578947368\n",
        "accuracy:   0.935975609756\n",
        "sentences:  44\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     1.0\n",
        "precision:  0.4\n",
        "f1:         0.571428571429\n",
        "accuracy:   0.986280487805\n",
        "sentences:  6\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     0.8\n",
        "precision:  0.565217391304\n",
        "f1:         0.662420382166\n",
        "accuracy:   0.919207317073\n",
        "sentences:  65\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     0.8125\n",
        "precision:  0.928571428571\n",
        "f1:         0.866666666667\n",
        "accuracy:   0.993902439024\n",
        "sentences:  16\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     0.846153846154\n",
        "precision:  1.0\n",
        "f1:         0.916666666667\n",
        "accuracy:   0.996951219512\n",
        "sentences:  13\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     0.857142857143\n",
        "precision:  0.705882352941\n",
        "f1:         0.774193548387\n",
        "accuracy:   0.978658536585\n",
        "sentences:  28\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     0.8\n",
        "precision:  0.8\n",
        "f1:         0.8\n",
        "accuracy:   0.990853658537\n",
        "sentences:  15\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.975524475524\n",
        "precision:  0.914754098361\n",
        "f1:         0.944162436548\n",
        "accuracy:   0.949695121951\n",
        "sentences:  286\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.656626506024\n",
        "precision:  0.497716894977\n",
        "f1:         0.566233766234\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.8496, Precision: 0.7171, F1: 0.7734, Accuracy: 0.9056, Codes:   911\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "Recall: 0.8496, Precision: 0.7171, F1: 0.7734, Accuracy: 0.9056, Codes:   911"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Window - 5, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LDA:      Recall: 0.8927, Precision: 0.6974, F1: 0.7675, Accuracy: 0.8823, Codes:   792\n",
      "LinSVC:   Recall: 0.7601, Precision: 0.7655, F1: 0.7563, Accuracy: 0.9048, Codes:   792\n",
      "DT:       Recall: 0.7462, Precision: 0.6890, F1: 0.7063, Accuracy: 0.8766, Codes:   792\n",
      "RidgeClf: Recall: 0.6843, Precision: 0.8359, F1: 0.6874, Accuracy: 0.9036, Codes:   795\n",
      "\n",
      "LinSVC\n",
      "Window - 7, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LinSVC: Recall: 0.7937, Precision: 0.7522, F1: 0.7677, Accuracy: 0.9037, Codes:   795\n",
      "\n",
      "Window - 9, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.7887, Precision: 0.7338, F1: 0.7555, Accuracy: 0.8929, Codes:   795\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.8058, Precision: 0.7559, F1: 0.7756, Accuracy: 0.9046, Codes:   798\n",
      "\n",
      "-- Starting adding new features, messing with feature freq\n",
      "Window - 5, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8008, Precision: 0.7369, F1: 0.7625, Accuracy: 0.9008, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8120, Precision: 0.7535, F1: 0.7779, Accuracy: 0.9066, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - ***15***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8145, Precision: 0.7460, F1: 0.7744, Accuracy: 0.9040, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 20\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7982, Precision: 0.7496, F1: 0.7685, Accuracy: 0.9025, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 25\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8070, Precision: 0.7485, F1: 0.7732, Accuracy: 0.9047, Codes:   798\n",
      "\n",
      "***\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 5 ***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "    + Positional BI-GRAMS ****\n",
      "Recall: 0.8145, Precision: 0.7642, F1: 0.7831, Accuracy: 0.9070, Codes:   798\n",
      "***\n",
      "\n",
      "Logistic Regression\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7306, Precision: 0.8298, F1: 0.7672, Accuracy: 0.9150, Codes:   798\n",
      "\n",
      "Window - 9, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7206, Precision: 0.8232, F1: 0.7580, Accuracy: 0.9121, Codes:   798\n",
      "\n",
      "RF\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit')\n",
      "Recall: 0.6028, Precision: 0.8071, F1: 0.6570, Accuracy: 0.8978, Codes:   798"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train Stacked Classifier\n",
      "========================"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Create Data Using Previous Classifier \"\"\"\n",
      "ix2newxs = {}\n",
      "ix2newys = {} #dict to dict to list\n",
      "\n",
      "CAUSAL_REL = \"CRel\"\n",
      "RESULT_REL = \"RRel\"\n",
      "CAUSE_RESULT = \"C->R\"\n",
      "\n",
      "cr_codes = [CAUSAL_REL, RESULT_REL, CAUSE_RESULT]\n",
      "tally = defaultdict(lambda: defaultdict(int))\n",
      "codes_per_row = []\n",
      "str_codes = []\n",
      "for i,xs in ix2xs.items():\n",
      "    \n",
      "    tmp_xs = []\n",
      "    tmp_ys = []\n",
      "    tmp_ys_by_code = defaultdict(list)\n",
      "\n",
      "    # add BOW features\n",
      "    tmp_xs.extend(ix2vector[i])\n",
      "    \n",
      "    un_codes = set()\n",
      "    un_pred_codes = set()\n",
      "    s_codes = \"|\"\n",
      "    for code in all_codes:\n",
      "        cls = code2cls[code]\n",
      "        pred = cls.decision_function(xs)\n",
      "        # add min and max values\n",
      "        mx = max(pred)\n",
      "        mn = min(pred)\n",
      "        diff = mx - mn\n",
      "        yes_no = max(cls.predict(xs))\n",
      "        \n",
      "        tmp_xs.append(mx)\n",
      "        tmp_xs.append(mn)\n",
      "        #tmp_xs.append(diff)\n",
      "        tmp_xs.append(yes_no)\n",
      "        \n",
      "        y_val = max(ix2ys[i][code])\n",
      "        tmp_ys_by_code[code] = np.array([y_val])\n",
      "        if y_val > 0:\n",
      "            un_codes.add(code)\n",
      "\n",
      "        if yes_no > 0:\n",
      "            un_pred_codes.add(code)\n",
      "            s_codes += code + \"|\"\n",
      "    codes_per_row.append(un_pred_codes)\n",
      "    str_codes.append(s_codes)\n",
      "    \n",
      "    #add 2 way feature combos\n",
      "    for a in all_codes:\n",
      "        for b in all_codes:\n",
      "            if b < a:\n",
      "                if a in un_pred_codes and b in un_pred_codes:\n",
      "                    tmp_xs.append(1)\n",
      "                else:\n",
      "                    tmp_xs.append(0)\n",
      "            #if (\"|%s|%s|\" %(a,b)) in s_codes:\n",
      "            #    tmp_xs.append(1)\n",
      "            #else:\n",
      "            #    tmp_xs.append(0)            \n",
      "            \n",
      "    tmp_ys_by_code[CAUSAL_REL] = np.array([ 1 if \"Causer\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[RESULT_REL] = np.array([ 1 if \"Result\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[CAUSE_RESULT] = np.array([ 1 if (\"Result\" in un_codes and \"explicit\" in un_codes and \"Causer\" in un_codes) else 0 ])\n",
      "    \n",
      "    for k,v in tmp_ys_by_code.items():\n",
      "        tally[k][max(v)] += 1\n",
      "        \n",
      "    ix2newxs[i] = np.array([tmp_xs])\n",
      "    ix2newys[i] = tmp_ys_by_code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,s in enumerate(str_codes):\n",
      "    print str(i).ljust(5), s\n",
      "    if i > 20:\n",
      "        break\n",
      "print ix2newxs[15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     |50|\n",
        "1     |50|\n",
        "2     |\n",
        "3     |\n",
        "4     |\n",
        "5     |1|\n",
        "6     |\n",
        "7     |\n",
        "8     |\n",
        "9     |\n",
        "10    |\n",
        "11    |\n",
        "12    |\n",
        "13    |\n",
        "14    |\n",
        "15    |7|50|Causer|Result|explicit|\n",
        "16    |50|\n",
        "17    |1|\n",
        "18    |2|\n",
        "19    |\n",
        "20    |\n",
        "21    |\n",
        "[[ 0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.26726124\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.26726124  0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.26726124  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.26726124  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.26726124  0.26726124  0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.26726124  0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.26726124  0.          0.          0.          0.          0.\n",
        "   0.          0.          0.26726124  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.26726124  0.26726124  0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.26726124  0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.26726124\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.26726124  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.\n",
        "  -1.14588885 -4.9194171   0.         -2.38336229 -3.94716234  0.\n",
        "  -1.93844708 -4.23718654  0.         -1.71348899 -3.02678092  0.\n",
        "  -1.49293405 -5.0405815   0.         -1.49547434 -3.21559997  0.\n",
        "   3.02971555 -3.1329509   1.         -1.52472378 -2.81506575  0.\n",
        "  -1.40988815 -2.59382639  0.         -2.08372863 -3.25042608  0.\n",
        "  -1.83288077 -2.82906795  0.          1.89452776 -3.8423496   1.\n",
        "  -1.86537657 -3.02296708  0.         -1.43019862 -1.91143906  0.\n",
        "  -0.96407932 -3.11160942  0.          1.80480228 -3.61201439  1.\n",
        "   2.00171462 -2.90550746  1.         -1.05784965 -3.31609188  0.\n",
        "   2.65527438 -3.68858459  1.         -0.90930525 -3.5134025   0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          1.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          1.\n",
        "   0.          0.          0.          0.          1.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          1.\n",
        "   0.          0.          0.          0.          1.          0.          1.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          1.\n",
        "   0.          0.          0.          0.          1.          0.          1.\n",
        "   1.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_plus_cr = all_codes + cr_codes\n",
      "newx_t, yByCode_t = extract_xs_ys(ixtest, ix2newxs, ix2newys, all_plus_cr)\n",
      "print newx_t[0].shape, \"features\"\n",
      "\n",
      "# SVM Is best when using joint features\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, sklearn.ensemble.GradientBoostingClassifier)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LDA)\n",
      "new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LinearSVC)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LogisticRegression)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, DecisionTreeClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(912,) features\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct = {}\n",
      "codes = cr_codes + [\"explicit\"] #[CAUSE_RESULT]\n",
      "for c in [1.0, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5]:\n",
      "    print \"C\", c\n",
      "    new_code2cls = train(codes, newx_t, yByCode_t, lambda : LinearSVC(C = float(c)))\n",
      "    dct[c] = test(codes, ixvalid, ix2newxs, ix2newys, new_code2cls)\n",
      "\n",
      "print \"\"\n",
      "for k,v in sorted(dct.items()):\n",
      "    print \"C\", str(k).ljust(5), \"Metric:\",v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C 1.0\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.535398230088\n",
        "f1:         0.625322997416\n",
        "accuracy:   0.778963414634\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.740740740741\n",
        "precision:  0.524017467249\n",
        "f1:         0.613810741688\n",
        "accuracy:   0.769817073171\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59375\n",
        "f1:         0.645892351275\n",
        "accuracy:   0.809451219512\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.5\n",
        "f1:         0.608490566038\n",
        "accuracy:   0.746951219512\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7446, Precision: 0.5380, F1: 0.6232, Accuracy: 0.7761, Codes:   650\n",
        "C 1.5\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.757763975155\n",
        "precision:  0.535087719298\n",
        "f1:         0.627249357326\n",
        "accuracy:   0.778963414634\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.746913580247\n",
        "precision:  0.519313304721\n",
        "f1:         0.612658227848\n",
        "accuracy:   0.766768292683\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59375\n",
        "f1:         0.645892351275\n",
        "accuracy:   0.809451219512\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.501945525292\n",
        "f1:         0.609929078014\n",
        "accuracy:   0.748475609756\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7477, Precision: 0.5372, F1: 0.6238, Accuracy: 0.7757, Codes:   650\n",
        "C 1.6\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.537777777778\n",
        "f1:         0.626943005181\n",
        "accuracy:   0.780487804878\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.734567901235\n",
        "precision:  0.519650655022\n",
        "f1:         0.608695652174\n",
        "accuracy:   0.766768292683\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59067357513\n",
        "f1:         0.64406779661\n",
        "accuracy:   0.807926829268\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.494252873563\n",
        "f1:         0.604215456674\n",
        "accuracy:   0.74237804878\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7431, Precision: 0.5352, F1: 0.6208, Accuracy: 0.7741, Codes:   650\n",
        "C 1.7\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.739130434783\n",
        "precision:  0.52422907489\n",
        "f1:         0.613402061856\n",
        "accuracy:   0.771341463415\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.734567901235\n",
        "precision:  0.519650655022\n",
        "f1:         0.608695652174\n",
        "accuracy:   0.766768292683\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59067357513\n",
        "f1:         0.64406779661\n",
        "accuracy:   0.807926829268\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7400, Precision: 0.5329, F1: 0.6182, Accuracy: 0.7726, Codes:   650\n",
        "C 1.8\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.757763975155\n",
        "precision:  0.530434782609\n",
        "f1:         0.624040920716\n",
        "accuracy:   0.775914634146\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.753086419753\n",
        "precision:  0.51914893617\n",
        "f1:         0.614609571788\n",
        "accuracy:   0.766768292683\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59067357513\n",
        "f1:         0.64406779661\n",
        "accuracy:   0.807926829268\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7492, Precision: 0.5343, F1: 0.6223, Accuracy: 0.7738, Codes:   650\n",
        "C 1.9\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.530701754386\n",
        "f1:         0.622107969152\n",
        "accuracy:   0.775914634146\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.740740740741\n",
        "precision:  0.524017467249\n",
        "f1:         0.613810741688\n",
        "accuracy:   0.769817073171\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.59375\n",
        "f1:         0.645892351275\n",
        "accuracy:   0.809451219512\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.5\n",
        "f1:         0.608490566038\n",
        "accuracy:   0.746951219512\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7446, Precision: 0.5368, F1: 0.6225, Accuracy: 0.7753, Codes:   650\n",
        "C 2.0\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.757763975155\n",
        "precision:  0.532751091703\n",
        "f1:         0.625641025641\n",
        "accuracy:   0.77743902439\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.808641975309\n",
        "precision:  0.503846153846\n",
        "f1:         0.620853080569\n",
        "accuracy:   0.756097560976\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.689440993789\n",
        "precision:  0.613259668508\n",
        "f1:         0.649122807018\n",
        "accuracy:   0.817073170732\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7585, Precision: 0.5366, F1: 0.6255, Accuracy: 0.7738, Codes:   650\n",
        "C 2.1\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.757763975155\n",
        "precision:  0.528138528139\n",
        "f1:         0.622448979592\n",
        "accuracy:   0.774390243902\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.753086419753\n",
        "precision:  0.512605042017\n",
        "f1:         0.61\n",
        "accuracy:   0.762195121951\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.596858638743\n",
        "f1:         0.647727272727\n",
        "accuracy:   0.810975609756\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.501945525292\n",
        "f1:         0.609929078014\n",
        "accuracy:   0.748475609756\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7492, Precision: 0.5346, F1: 0.6224, Accuracy: 0.7738, Codes:   650\n",
        "C 2.2\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.530701754386\n",
        "f1:         0.622107969152\n",
        "accuracy:   0.775914634146\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.734567901235\n",
        "precision:  0.512931034483\n",
        "f1:         0.604060913706\n",
        "accuracy:   0.762195121951\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.584615384615\n",
        "f1:         0.640449438202\n",
        "accuracy:   0.80487804878\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7431, Precision: 0.5313, F1: 0.6183, Accuracy: 0.7719, Codes:   650\n",
        "C 2.3\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.535398230088\n",
        "f1:         0.625322997416\n",
        "accuracy:   0.778963414634\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.740740740741\n",
        "precision:  0.521739130435\n",
        "f1:         0.612244897959\n",
        "accuracy:   0.768292682927\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.596858638743\n",
        "f1:         0.647727272727\n",
        "accuracy:   0.810975609756\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.501945525292\n",
        "f1:         0.609929078014\n",
        "accuracy:   0.748475609756\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7446, Precision: 0.5387, F1: 0.6237, Accuracy: 0.7764, Codes:   650\n",
        "C 2.4\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.535398230088\n",
        "f1:         0.625322997416\n",
        "accuracy:   0.778963414634\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.746913580247\n",
        "precision:  0.514893617021\n",
        "f1:         0.609571788413\n",
        "accuracy:   0.763719512195\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.714285714286\n",
        "precision:  0.580808080808\n",
        "f1:         0.640668523677\n",
        "accuracy:   0.803353658537\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7477, Precision: 0.5320, F1: 0.6205, Accuracy: 0.7726, Codes:   650\n",
        "C 2.5\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.533039647577\n",
        "f1:         0.623711340206\n",
        "accuracy:   0.77743902439\n",
        "sentences:  161\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.740740740741\n",
        "precision:  0.515021459227\n",
        "f1:         0.607594936709\n",
        "accuracy:   0.763719512195\n",
        "sentences:  162\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.587628865979\n",
        "f1:         0.642253521127\n",
        "accuracy:   0.806402439024\n",
        "sentences:  161\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7446, Precision: 0.5331, F1: 0.6200, Accuracy: 0.7730, Codes:   650\n",
        "\n",
        "C 1.0   Metric: Recall: 0.7446, Precision: 0.5380, F1: 0.6232, Accuracy: 0.7761, Codes:   650\n",
        "C 1.5   Metric: Recall: 0.7477, Precision: 0.5372, F1: 0.6238, Accuracy: 0.7757, Codes:   650\n",
        "C 1.6   Metric: Recall: 0.7431, Precision: 0.5352, F1: 0.6208, Accuracy: 0.7741, Codes:   650\n",
        "C 1.7   Metric: Recall: 0.7400, Precision: 0.5329, F1: 0.6182, Accuracy: 0.7726, Codes:   650\n",
        "C 1.8   Metric: Recall: 0.7492, Precision: 0.5343, F1: 0.6223, Accuracy: 0.7738, Codes:   650\n",
        "C 1.9   Metric: Recall: 0.7446, Precision: 0.5368, F1: 0.6225, Accuracy: 0.7753, Codes:   650\n",
        "C 2.0   Metric: Recall: 0.7585, Precision: 0.5366, F1: 0.6255, Accuracy: 0.7738, Codes:   650\n",
        "C 2.1   Metric: Recall: 0.7492, Precision: 0.5346, F1: 0.6224, Accuracy: 0.7738, Codes:   650\n",
        "C 2.2   Metric: Recall: 0.7431, Precision: 0.5313, F1: 0.6183, Accuracy: 0.7719, Codes:   650\n",
        "C 2.3   Metric: Recall: 0.7446, Precision: 0.5387, F1: 0.6237, Accuracy: 0.7764, Codes:   650\n",
        "C 2.4   Metric: Recall: 0.7477, Precision: 0.5320, F1: 0.6205, Accuracy: 0.7726, Codes:   650\n",
        "C 2.5   Metric: Recall: 0.7446, Precision: 0.5331, F1: 0.6200, Accuracy: 0.7730, Codes:   650\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Test Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixtest, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Data #2: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     1.0\n",
        "precision:  0.997624703088\n",
        "f1:         0.998810939358\n",
        "accuracy:   0.999491869919\n",
        "sentences:  420\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     1.0\n",
        "precision:  0.997641509434\n",
        "f1:         0.998819362456\n",
        "accuracy:   0.999491869919\n",
        "sentences:  423\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     1.0\n",
        "precision:  0.997555012225\n",
        "f1:         0.998776009792\n",
        "accuracy:   0.999491869919\n",
        "sentences:  408\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     1.0\n",
        "precision:  0.997742663657\n",
        "f1:         0.998870056497\n",
        "accuracy:   0.999491869919\n",
        "sentences:  442\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 1.0000, Precision: 0.9976, F1: 0.9988, Accuracy: 0.9995, Codes:  1693\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixvalid, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data #2: \n",
        "code:       CRel\n",
        "recall:     0.751552795031\n",
        "precision:  0.533039647577\n",
        "f1:         0.623711340206\n",
        "accuracy:   0.77743902439\n",
        "sentences:  161\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.740740740741\n",
        "precision:  0.515021459227\n",
        "f1:         0.607594936709\n",
        "accuracy:   0.763719512195\n",
        "sentences:  162\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.708074534161\n",
        "precision:  0.587628865979\n",
        "f1:         0.642253521127\n",
        "accuracy:   0.806402439024\n",
        "sentences:  161\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.777108433735\n",
        "precision:  0.498069498069\n",
        "f1:         0.607058823529\n",
        "accuracy:   0.745426829268\n",
        "sentences:  166\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7446, Precision: 0.5331, F1: 0.6200, Accuracy: 0.7730, Codes:   650\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Using Min\\Max Distance from Decision Plane\n",
      "  Single Features\n",
      "***\n",
      "<class 'LDA'> Recall: 0.6797, Precision: 0.6151, F1: 0.6458, Accuracy: 0.7784, Codes:   637\n",
      "***\n",
      "<class 'LinearSVC'> Recall: 0.6562, Precision: 0.6069, F1: 0.6297, Accuracy: 0.7704, Codes:   637\n",
      "<class 'logistic.LogisticRegression'> Recall: 0.6578, Precision: 0.6207, F1: 0.6379, Accuracy: 0.7784, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6185, Precision: 0.6458, F1: 0.6288, Accuracy: 0.7835, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5950, Precision: 0.6334, F1: 0.6118, Accuracy: 0.7755, Codes:   637\n",
      "    \n",
      "  Joint Features\n",
      "<class 'sklearn.lda.LDA'> Recall: 0.5667, Precision: 0.6260, F1: 0.5934, Accuracy: 0.7700, Codes:   637\n",
      "***\n",
      "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6703, Precision: 0.6323, F1: 0.6502, Accuracy: 0.7853, Codes:   637\n",
      "***\n",
      "code:       C->R\n",
      "recall:     0.677215189873\n",
      "precision:  0.685897435897\n",
      "f1:         0.68152866242\n",
      "accuracy:   0.813432835821\n",
      "sentences:  158\n",
      "<class 'LogisticRegression'> Recall: 0.6342, Precision: 0.6539, F1: 0.6424, Accuracy: 0.7900, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6075, Precision: 0.6396, F1: 0.6196, Accuracy: 0.7793, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5651, Precision: 0.6236, F1: 0.5896, Accuracy: 0.7672, Codes:   637"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*** TODO *** - Peter\\Simon 5.14.2014\n",
      "Match Explicit + Cause or Result (or both)\n",
      "Try reading this: http://ceur-ws.org/Vol-1109/paper4.pdf\n",
      "Read Peter's paper\n",
      "\n",
      "1. <s>Try removing commas and '\"''s and other punctuation</s>\n",
      "2. <s>Try skip gram features (Peter)</s>\n",
      "3. Dependency parse \n",
      "    - span of words for the explicit and the concept\n",
      "    - find any depencencies tha join those two groups\n",
      "    - dependency type\n",
      "        - NSUBJ or PREP_TO or CONJ_AND\n",
      "        - OR advmod, conj_and, dobj, prep_of, prep_in\n",
      "        - OR acomp,  advmod\n",
      "4. <s>Read Peter's latest paper </s>\n",
      "5. Read related papers - Semeval 2007 (or close), Rink et al, Girju et al, etc\n",
      "5. <s>Try training a second classifier based on the output of the first including the predictions for the previous and next word</s>\n",
      "6. Add in sentence level features, such as BOW and dependency parse features\n",
      "7. Do some cross validation\n",
      "8. Add in predicted codes from previous \\ next sentence\n",
      "9. Try blending multiple window based classifiers (Log R, SVM, LDA, DT) using a regression model\n",
      "\"\"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}