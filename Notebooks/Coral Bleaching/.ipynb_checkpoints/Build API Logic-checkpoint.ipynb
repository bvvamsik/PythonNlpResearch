{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Settings\n",
    "from model_store import ModelStore\n",
    "from window_based_tagger_config import get_config\n",
    "from processessays import process_essays, build_spelling_corrector\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import defaultdict\n",
    "from BrattEssay import Essay, load_bratt_essays\n",
    "\n",
    "from featureextractortransformer import FeatureExtractorTransformer\n",
    "from sent_feats_for_stacking import *\n",
    "from load_data import load_process_essays_without_annotations\n",
    "\n",
    "from featureextractionfunctions import *\n",
    "from wordtagginghelper import *\n",
    "\n",
    "from traceback import format_exc\n",
    "\n",
    "import logging\n",
    "\n",
    "def onlyascii(s):\n",
    "    out = \"\"\n",
    "    for char in s:\n",
    "        if ord(char) > 127:\n",
    "            out += \"\"\n",
    "        else:\n",
    "            out += char\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Annotator(object):\n",
    "\n",
    "    def __init__(self, models_folder, temp_folder, essays_folder):\n",
    "\n",
    "        logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "        if not models_folder.endswith(\"/\"):\n",
    "            models_folder += \"/\"\n",
    "        if not temp_folder.endswith(\"/\"):\n",
    "            temp_folder += \"/\"\n",
    "        if not essays_folder.endswith(\"/\"):\n",
    "            essays_folder += \"/\"\n",
    "\n",
    "        self.logger = logging.getLogger()\n",
    "        self.temp_folder = temp_folder\n",
    "        cfg = get_config(temp_folder)\n",
    "        self.config = cfg\n",
    "        self.essays_folder = essays_folder\n",
    "\n",
    "        # Create spell checker\n",
    "        # Need annotations here purely to load the tags\n",
    "        tagged_essays = load_bratt_essays(essays_folder, include_vague=cfg[\"include_vague\"], include_normal=cfg[\"include_normal\"], load_annotations=True)\n",
    "        self.__set_tags_(tagged_essays)\n",
    "        self.wd_sent_freq = defaultdict(int)\n",
    "        self.spelling_corrector = build_spelling_corrector(tagged_essays, self.config[\"lower_case\"], self.wd_sent_freq)\n",
    "\n",
    "        offset = (self.config[\"window_size\"] - 1) / 2\n",
    "\n",
    "        unigram_window_stemmed = fact_extract_positional_word_features_stemmed(offset)\n",
    "        biigram_window_stemmed = fact_extract_ngram_features_stemmed(offset, 2)\n",
    "\n",
    "        extractors = [unigram_window_stemmed, biigram_window_stemmed]\n",
    "\n",
    "        # most params below exist ONLY for the purposes of the hashing to and from disk\n",
    "        self.feature_extractor = FeatureExtractorTransformer(extractors)\n",
    "\n",
    "        # load models\n",
    "        self.logger.info(\"Loading pickled models\")\n",
    "        store = ModelStore(models_folder=models_folder)\n",
    "\n",
    "        self.feature_transformer =  store.get_transformer()\n",
    "        self.logger.info(\"Loaded Transformer\")\n",
    "        self.tag_2_wd_classifier = store.get_tag_2_wd_classifier()\n",
    "        self.logger.info(\"Loaded word tagging model\")\n",
    "        self.tag_2_sent_classifier = store.get_tag_2_sent_classifier()\n",
    "        self.logger.info(\"Loaded sentence classifier\")\n",
    "\n",
    "    def __set_tags_(self, tagged_essays):\n",
    "\n",
    "        MIN_TAG_FREQ = 5\n",
    "\n",
    "        tag_freq = defaultdict(int)\n",
    "        for essay in tagged_essays:\n",
    "            for sentence in essay.tagged_sentences:\n",
    "                un_tags = set()\n",
    "                for word, tags in sentence:\n",
    "                    for tag in tags:\n",
    "                        if \"5b\" in tag:\n",
    "                            continue\n",
    "                        if      (tag[-1].isdigit() or tag in {\"Causer\", \"explicit\", \"Result\"} \\\n",
    "                                    or tag.startswith(\"Causer\") or tag.startswith(\"Result\") \\\n",
    "                                    or tag.startswith(\"explicit\") or \"->\" in tag) \\\n",
    "                                and not (\"Anaphor\" in tag or \"rhetorical\" in tag or \"other\" in tag):\n",
    "                            # if not (\"Anaphor\" in tag or \"rhetorical\" in tag or \"other\" in tag):\n",
    "                            un_tags.add(tag)\n",
    "                for tag in un_tags:\n",
    "                    tag_freq[tag] += 1\n",
    "\n",
    "        all_tags = list(tag_freq.keys())\n",
    "        freq_tags = list(set((tag for tag, freq in tag_freq.items() if freq >= MIN_TAG_FREQ)))\n",
    "        non_causal = [t for t in freq_tags if \"->\" not in t]\n",
    "        only_causal = [t for t in freq_tags if \"->\" in t]\n",
    "\n",
    "        CAUSE_TAGS = [\"Causer\", \"Result\", \"explicit\"]\n",
    "        CAUSAL_REL_TAGS = [CAUSAL_REL, CAUSE_RESULT, RESULT_REL]  # + [\"explicit\"]\n",
    "\n",
    "        \"\"\" works best with all the pair-wise causal relation codes \"\"\"\n",
    "        # Include all tags for the output\n",
    "        self.wd_test_tags = list(set(all_tags + CAUSE_TAGS))\n",
    "\n",
    "        # tags from tagging model used to train the stacked model\n",
    "        self.sent_input_feat_tags = list(set(freq_tags + CAUSE_TAGS))\n",
    "        # find interactions between these predicted tags from the word tagger to feed to the sentence tagger\n",
    "        self.sent_input_interaction_tags = list(set(non_causal + CAUSE_TAGS))\n",
    "        # tags to train (as output) for the sentence based classifier\n",
    "        self.sent_output_train_test_tags = list(set(all_tags + CAUSE_TAGS + CAUSAL_REL_TAGS))\n",
    "\n",
    "    def annotate(self, essay_text):\n",
    "\n",
    "        try:\n",
    "            sentences = sent_tokenize(essay_text.strip())\n",
    "            contents = \"\\n\".join(sentences)\n",
    "\n",
    "            fname = self.temp_folder + \"essay.txt\"\n",
    "            with open(fname, 'w\"') as f:\n",
    "                f.write(contents)\n",
    "\n",
    "            essay = Essay(fname, include_vague=self.config[\"include_vague\"],\n",
    "                          include_normal=self.config[\"include_normal\"], load_annotations=False)\n",
    "\n",
    "            processed_essays = process_essays(essays=[essay],\n",
    "                                              spelling_corrector=self.spelling_corrector,\n",
    "                                              wd_sent_freq=self.wd_sent_freq,\n",
    "                                              remove_infrequent=self.config[\"remove_infrequent\"],\n",
    "                                              spelling_correct=self.config[\"spelling_correct\"],\n",
    "                                              replace_nums=self.config[\"replace_nums\"],\n",
    "                                              stem=self.config[\"stem\"],\n",
    "                                              remove_stop_words=self.config[\"remove_stop_words\"],\n",
    "                                              remove_punctuation=self.config[\"remove_punctuation\"],\n",
    "                                              lower_case=self.config[\"lower_case\"])\n",
    "\n",
    "            self.logger.info(\"Essay loaded successfully\")\n",
    "            essays_TD = self.feature_extractor.transform(processed_essays)\n",
    "\n",
    "            wd_feats, _ = flatten_to_wordlevel_feat_tags(essays_TD)\n",
    "            xs = self.feature_transformer.transform(wd_feats)\n",
    "            wd_predictions_by_code = test_classifier_per_code(xs, self.tag_2_wd_classifier, self.wd_test_tags)\n",
    "\n",
    "            dummy_wd_td_ys_bytag = defaultdict(lambda: np.asarray([0.0] * xs.shape[0]))\n",
    "            sent_xs, sent_ys_bycode = get_sent_feature_for_stacking_from_tagging_model(self.sent_input_feat_tags,\n",
    "                                                                                             self.sent_input_interaction_tags,\n",
    "                                                                                             essays_TD, xs,\n",
    "                                                                                             dummy_wd_td_ys_bytag,\n",
    "                                                                                             self.tag_2_wd_classifier,\n",
    "                                                                                             sparse=True,\n",
    "                                                                                             look_back=0)\n",
    "\n",
    "            \"\"\" Test Stack Classifier \"\"\"\n",
    "            sent_predictions_by_code = test_classifier_per_code(sent_xs, self.tag_2_sent_classifier, self.sent_output_train_test_tags)\n",
    "\n",
    "            return {\"tagged_words\":      self.__get_tagged_words_(essay, essays_TD[0], wd_predictions_by_code),\n",
    "                    \"tagged_sentences\" : self.__get_tagged_sentences_(essay, sent_predictions_by_code)}\n",
    "        except Exception as x:\n",
    "            self.logger.exception(\"An exception occured while annotating essay\")\n",
    "            return {\"error\": format_exc()}\n",
    "        pass\n",
    "\n",
    "    def __is_tag_to_return_(self, tag):\n",
    "        return tag[0].isdigit() or (\"->\" in tag and \"Causer\" in tag)\n",
    "\n",
    "    def __friendly_tag_(self, tag):\n",
    "        return tag.replace(\"Causer:\", \"\").replace(\"Result:\", \"\")\n",
    "\n",
    "    def __get_regular_tags_(self, pred_tags):\n",
    "        r_tags = sorted(filter(lambda t: t[0].isdigit() and \"->\" not in t, pred_tags),\n",
    "                        key=lambda s: (int(s), s) if s.isdigit() else ((-1, s)))\n",
    "        str_r_tags = \",\".join(r_tags)\n",
    "        return str_r_tags\n",
    "\n",
    "    def __get_causal_tags_(self, pred_tags):\n",
    "        c_tags = sorted(filter(lambda t: \"->\" in t, pred_tags), key=lambda s: int(s.split(\"->\")[0]))\n",
    "        str_c_tags = \",\".join(c_tags)\n",
    "        return str_c_tags\n",
    "\n",
    "    def __get_tagged_sentences_(self, essay, sent_predictions_by_code):\n",
    "        tagged_sents = []\n",
    "        for i, sent in enumerate(essay.tagged_sentences):\n",
    "            wds, _ = zip(*sent)\n",
    "            str_sent = \" \".join(wds)\n",
    "            pred_tags = set()\n",
    "            for tag, array in sent_predictions_by_code.items():\n",
    "                if self.__is_tag_to_return_(tag):\n",
    "                    if np.max(array) == 1:\n",
    "                        pred_tags.add(self.__friendly_tag_(tag))\n",
    "\n",
    "            str_r_tags = self.__get_regular_tags_(pred_tags)\n",
    "            str_c_tags = self.__get_causal_tags_(pred_tags)\n",
    "\n",
    "            tagged_sents.append((str_sent, str_r_tags, str_c_tags ))\n",
    "        return tagged_sents\n",
    "\n",
    "    def __fuzzy_match_(self, original, feat_wd):\n",
    "        original = original.lower().strip()\n",
    "        feat_wd = feat_wd.lower().strip()\n",
    "        if original == feat_wd:\n",
    "            return True\n",
    "        if original[:3] == feat_wd[:3]:\n",
    "            return True\n",
    "        a = set(original)\n",
    "        b = set(feat_wd)\n",
    "        jaccard = float(len(a.intersection(b))) / float(len(a.union(b)))\n",
    "        return jaccard >= 0.5\n",
    "\n",
    "    def __align_wd_tags_(self, orig, feats):\n",
    "        \"\"\"\n",
    "        Once processed, there may be a different number of words than in the original sentence\n",
    "        Try and recover the tags for the original words by aligning the two using simple heuristics\n",
    "        \"\"\"\n",
    "        if len(orig) < len(feats):\n",
    "            raise Exception(\"align_wd_tags() : Original sentence is longer!\")\n",
    "\n",
    "        o_wds, _ = zip(*orig)\n",
    "        feat_wds, new_tags = zip(*feats)\n",
    "\n",
    "        if len(orig) == len(feats):\n",
    "            return zip(o_wds, new_tags)\n",
    "\n",
    "        #here orig is longer than feats\n",
    "        diff = len(orig) - len(feats)\n",
    "        tagged_wds = []\n",
    "        feat_offset = 0\n",
    "        while len(tagged_wds) < len(o_wds):\n",
    "            i = len(tagged_wds)\n",
    "            orig_wd = o_wds[i]\n",
    "            print i, orig_wd\n",
    "\n",
    "            if i >= len(feats):\n",
    "                tagged_wds.append((orig_wd, new_tags[-1]))\n",
    "                continue\n",
    "            else:\n",
    "                new_tag_ix = i - feat_offset\n",
    "                feat_wd = feats[new_tag_ix][0]\n",
    "                if feat_wd == \"INFREQUENT\" or feat_wd.isdigit():\n",
    "                    tagged_wds.append((orig_wd, new_tags[new_tag_ix]))\n",
    "                    continue\n",
    "\n",
    "                new_tagged_wds = []\n",
    "                found = False\n",
    "                for j in range(i, i + diff + 1):\n",
    "                    new_tagged_wds.append((o_wds[j], new_tags[new_tag_ix]))\n",
    "                    next_orig_wd = o_wds[j]\n",
    "                    if self.__fuzzy_match_(next_orig_wd, feat_wd):\n",
    "                        found = True\n",
    "                        tagged_wds.extend(new_tagged_wds)\n",
    "                        feat_offset += len(new_tagged_wds) - 1\n",
    "                        break\n",
    "                if not found:\n",
    "                    raise Exception(\"No matching word found for index:%i and processed word:%s\" % (i, feat_wd))\n",
    "        return tagged_wds\n",
    "\n",
    "    def __get_tagged_words_(self, original_essay, essay_TD, wd_predictions_by_code):\n",
    "        tagged_sents = []\n",
    "        # should be a one to one correspondance between words in essays_TD[0] and predictions\n",
    "        i = 0\n",
    "        for sent_ix, sent in enumerate(essay_TD.sentences):\n",
    "            tmp_tagged_wds = []\n",
    "            for wix, (feat) in enumerate(sent):\n",
    "                word = feat.word\n",
    "                tags = set()\n",
    "                for tag in wd_predictions_by_code.keys():\n",
    "                    if wd_predictions_by_code[tag][i] > 0:\n",
    "                        tags.add(tag)\n",
    "                i += 1\n",
    "                tmp_tagged_wds.append((word, tags))\n",
    "\n",
    "            # Now allign the predicted tags with the original words\n",
    "            wds, aligned_tags = zip(*self.__align_wd_tags_(original_essay.tagged_sentences[sent_ix], tmp_tagged_wds))\n",
    "            fr_aligned_tags = map(lambda tags: set(map(self.__friendly_tag_, tags)), aligned_tags)\n",
    "            tagged_words = zip(wds, fr_aligned_tags)\n",
    "            tagged_sents.append(map(lambda (wd, tags): (wd, self.__get_regular_tags_(tags), self.__get_causal_tags_(tags)), tagged_words))\n",
    "        return tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "1154 files found\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05571.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_AEKD_4_CB_ES-05904.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_BGJD_1_CB_ES-05733.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_ERSK_7_CB_ES-05798.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_KYLS_5_CB_ES-05671.ann file as .txt file is no essay //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_LRJE_5_CB_ES-05128.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05612.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_2_CB_ES-05617.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05632.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SVJJ_4_CB_ES-05640.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_SWSP_4_CB_ES-05459.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05484.ann file as .txt file is no essay. //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_1_CB_ES-05485.ann file as .txt file is no essay.  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFBM_2_CB_ES-05548.ann file as .txt file is no essay  //'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TFMV_3_CB_ES-05845.ann file as .txt file is no essay'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05715.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_11_CB_ES-05721.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06128.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRDJ_2_CB_ES-06132.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05025.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TRKM_1_CB_ES-05030.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_2_CB_ES-06140.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06149.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTCM_910_CB_ES-06153.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415_TTKP_7-8_CB_ES-06174.ann file as .txt file is no essay.'\n",
      "Skipping /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged/EBA1415post_TWNB_2_CB_ES-04948.ann file as .txt file is no essay.'\n",
      "1128 essays processed\n",
      "Loading models from /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/API/Models/CB/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/API\"\n",
    "\n",
    "settings = Settings.Settings()\n",
    "folder = settings.data_directory + \"CoralBleaching/BrattData/EBA1415_Merged/\"\n",
    "\n",
    "annotator = Annotator(models_folder= cwd +\"/Models/CB/\", temp_folder=cwd+\"/temp/\", essays_folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_text = \"\"\"\n",
    "Corals are living animals in the ocean.\n",
    "Corals live in one place and dont really move alot.\n",
    "Some corals have white on them and that is called \"coral bleaching.\"\n",
    "Coral Bleaching means that the coral is unhealthy and is trusting into a white color.\n",
    "Normal water tempatures that the coral live in are 70-80 degrees.\n",
    "But some of the waters are too cool like 3 to 10 degrees F.\n",
    "Corals are also affected by storms because corals rely on the amounts of salt in the waters.\n",
    "So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral.\n",
    "The storms have to be very extreme to make corals sick or unhealthy.\n",
    "In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy.\n",
    "The water tempatures coral usally build their reefs in are 70-85 degrees F.\n",
    "So those are the tempature range to keep them healthy.\n",
    "Corals and zooanthellae algae have a relatioship together.\n",
    "Most zooanthellae can not live without outside the corals bodies.\n",
    "It is because there isnt enough nutrience to have the ocean do photosynthesis.\n",
    "The zooanthellae rely on the coral to stay healthy, but the coral can get physical damage.\n",
    "Coral bleaching is a physical damage to the corals.\n",
    "Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae. //\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_annotations = d_annotations = annotator.annotate(essay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Corals are living animals in the ocean .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Corals live in one place and dont really move alot .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Some corals have white on them and that is called \" coral bleaching . \"\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Coral Bleaching means that the coral is unhealthy and is trusting into a white color .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Normal water tempatures that the coral live in are 70 - 80 degrees .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"But some of the waters are too cool like 3 to 10 degrees F .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Corals are also affected by storms because corals rely on the amounts of salt in the waters .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"The storms have to be very extreme to make corals sick or unhealthy .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"The water tempatures coral usally build their reefs in are 70 - 85 degrees F .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"So those are the tempature range to keep them healthy .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Corals and zooanthellae algae have a relatioship together .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Most zooanthellae can not live without outside the corals bodies .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"It is because there isnt enough nutrience to have the ocean do photosynthesis .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"The zooanthellae rely on the coral to stay healthy , but the coral can get physical damage .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Coral bleaching is a physical damage to the corals .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n",
      "\"Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae .\" 3,4,11,13,50 3->4,11->14,11->3,11->50,11->13\n"
     ]
    }
   ],
   "source": [
    "for sent, r_tags, c_tags in d_annotations[\"tagged_sentences\"]:\n",
    "    print \"\\\"\" + sent+ \"\\\"\", r_tags, c_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corals', '', '')\n",
      "('are', '', '')\n",
      "('living', '', '')\n",
      "('animals', '', '')\n",
      "('in', '', '')\n",
      "('the', '', '')\n",
      "('ocean', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Corals', '', '')\n",
      "('live', '', '')\n",
      "('in', '', '')\n",
      "('one', '', '')\n",
      "('place', '', '')\n",
      "('and', '', '')\n",
      "('dont', '', '')\n",
      "('really', '', '')\n",
      "('move', '', '')\n",
      "('alot', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Some', '50', '')\n",
      "('corals', '50', '')\n",
      "('have', '50', '')\n",
      "('white', '50', '')\n",
      "('on', '', '')\n",
      "('them', '', '')\n",
      "('and', '', '')\n",
      "('that', '', '')\n",
      "('is', '50', '')\n",
      "('called', '', '')\n",
      "('\"', '', '')\n",
      "('coral', '50', '')\n",
      "('bleaching', '50', '')\n",
      "('.', '', '')\n",
      "('\"', '', '')\n",
      "\n",
      "('Coral', '50', '')\n",
      "('Bleaching', '50', '')\n",
      "('means', '', '')\n",
      "('that', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('is', '', '')\n",
      "('unhealthy', '', '')\n",
      "('and', '', '')\n",
      "('is', '', '')\n",
      "('trusting', '50', '')\n",
      "('into', '50', '')\n",
      "('a', '50', '')\n",
      "('white', '50', '')\n",
      "('color', '50', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Normal', '', '')\n",
      "('water', '', '')\n",
      "('tempatures', '', '')\n",
      "('that', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('live', '', '')\n",
      "('in', '', '')\n",
      "('are', '', '')\n",
      "('70', '', '')\n",
      "('-', '', '')\n",
      "('80', '', '')\n",
      "('degrees', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('But', '', '')\n",
      "('some', '', '')\n",
      "('of', '', '')\n",
      "('the', '', '')\n",
      "('waters', '3', '')\n",
      "('are', '3', '')\n",
      "('too', '3', '')\n",
      "('cool', '', '')\n",
      "('like', '', '')\n",
      "('3', '3', '')\n",
      "('to', '3', '')\n",
      "('10', '3', '')\n",
      "('degrees', '3', '')\n",
      "('F', '3', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Corals', '', '')\n",
      "('are', '', '')\n",
      "('also', '', '')\n",
      "('affected', '', '')\n",
      "('by', '', '')\n",
      "('storms', '11', '')\n",
      "('because', '', '')\n",
      "('corals', '', '')\n",
      "('rely', '', '')\n",
      "('on', '', '')\n",
      "('the', '', '')\n",
      "('amounts', '', '')\n",
      "('of', '13', '')\n",
      "('salt', '13', '')\n",
      "('in', '13', '')\n",
      "('the', '13', '')\n",
      "('waters', '13', '')\n",
      "('.', '', '')\n",
      "\n",
      "('So', '', '')\n",
      "('when', '', '')\n",
      "('it', '', '')\n",
      "('storms', '11', '')\n",
      "('the', '', '11->13')\n",
      "('water', '3', '11->13')\n",
      "('tempatures', '3', '11->13')\n",
      "('and', '', '')\n",
      "('levels', '13', '')\n",
      "('of', '13', '11->13')\n",
      "('salt', '13', '11->13')\n",
      "('will', '13', '11->13')\n",
      "('be', '', '')\n",
      "('all', '', '')\n",
      "('mest', '', '')\n",
      "('up', '', '')\n",
      "('and', '', '')\n",
      "('bad', '', '')\n",
      "('for', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('The', '', '')\n",
      "('storms', '11', '')\n",
      "('have', '', '')\n",
      "('to', '', '')\n",
      "('be', '', '')\n",
      "('very', '', '')\n",
      "('extreme', '', '')\n",
      "('to', '', '')\n",
      "('make', '', '')\n",
      "('corals', '', '')\n",
      "('sick', '', '')\n",
      "('or', '', '')\n",
      "('unhealthy', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('In', '', '')\n",
      "('the', '', '')\n",
      "('water', '', '')\n",
      "('if', '3', '')\n",
      "('the', '3', '3->4')\n",
      "('tempature', '3', '3->4')\n",
      "('increases', '3', '3->4')\n",
      "('the', '', '3->4')\n",
      "('amounts', '4', '3->4')\n",
      "('of', '4', '')\n",
      "('dioxide', '', '')\n",
      "('will', '', '')\n",
      "('drop', '', '')\n",
      "('and', '', '')\n",
      "('willmake', '', '')\n",
      "('the', '', '')\n",
      "('coral', '14', '')\n",
      "('unhealthy', '14', '')\n",
      "('.', '', '')\n",
      "\n",
      "('The', '', '')\n",
      "('water', '3', '')\n",
      "('tempatures', '', '')\n",
      "('coral', '', '')\n",
      "('usally', '', '')\n",
      "('build', '', '')\n",
      "('their', '', '')\n",
      "('reefs', '', '')\n",
      "('in', '', '')\n",
      "('are', '', '')\n",
      "('70', '', '')\n",
      "('-', '', '')\n",
      "('85', '', '')\n",
      "('degrees', '', '')\n",
      "('F', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('So', '', '')\n",
      "('those', '', '')\n",
      "('are', '', '')\n",
      "('the', '', '')\n",
      "('tempature', '', '')\n",
      "('range', '', '')\n",
      "('to', '', '')\n",
      "('keep', '', '')\n",
      "('them', '', '')\n",
      "('healthy', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Corals', '', '')\n",
      "('and', '', '')\n",
      "('zooanthellae', '', '')\n",
      "('algae', '', '')\n",
      "('have', '', '')\n",
      "('a', '', '')\n",
      "('relatioship', '', '')\n",
      "('together', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Most', '', '')\n",
      "('zooanthellae', '', '')\n",
      "('can', '', '')\n",
      "('not', '', '')\n",
      "('live', '', '')\n",
      "('without', '', '')\n",
      "('outside', '', '')\n",
      "('the', '', '')\n",
      "('corals', '', '')\n",
      "('bodies', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('It', '', '')\n",
      "('is', '', '')\n",
      "('because', '', '')\n",
      "('there', '', '')\n",
      "('isnt', '', '')\n",
      "('enough', '', '')\n",
      "('nutrience', '', '')\n",
      "('to', '', '')\n",
      "('have', '', '')\n",
      "('the', '', '')\n",
      "('ocean', '', '')\n",
      "('do', '', '')\n",
      "('photosynthesis', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('The', '', '')\n",
      "('zooanthellae', '', '')\n",
      "('rely', '', '')\n",
      "('on', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('to', '', '')\n",
      "('stay', '', '')\n",
      "('healthy', '', '')\n",
      "(',', '', '')\n",
      "('but', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('can', '', '')\n",
      "('get', '', '')\n",
      "('physical', '', '')\n",
      "('damage', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Coral', '50', '')\n",
      "('bleaching', '50', '')\n",
      "('is', '', '')\n",
      "('a', '', '')\n",
      "('physical', '', '')\n",
      "('damage', '', '')\n",
      "('to', '', '')\n",
      "('the', '', '')\n",
      "('corals', '', '')\n",
      "('.', '', '')\n",
      "\n",
      "('Coral', '50', '')\n",
      "('bleaching', '50', '')\n",
      "('is', '', '')\n",
      "('also', '', '')\n",
      "('an', '', '')\n",
      "('example', '', '')\n",
      "('how', '', '14->50')\n",
      "('the', '', '14->50')\n",
      "('envionmental', '6', '14->50')\n",
      "('stressors', '', '')\n",
      "('can', '', '')\n",
      "('affect', '', '')\n",
      "('the', '', '')\n",
      "('relationships', '', '')\n",
      "('between', '', '')\n",
      "('the', '', '')\n",
      "('coral', '', '')\n",
      "('and', '', '')\n",
      "('the', '', '')\n",
      "('algae', '', '')\n",
      "('.', '', '')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in d_annotations[\"tagged_words\"]:\n",
    "    for wd, r_tags, c_tags in sent:\n",
    "        print str((wd, r_tags, c_tags))\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "self = annotator\n",
    "# expects a new line per sentence\n",
    "sentences = sent_tokenize(essay_text.strip())\n",
    "contents = \"\\n\".join(sentences)\n",
    "\n",
    "fname = self.temp_folder + \"essay.txt\"\n",
    "with open(fname, 'w\"') as f:\n",
    "    f.write(contents)\n",
    "\n",
    "essay = Essay(fname, include_vague=self.config[\"include_vague\"], include_normal=self.config[\"include_normal\"], load_annotations=False)\n",
    "processed_essays = process_essays(essays=[essay],\n",
    "                                  spelling_corrector=self.spelling_corrector,\n",
    "                                  wd_sent_freq=self.wd_sent_freq,\n",
    "                                  remove_infrequent=self.config[\"remove_infrequent\"],\n",
    "                                  spelling_correct=self.config[\"spelling_correct\"],\n",
    "                                  replace_nums=self.config[\"replace_nums\"],\n",
    "                                  stem=self.config[\"stem\"],\n",
    "                                  remove_stop_words=self.config[\"remove_stop_words\"],\n",
    "                                  remove_punctuation=self.config[\"remove_punctuation\"],\n",
    "                                  lower_case=self.config[\"lower_case\"])\n",
    "\n",
    "self.logger.info(\"Essay loaded successfully\")\n",
    "essays_TD = self.feature_extractor.transform(processed_essays)\n",
    "\n",
    "td_feats, _ = flatten_to_wordlevel_feat_tags(essays_TD)\n",
    "td_X = self.feature_transformer.transform(td_feats)\n",
    "td_wd_predictions_by_code = test_classifier_per_code(td_X, self.tag_2_wd_classifier, self.wd_test_tags)\n",
    "\n",
    "dummy_wd_td_ys_bytag = defaultdict(lambda: np.asarray([0.0] * td_X.shape[0]))\n",
    "sent_td_xs, sent_td_ys_bycode = get_sent_feature_for_stacking_from_tagging_model(self.sent_input_feat_tags,\n",
    "                                                                                 self.sent_input_interaction_tags,\n",
    "                                                                                 essays_TD, td_X,\n",
    "                                                                                 dummy_wd_td_ys_bytag,\n",
    "                                                                                 self.tag_2_wd_classifier,\n",
    "                                                                                 sparse=True,\n",
    "                                                                                 look_back=0)\n",
    "\n",
    "\"\"\" Test Stack Classifier \"\"\"\n",
    "td_sent_predictions_by_code \\\n",
    "    = test_classifier_per_code(sent_td_xs, self.tag_2_sent_classifier, self.sent_output_train_test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Corals are living animals in the ocean .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Corals live in one place and dont really move alot .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Some corals have white on them and that is called \" coral bleaching . \"',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Coral Bleaching means that the coral is unhealthy and is trusting into a white color .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Normal water tempatures that the coral live in are 70 - 80 degrees .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('But some of the waters are too cool like 3 to 10 degrees F .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Corals are also affected by storms because corals rely on the amounts of salt in the waters .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('The storms have to be very extreme to make corals sick or unhealthy .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('The water tempatures coral usally build their reefs in are 70 - 85 degrees F .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('So those are the tempature range to keep them healthy .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Corals and zooanthellae algae have a relatioship together .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Most zooanthellae can not live without outside the corals bodies .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('It is because there isnt enough nutrience to have the ocean do photosynthesis .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('The zooanthellae rely on the coral to stay healthy , but the coral can get physical damage .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Coral bleaching is a physical damage to the corals .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13'),\n",
       " ('Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae .',\n",
       "  '3,4,11,13,50',\n",
       "  '3->4,11->14,11->3,11->50,11->13')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = []\n",
    "for i, sent in enumerate(essay.tagged_sentences):\n",
    "    wds, _ = zip(*sent)\n",
    "    str_sent = \" \".join(wds)\n",
    "    pred_tags = set()\n",
    "    for tag, array in td_sent_predictions_by_code.items():\n",
    "        if tag[0].isdigit() or (\"->\" in tag and \"Causer\" in tag):\n",
    "            if np.max(array) == 1:\n",
    "                pred_tags.add(tag.replace(\"Causer:\",\"\").replace(\"Result:\",\"\"))\n",
    "    r_tags = sorted(filter(lambda t: \"->\" not in t, pred_tags), key=lambda s: (int(s),s) if s.isdigit() else ((-1,s)))\n",
    "    c_tags = sorted(filter(lambda t: \"->\" in t, pred_tags), key = lambda s: int(s.split(\"->\")[0]))\n",
    "    s_tags = \",\".join(r_tags) + \",\" + \",\".join(c_tags)\n",
    "    tagged_sents.append((str_sent, \",\".join(r_tags), \",\".join(c_tags) ))\n",
    "tagged_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_wd_predictions_by_code[\"5\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "262\n",
      "262\n"
     ]
    }
   ],
   "source": [
    "print sum([len(sent) for sent in essay.tagged_sentences])\n",
    "print sum([len(sent) for sent in processed_essays[0].sentences])\n",
    "print sum([len(sent) for sent in essays_TD[0].sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corals are living animals in the ocean .\n",
      "Corals are living animals in the ocean .\n",
      "\n",
      "Corals live in one place and dont really move alot .\n",
      "Corals live in one place and dont really move alot .\n",
      "\n",
      "Some corals have white on them and that is called \" coral bleaching . \"\n",
      "Some corals have white on them and that is called \" coral bleaching . \"\n",
      "\n",
      "Coral Bleaching means that the coral is unhealthy and is trusting into a white color .\n",
      "Coral Bleaching means that the coral is unhealthy and is INFREQUENT into a white color .\n",
      "\n",
      "Normal water tempatures that the coral live in are 70 - 80 degrees .\n",
      "Normal water temperatures that the coral live in are 00 - 00 degrees .\n",
      "\n",
      "But some of the waters are too cool like 3 to 10 degrees F .\n",
      "But some of the waters are too cool like 0 to 00 degrees F .\n",
      "\n",
      "Corals are also affected by storms because corals rely on the amounts of salt in the waters .\n",
      "Corals are also affected by storms because corals rely on the amounts of salt in the waters .\n",
      "\n",
      "So when it storms the water tempatures and levels of salt will be all mest up and bad for the coral .\n",
      "So when it storms the water temperatures and levels of salt will be all most up and bad for the coral .\n",
      "\n",
      "The storms have to be very extreme to make corals sick or unhealthy .\n",
      "The storms have to be very extreme to make corals sick or unhealthy .\n",
      "\n",
      "In the water if the tempature increases the amounts of dioxide will drop and willmake the coral unhealthy .\n",
      "In the water if the temperature increases the amounts of dioxide will drop and INFREQUENT the coral unhealthy .\n",
      "\n",
      "The water tempatures coral usally build their reefs in are 70 - 85 degrees F .\n",
      "The water temperatures coral usually build their reefs in are 00 - 00 degrees F .\n",
      "\n",
      "So those are the tempature range to keep them healthy .\n",
      "So those are the temperature range to keep them healthy .\n",
      "\n",
      "Corals and zooanthellae algae have a relatioship together .\n",
      "Corals and zooanthellae algae have a relationship together .\n",
      "\n",
      "Most zooanthellae can not live without outside the corals bodies .\n",
      "Most zooanthellae can not live without outside the corals bodies .\n",
      "\n",
      "It is because there isnt enough nutrience to have the ocean do photosynthesis .\n",
      "It is because there int enough nutrients to have the ocean do photosynthesis .\n",
      "\n",
      "The zooanthellae rely on the coral to stay healthy , but the coral can get physical damage .\n",
      "The zooanthellae rely on the coral to stay healthy , but the coral can get physical damage .\n",
      "\n",
      "Coral bleaching is a physical damage to the corals .\n",
      "Coral bleaching is a physical damage to the corals .\n",
      "\n",
      "Coral bleaching is also an example how the envionmental stressors can affect the relationships between the coral and the algae .\n",
      "Coral bleaching is also an example how the environmental stressors can affect the relationships between the coral and the algae .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ix, sent in enumerate(processed_essays[0].sentences):\n",
    "    orig = essay.tagged_sentences[ix]\n",
    "    orig_sent = \" \".join(zip(*orig)[0])\n",
    "    proc_sent = \" \".join(zip(*sent)[0])\n",
    "    print orig_sent\n",
    "    print proc_sent\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Corals', set()),\n",
       "  ('are', set()),\n",
       "  ('living', set()),\n",
       "  ('animals', set()),\n",
       "  ('in', set()),\n",
       "  ('the', set()),\n",
       "  ('ocean', set()),\n",
       "  ('.', set())],\n",
       " [('Corals', set()),\n",
       "  ('live', set()),\n",
       "  ('in', set()),\n",
       "  ('one', set()),\n",
       "  ('place', set()),\n",
       "  ('and', set()),\n",
       "  ('dont', set()),\n",
       "  ('really', set()),\n",
       "  ('move', set()),\n",
       "  ('alot', set()),\n",
       "  ('.', set())],\n",
       " [('Some', {'50'}),\n",
       "  ('corals', {'50'}),\n",
       "  ('have', {'50'}),\n",
       "  ('white', {'50'}),\n",
       "  ('on', set()),\n",
       "  ('them', set()),\n",
       "  ('and', set()),\n",
       "  ('that', set()),\n",
       "  ('is', {'50'}),\n",
       "  ('called', set()),\n",
       "  ('\"', set()),\n",
       "  ('coral', {'50'}),\n",
       "  ('bleaching', {'50'}),\n",
       "  ('.', set()),\n",
       "  ('\"', set())],\n",
       " [('Coral', {'50'}),\n",
       "  ('Bleaching', {'50'}),\n",
       "  ('means', set()),\n",
       "  ('that', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('is', set()),\n",
       "  ('unhealthy', set()),\n",
       "  ('and', set()),\n",
       "  ('is', set()),\n",
       "  ('INFREQUENT', {'50'}),\n",
       "  ('into', {'50'}),\n",
       "  ('a', {'50'}),\n",
       "  ('white', {'50'}),\n",
       "  ('color', {'50'}),\n",
       "  ('.', set())],\n",
       " [('Normal', set()),\n",
       "  ('water', set()),\n",
       "  ('temperatures', set()),\n",
       "  ('that', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('live', set()),\n",
       "  ('in', set()),\n",
       "  ('are', set()),\n",
       "  ('00', set()),\n",
       "  ('-', set()),\n",
       "  ('00', set()),\n",
       "  ('degrees', set()),\n",
       "  ('.', set())],\n",
       " [('But', set()),\n",
       "  ('some', set()),\n",
       "  ('of', set()),\n",
       "  ('the', set()),\n",
       "  ('waters', {'3'}),\n",
       "  ('are', {'3'}),\n",
       "  ('too', {'3'}),\n",
       "  ('cool', set()),\n",
       "  ('like', set()),\n",
       "  ('0', {'3'}),\n",
       "  ('to', {'3'}),\n",
       "  ('00', {'3'}),\n",
       "  ('degrees', {'3', 'Result', 'Result:3'}),\n",
       "  ('F', {'3'}),\n",
       "  ('.', set())],\n",
       " [('Corals', set()),\n",
       "  ('are', set()),\n",
       "  ('also', set()),\n",
       "  ('affected', set()),\n",
       "  ('by', set()),\n",
       "  ('storms', {'11'}),\n",
       "  ('because', set()),\n",
       "  ('corals', set()),\n",
       "  ('rely', set()),\n",
       "  ('on', set()),\n",
       "  ('the', set()),\n",
       "  ('amounts', set()),\n",
       "  ('of', {'13'}),\n",
       "  ('salt', {'13'}),\n",
       "  ('in', {'13'}),\n",
       "  ('the', {'13'}),\n",
       "  ('waters', {'13'}),\n",
       "  ('.', set())],\n",
       " [('So', set()),\n",
       "  ('when', {'explicit'}),\n",
       "  ('it', set()),\n",
       "  ('storms', {'11', 'Causer', 'Causer:11'}),\n",
       "  ('the', {'Causer:11->Result:13'}),\n",
       "  ('water', {'3', 'Causer:11->Result:13', 'Result'}),\n",
       "  ('temperatures', {'3', 'Causer:11->Result:13', 'Result'}),\n",
       "  ('and', set()),\n",
       "  ('levels', {'13', 'Causer', 'Result:13'}),\n",
       "  ('of', {'13', 'Causer:11->Result:13', 'Result:13'}),\n",
       "  ('salt', {'13', 'Causer:11->Result:13', 'Result:13'}),\n",
       "  ('will', {'13', 'Causer:11->Result:13', 'Result:13'}),\n",
       "  ('be', set()),\n",
       "  ('all', set()),\n",
       "  ('most', set()),\n",
       "  ('up', set()),\n",
       "  ('and', set()),\n",
       "  ('bad', set()),\n",
       "  ('for', {'Result'}),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('.', set())],\n",
       " [('The', set()),\n",
       "  ('storms', {'11', 'Causer', 'Causer:11'}),\n",
       "  ('have', set()),\n",
       "  ('to', set()),\n",
       "  ('be', set()),\n",
       "  ('very', set()),\n",
       "  ('extreme', set()),\n",
       "  ('to', set()),\n",
       "  ('make', set()),\n",
       "  ('corals', set()),\n",
       "  ('sick', set()),\n",
       "  ('or', set()),\n",
       "  ('unhealthy', set()),\n",
       "  ('.', set())],\n",
       " [('In', set()),\n",
       "  ('the', set()),\n",
       "  ('water', set()),\n",
       "  ('if', {'3', 'explicit'}),\n",
       "  ('the', {'3', 'Causer:3', 'Causer:3->Result:4'}),\n",
       "  ('temperature', {'3', 'Causer', 'Causer:3', 'Causer:3->Result:4'}),\n",
       "  ('increases', {'3', 'Causer', 'Causer:3', 'Causer:3->Result:4'}),\n",
       "  ('the', {'Causer:3->Result:4'}),\n",
       "  ('amounts', {'4', 'Causer:3->Result:4', 'Result', 'Result:4'}),\n",
       "  ('of', {'4', 'Causer', 'Result'}),\n",
       "  ('dioxide', {'Result'}),\n",
       "  ('will', set()),\n",
       "  ('drop', set()),\n",
       "  ('and', set()),\n",
       "  ('INFREQUENT', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', {'14', 'Result', 'Result:14'}),\n",
       "  ('unhealthy', {'14', 'Result'}),\n",
       "  ('.', set())],\n",
       " [('The', set()),\n",
       "  ('water', {'3'}),\n",
       "  ('temperatures', set()),\n",
       "  ('coral', set()),\n",
       "  ('usually', set()),\n",
       "  ('build', set()),\n",
       "  ('their', set()),\n",
       "  ('reefs', set()),\n",
       "  ('in', set()),\n",
       "  ('are', set()),\n",
       "  ('00', set()),\n",
       "  ('-', set()),\n",
       "  ('00', set()),\n",
       "  ('degrees', set()),\n",
       "  ('F', set()),\n",
       "  ('.', set())],\n",
       " [('So', set()),\n",
       "  ('those', set()),\n",
       "  ('are', set()),\n",
       "  ('the', set()),\n",
       "  ('temperature', set()),\n",
       "  ('range', set()),\n",
       "  ('to', set()),\n",
       "  ('keep', set()),\n",
       "  ('them', set()),\n",
       "  ('healthy', set()),\n",
       "  ('.', set())],\n",
       " [('Corals', set()),\n",
       "  ('and', set()),\n",
       "  ('zooanthellae', set()),\n",
       "  ('algae', set()),\n",
       "  ('have', set()),\n",
       "  ('a', set()),\n",
       "  ('relationship', set()),\n",
       "  ('together', set()),\n",
       "  ('.', set())],\n",
       " [('Most', set()),\n",
       "  ('zooanthellae', set()),\n",
       "  ('can', set()),\n",
       "  ('not', set()),\n",
       "  ('live', set()),\n",
       "  ('without', set()),\n",
       "  ('outside', set()),\n",
       "  ('the', set()),\n",
       "  ('corals', set()),\n",
       "  ('bodies', set()),\n",
       "  ('.', set())],\n",
       " [('It', set()),\n",
       "  ('is', set()),\n",
       "  ('because', set()),\n",
       "  ('there', set()),\n",
       "  ('int', set()),\n",
       "  ('enough', set()),\n",
       "  ('nutrients', set()),\n",
       "  ('to', set()),\n",
       "  ('have', set()),\n",
       "  ('the', set()),\n",
       "  ('ocean', set()),\n",
       "  ('do', set()),\n",
       "  ('photosynthesis', set()),\n",
       "  ('.', set())],\n",
       " [('The', set()),\n",
       "  ('zooanthellae', set()),\n",
       "  ('rely', set()),\n",
       "  ('on', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('to', set()),\n",
       "  ('stay', set()),\n",
       "  ('healthy', set()),\n",
       "  (',', set()),\n",
       "  ('but', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('can', set()),\n",
       "  ('get', set()),\n",
       "  ('physical', set()),\n",
       "  ('damage', set()),\n",
       "  ('.', set())],\n",
       " [('Coral', {'50'}),\n",
       "  ('bleaching', {'50'}),\n",
       "  ('is', set()),\n",
       "  ('a', set()),\n",
       "  ('physical', set()),\n",
       "  ('damage', set()),\n",
       "  ('to', set()),\n",
       "  ('the', set()),\n",
       "  ('corals', set()),\n",
       "  ('.', set())],\n",
       " [('Coral', {'50'}),\n",
       "  ('bleaching', {'50'}),\n",
       "  ('is', set()),\n",
       "  ('also', set()),\n",
       "  ('an', set()),\n",
       "  ('example', set()),\n",
       "  ('how', {'Causer:14->Result:50'}),\n",
       "  ('the', {'Causer:14->Result:50'}),\n",
       "  ('environmental', {'6', 'Causer:14->Result:50'}),\n",
       "  ('stressors', {'Causer'}),\n",
       "  ('can', set()),\n",
       "  ('affect', set()),\n",
       "  ('the', set()),\n",
       "  ('relationships', set()),\n",
       "  ('between', set()),\n",
       "  ('the', set()),\n",
       "  ('coral', set()),\n",
       "  ('and', set()),\n",
       "  ('the', set()),\n",
       "  ('algae', set()),\n",
       "  ('.', set())]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_wd_sents = []\n",
    "#should be a one to one correspondance between words in essays_TD[0] and predictions\n",
    "i = 0\n",
    "for sent in essays_TD[0].sentences:\n",
    "    tagged_wds = []\n",
    "    for wix, (feat) in enumerate(sent):\n",
    "        word = feat.word\n",
    "        tags = set()\n",
    "        for tag in td_wd_predictions_by_code.keys():\n",
    "            if td_wd_predictions_by_code[tag][i] > 0:\n",
    "                tags.add(tag)\n",
    "        i+=1\n",
    "        tagged_wds.append((word, tags))\n",
    "    tagged_wd_sents.append(tagged_wds)\n",
    "tagged_wd_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Once processed, there may be a different number of words than in the original sentence\n",
    "#Try and recover the tags for the original words by aligning the two using simple heuristics\n",
    "def fuzzy_match(original, feat_wd):\n",
    "    original = original.lower().strip()\n",
    "    feat_wd = feat_wd.lower().strip()\n",
    "    if original == feat_wd:\n",
    "        #print \"\\nMatch\"\n",
    "        return True\n",
    "    if orig[:3] == feat_wd[:3]:\n",
    "        #print \"\\n\", orig[:3] , feat_wd[:3]\n",
    "        return True\n",
    "    a = set(original)\n",
    "    b = set(feat_wd)\n",
    "    jaccard = float(len(a.intersection(b))) / float(len(a.union(b)))\n",
    "    #print \"\\nJaccard\"\n",
    "    return jaccard >= 0.5\n",
    "\n",
    "def align_wd_tags(orig, feats):\n",
    "    if len(orig) < len(feats):\n",
    "        raise Exception(\"align_wd_tags() : Original sentence is longer!\")\n",
    "\n",
    "    o_wds,    _        = zip(*orig)\n",
    "    feat_wds, new_tags = zip(*feats)\n",
    "\n",
    "    if len(orig) == len(feats):\n",
    "        return zip(o_wds, new_tags)\n",
    "\n",
    "    #here orig is longer than feats\n",
    "    diff = len(orig) - len(feats)\n",
    "    tagged_wds = []\n",
    "    feat_offset = 0\n",
    "    while len(tagged_wds) < len(o_wds):\n",
    "        i = len(tagged_wds)\n",
    "        orig_wd = o_wds[i]\n",
    "        print i, orig_wd\n",
    "\n",
    "        if i >= len(feats):\n",
    "            tagged_wds.append((orig_wd, new_tags[-1]))\n",
    "            continue\n",
    "        else:\n",
    "            new_tag_ix = i - feat_offset\n",
    "            feat_wd = feats[new_tag_ix][0]\n",
    "            if feat_wd == \"INFREQUENT\" or feat_wd.isdigit():\n",
    "                tagged_wds.append((orig_wd, new_tags[new_tag_ix]))\n",
    "                continue\n",
    "\n",
    "            new_tagged_wds = []\n",
    "            found = False\n",
    "            for j in range(i, i+diff+1):\n",
    "                new_tagged_wds.append((o_wds[j], new_tags[new_tag_ix]))\n",
    "                next_orig_wd = o_wds[j]\n",
    "                if fuzzy_match(next_orig_wd, feat_wd):\n",
    "                    found = True\n",
    "                    tagged_wds.extend(new_tagged_wds)\n",
    "                    feat_offset += len(new_tagged_wds) -1\n",
    "                    break\n",
    "            if not found:\n",
    "                raise Exception(\"No matching word found for index:%i and processed word:%s\" % (i, feat_wd))\n",
    "    return tagged_wds\n",
    "\n",
    "def test(a,b):\n",
    "    print a, b, \"\\t\", fuzzy_match(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog frog \tTrue\n",
      "frog froXXXX \tTrue\n",
      "frogggy fr \tFalse\n",
      "123456 645 \tTrue\n",
      "123456 aaa645 \tFalse\n",
      "123456xyz abc645231 \tTrue\n"
     ]
    }
   ],
   "source": [
    "test(\"frog\", \"frog\")\n",
    "test(\"frog\", \"froXXXX\")\n",
    "test(\"frogggy\", \"fr\")\n",
    "test(\"123456\", \"645\")\n",
    "test(\"123456\", \"aaa645\")\n",
    "test(\"123456xyz\", \"abc645231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "'The',\n",
      "'plankton',\n",
      "'was',\n",
      "'causing',\n",
      "'the',\n",
      "'coral',\n",
      "'to',\n",
      "'be',\n",
      "'bleached',\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def print_lst(tag_l):\n",
    "    print \"[\"\n",
    "    for wd in zip(*tag_l)[0]:\n",
    "        print \"'%s',\" % wd\n",
    "    print \"]\"\n",
    "\n",
    "orig = map(lambda wd: (wd, set()), \"The plankton was causing the coral to be bleached\".split(\" \"))\n",
    "print_lst(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The\n",
      "1 plankton\n",
      "3 causing\n",
      "4 the\n",
      "6 to\n",
      "7 be\n",
      "8 bleached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', {'INFREQUENT'}),\n",
       " ('plankton', {'was'}),\n",
       " ('was', {'was'}),\n",
       " ('causing', {'causing'}),\n",
       " ('the', {'coral'}),\n",
       " ('coral', {'coral'}),\n",
       " ('to', {'to'}),\n",
       " ('be', {'bleached'}),\n",
       " ('bleached', {'bleached'})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = [\n",
    "#'The',\n",
    "'INFREQUENT',\n",
    "'was',\n",
    "'causing',\n",
    "#'the',\n",
    "'coral',\n",
    "'to',\n",
    "'be',\n",
    "'bleached',\n",
    "]\n",
    "tagged = map(lambda w: (w,set([w])), tagged)\n",
    "aligned = align_wd_tags(orig, tagged)\n",
    "aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
