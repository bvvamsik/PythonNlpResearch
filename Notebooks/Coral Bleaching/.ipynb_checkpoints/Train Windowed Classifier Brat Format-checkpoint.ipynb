{
 "metadata": {
  "name": "",
  "signature": "sha256:355d1e877491214e8ceccbf16e2552b1b6407162bf26b9622badc2fa34a6774a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train a Window Based Classier on the Coral Bleaching Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setup:\n",
      "------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Imports \"\"\"\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "from gensim import matutils\n",
      "from numpy import random\n",
      "import pylibfm \n",
      "\n",
      "from Metrics import rpf1a\n",
      "from Rpfa import rpfa, weighted_mean_rpfa\n",
      "from BrattEssay import load_bratt_essays\n",
      "from WindowSplitter import split_into_windows\n",
      "\n",
      "from IdGenerator import IdGenerator\n",
      "from IterableFP import flatten\n",
      "\n",
      "from nltk import PorterStemmer\n",
      "from stanford_parser import parser\n",
      "\n",
      "\"\"\" TODO \n",
      "    Try dependency parse features from this python dependency parser: https://github.com/syllog1sm/redshift\n",
      "\"\"\"\n",
      "\n",
      "\"\"\" Settings \"\"\"\n",
      "\"\"\" Start Script \"\"\"\n",
      "WINDOW_SIZE = 7 #7 is best\n",
      "MID_IX = int(round(WINDOW_SIZE / 2.0) - 1)\n",
      "\n",
      "MIN_SENTENCE_FREQ = 2\n",
      "PCT_VALIDATION  = 0.2\n",
      "MIN_FEAT_FREQ = 5     #15 best so far\n",
      "PCT_VALIDATION = 0.25\n",
      "\n",
      "SENTENCE_START = \"<START>\"\n",
      "SENTENCE_END   = \"<END>\"\n",
      "STEM = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the Essays\n",
      "---------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\" Load Essays \"\"\"\n",
      "essays = load_bratt_essays(\"/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/Merged/\")\n",
      "\n",
      "all_codes = set()\n",
      "all_words = []\n",
      "\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        for w, tags in sentence:\n",
      "            all_words.append(w)\n",
      "            all_codes.update(tags)\n",
      "                \n",
      "# Correct miss-spellings\n",
      "from SpellingCorrector import SpellingCorrector\n",
      "\n",
      "corrector = SpellingCorrector(all_words)\n",
      "corrections = defaultdict(int)\n",
      "\n",
      "for essay in essays:\n",
      "    for i, sentence in enumerate(essay.tagged_sentences):\n",
      "        for j, (w, tags) in enumerate(sentence):\n",
      "            # common error is ..n't and ..nt\n",
      "            if w.endswith(\"n't\") or w.endswith(\"n'\"):\n",
      "                cw = w[:-3] + \"nt\"\n",
      "            elif w.endswith(\"'s\"):\n",
      "                cw = w[:-2]\n",
      "            elif w == \"&\":\n",
      "                cw = \"and\"\n",
      "            else:\n",
      "                cw = corrector.correct(w)\n",
      "            if cw != w:\n",
      "                corrections[(w,cw)] += 1\n",
      "                sentence[j] = (cw, tags)            \n",
      "            \n",
      "wd_sent_freq = defaultdict(int)\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        wds, tag_list = zip(*sentence)\n",
      "        unique_wds = set(wds)\n",
      "        for w in unique_wds: \n",
      "            wd_sent_freq[w] += 1\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "297 files found\n",
        "297 essays processed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "cor_srtd = sort_by_value(corrections, reverse = True)\n",
      "cor_srtd[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[((\"it's\", 'it'), 52),\n",
        " (('zox', 'zo'), 41),\n",
        " ((\"don't\", 'dont'), 31),\n",
        " ((\"that's\", 'that'), 29),\n",
        " (('algea', 'algae'), 26),\n",
        " ((\"world's\", 'world'), 20),\n",
        " (('&', 'and'), 17),\n",
        " ((\"can't\", 'cant'), 14),\n",
        " (('bleaches', 'bleached'), 13),\n",
        " (('cloral', 'coral'), 11),\n",
        " ((\"they're\", 'there'), 11),\n",
        " ((\"coral's\", 'coral'), 11),\n",
        " ((\"isn't\", 'isnt'), 11),\n",
        " (('tempeture', 'temperature'), 9),\n",
        " ((\"won't\", 'wont'), 9),\n",
        " (('alge', 'algae'), 9),\n",
        " (('tiems', 'times'), 8),\n",
        " ((\"doesn't\", 'doesnt'), 8),\n",
        " (('tempature', 'temperature'), 8),\n",
        " (('varys', 'vary'), 7)]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Single char words \"\"\"\n",
      "wds = [(w,f) for w,f in wd_sent_freq.items() if len(w.strip()) == 1 and not w[0].isalpha()]\n",
      "print \"\\n\".join(map(str,sorted(wds, key = lambda (w,f): -f)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('.', 2563)\n",
        "(',', 677)\n",
        "('-', 104)\n",
        "('\"', 103)\n",
        "('?', 90)\n",
        "('(', 43)\n",
        "(')', 42)\n",
        "('3', 40)\n",
        "('%', 36)\n",
        "('\\xc2', 27)\n",
        "('\\xb0', 27)\n",
        "('\\x80', 17)\n",
        "('\\xe2', 17)\n",
        "('1', 17)\n",
        "('\\\\', 16)\n",
        "('5', 15)\n",
        "(';', 12)\n",
        "(':', 9)\n",
        "('\\x99', 8)\n",
        "('+', 7)\n",
        "('2', 7)\n",
        "('!', 7)\n",
        "('\\x93', 7)\n",
        "(\"'\", 6)\n",
        "('0', 4)\n",
        "('6', 4)\n",
        "('8', 2)\n",
        "('9', 2)\n",
        "('\\xa6', 2)\n",
        "('=', 2)\n",
        "('7', 1)\n",
        "('4', 1)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Windows\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Creating Windows \"\"\"\n",
      "def filter2min_word_freq(sentence):\n",
      "    return filter(lambda (w, tags4word): wd_sent_freq[w] >= MIN_SENTENCE_FREQ, sentence)\n",
      "\n",
      "VALID_CHARS = {\".\", \"?\", \"!\", \"=\", \"/\", \":\", \";\", \"&\", \"+\",  \"-\", \"=\",  \"%\", \"'\", \",\", \"\\\\\", \"(\", \")\", \"\\\"\"}\n",
      "\"\"\" Remove bad chars (see above - e.g. '\\x93') \"\"\"\n",
      "removed = set()\n",
      "def valid_wd(wd):\n",
      "    wd = wd.strip()\n",
      "    if len(wd) != 1:\n",
      "        return True\n",
      "    if wd in removed:\n",
      "        return False\n",
      "    if wd.isalpha() or wd.isdigit() or wd in VALID_CHARS:\n",
      "        return True\n",
      "    removed.add(wd)\n",
      "    return False\n",
      "    \n",
      "def filterout_punctuation(sentence):\n",
      "    return filter(lambda (w, tags4word): valid_wd(w), sentence)\n",
      "\n",
      "def bookend(sentence):\n",
      "    for i in range(MID_IX):\n",
      "        modified_sentence.insert(0, (SENTENCE_START,    set()))\n",
      "        modified_sentence.append(   (SENTENCE_END,      set()))\n",
      "\n",
      "def assert_windows_correct(windows):\n",
      "    lens = map(len, windows)\n",
      "    assert min(lens) == max(lens) == WINDOW_SIZE, \\\n",
      "            \"Windows are not all the correct size\"\n",
      "   \n",
      "ix2windows = {}\n",
      "ix2sents = {}\n",
      "sentences = []\n",
      "tokenized_sentences = []\n",
      "\n",
      "i = 0\n",
      "for essay in essays:\n",
      "    for sentence in essay.tagged_sentences:\n",
      "        \n",
      "        modified_sentence = filter2min_word_freq(sentence)\n",
      "        modified_sentence = filterout_punctuation(modified_sentence)\n",
      "        if len(modified_sentence) == 0:\n",
      "            continue\n",
      "        \n",
      "        bookend(modified_sentence)        \n",
      "        new_windows = split_into_windows(modified_sentence, window_size= WINDOW_SIZE)        \n",
      "        assert_windows_correct(new_windows)       \n",
      "        \n",
      "        # tagged words\n",
      "        sentences.append(sentence)\n",
      "        # words only\n",
      "        tokenized_sentences.append(zip(*sentence)[0])\n",
      "        \n",
      "        ix2windows[i] = new_windows\n",
      "        ix2sents[i] = modified_sentence\n",
      "        i += 1\n",
      "        \n",
      "\"\"\" Assert tags set correctly \"\"\"\n",
      "print \"Windows loaded correctly!\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Windows loaded correctly!\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sentence Level Features\n",
      "-----------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from gensim import matutils\n",
      "\n",
      "def filter_words(wd):\n",
      "    return wd.isalnum()\n",
      "\n",
      "docs = map(lambda sen : \" \".join(filter(filter_words,sen)),tokenized_sentences)\n",
      "\n",
      "#Vectorize\n",
      "vectorizer = TfidfVectorizer(use_idf = False, ngram_range = (1, 1), min_df = 5, binary=True)\n",
      "sentence_vectors = vectorizer.fit_transform(docs)\n",
      "sentence_vectors = sentence_vectors.todense()\n",
      "sentence_vectors = map(lambda s: s.tolist()[0], sentence_vectors)\n",
      "ix2vector = dict(enumerate(sentence_vectors))\n",
      "print len(ix2vector[0]), \"features\"\n",
      "#ix2vector[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "662 features\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Removed Characters\n",
      "------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(sorted(removed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n",
        "\ufffd\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract Features\n",
      "----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract Features \"\"\"\n",
      "from WindowFeatures import extract_positional_word_features, extract_word_features\n",
      "from NgramGenerator import compute_ngrams\n",
      "\n",
      "def extract_skip_b4_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[:mid_ix]:\n",
      "        feats[\"_BEFORE: \" + wd + \"|\" + target] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_skip_after_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for wd in window[mid_ix+1:]:\n",
      "        feats[\"_AFTER: \" + target + \"|\" + wd] = feature_val\n",
      "    return feats\n",
      "\n",
      "def extract_positional_bigram_features(window, mid_ix, feature_val = 1):\n",
      "    bi_grams = compute_ngrams(window, max_len = 2, min_len = 2)\n",
      "    d = {}\n",
      "    for i, bi_gram in enumerate(bi_grams):\n",
      "        d[\"BI\" + \":\" + str(-mid_ix + i) + \" \" + bi_gram[0] + \" | \" + bi_gram[1]] = feature_val\n",
      "    return d\n",
      "\n",
      "def extract_positional_skip_word_features(window, mid_ix, feature_val = 1):\n",
      "    feats = {}\n",
      "    target = window[mid_ix]\n",
      "    for i, wd in enumerate(window):\n",
      "        if i == mid_ix:\n",
      "            continue\n",
      "        a,b = wd,target\n",
      "        if i > mid_ix:\n",
      "            a,b = b,a\n",
      "        feats[\"SKIP:\" + str(-mid_ix + i) + \" \" + a + \" | \" + b] = feature_val\n",
      "    return feats\n",
      "\n",
      "\"\"\" TODO:\n",
      "        Extract features for numbers\n",
      "        Extract features for years\n",
      "        Extract features that are temperatures (look for degree\\degrees in subsequent words, along with C or F)\n",
      "\"\"\"\n",
      "idgen = IdGenerator()\n",
      "stemmer = PorterStemmer()\n",
      "\n",
      "def extract_features(words):\n",
      "    \n",
      "    if STEM:\n",
      "        words = [stemmer.stem(w) for w in words]\n",
      "    #Extract features for words\n",
      "    \n",
      "    \"\"\" Try only middle word \"\"\"\n",
      "    features = {}\n",
      "    ###\n",
      "    pos_features = extract_positional_word_features(words, MID_IX, feature_val=1)    \n",
      "    word_features  = extract_word_features(words, feature_val=1)\n",
      "    \n",
      "    #DO NOT HELP\n",
      "    #b4_features    = extract_skip_b4_word_features(words, MID_IX, feature_val=1)\n",
      "    #after_features = extract_skip_after_word_features(words, MID_IX, feature_val=1)\n",
      "    #pos_skip_grams = extract_positional_skip_word_features(words, MID_IX,  feature_val = 1)\n",
      "    pos_bi_grams = extract_positional_bigram_features(words, MID_IX, feature_val = 1)\n",
      "\n",
      "    features.update(pos_features)\n",
      "    features.update(word_features)\n",
      "    #features.update(b4_features)\n",
      "    #features.update(after_features)\n",
      "    #features.update(pos_skip_grams)\n",
      "    features.update(pos_bi_grams)\n",
      "    return features.items()\n",
      "\n",
      "def extract_ys_by_code(tags, ysByCode):\n",
      "    for code in all_codes:\n",
      "        ysByCode[code].append(1 if code in tags else 0 )    \n",
      "\n",
      "ix2ys = {}\n",
      "ix2feats = {}\n",
      "feat_counts = defaultdict(int)\n",
      "def tally_features(feats):\n",
      "    for k,v in feats:\n",
      "        feat_counts[k] += 1\n",
      "\n",
      "for i, windows in ix2windows.items():\n",
      "    feats = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    \n",
      "    ix2feats[i] = feats\n",
      "    ix2ys[i] = ysByCode\n",
      "    for window in windows:\n",
      "        # Get the words minus tags\n",
      "        words, tags = zip(*window)                \n",
      "        feat = extract_features(words)\n",
      "        tally_features(feat)\n",
      "        feats.append(feat)\n",
      "        \n",
      "        #Tags for middle word (target)\n",
      "        tags4word = tags[MID_IX]\n",
      "        extract_ys_by_code(tags4word, ysByCode)\n",
      "    assert len(windows) == len(feats)\n",
      "    assert all(map(lambda (k,v): len(v) == len(feats), ysByCode.items()))\n",
      "        \n",
      "\"\"\" Convert sparse dictionary features to sparse arrays \"\"\"\n",
      "ix2xs = {}\n",
      "for i, feature_lists in ix2feats.items():\n",
      "    xs = []\n",
      "    ix2xs[i] = xs\n",
      "    for feats in feature_lists:\n",
      "        x = [(idgen.get_id(f),v) \n",
      "             for f,v in feats \n",
      "             if feat_counts[f] >= MIN_FEAT_FREQ or f.startswith(\"WD:0\" )]\n",
      "        xs.append(x)        \n",
      "\n",
      "num_features = idgen.max_id() + 1\n",
      "print \"Number of features:\", num_features\n",
      "\n",
      "\"\"\" Convert to dense numpy arrays \"\"\"\n",
      "for i in ix2xs.keys():\n",
      "    xs = ix2xs[i]\n",
      "    xs = np.array([matutils.sparse2full(x, num_features) for x in xs])        \n",
      "    ix2xs[i] = xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of features: 14225\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DictionaryHelper import *\n",
      "\n",
      "def count_above(ft_counts, threshold):\n",
      "    above = [ v for k,v in ft_counts.items() if v >= threshold]\n",
      "    return (sum(above), len(above))\n",
      "\n",
      "total_all, cnt_all = count_above(feat_counts, 0)\n",
      "total_above, cnt_above = count_above(feat_counts, MIN_FEAT_FREQ)\n",
      "\n",
      "print \"Counts\"\n",
      "print \"all:     \", cnt_all\n",
      "print \"above:   \", cnt_above\n",
      "print \"% above: \", str(100.0 * cnt_above / float(cnt_all))+ \"%\"\n",
      "\n",
      "print \"\\nTotal Frequency\"\n",
      "print \"all:     \", total_all\n",
      "print \"above:   \", total_above\n",
      "print \"% above: \", str(100.0 * total_above / float(total_all))+ \"%\"\n",
      "\n",
      "#srtd = sort_by_value(feat_counts, reverse = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counts\n",
        "all:      69067\n",
        "above:    13921\n",
        "% above:  20.1557907539%\n",
        "\n",
        "Total Frequency\n",
        "all:      847306\n",
        "above:    764043\n",
        "% above:  90.1732077903%\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_window(win):\n",
      "    def set2str(st):\n",
      "        return \"{\" + str(t)[5:-2] + \"}\"\n",
      "    \n",
      "    w, tg = zip(*win)\n",
      "    lens = [max(len(wd),len(set2str(t))) for wd,t in win]\n",
      "    \n",
      "    for i, wd in enumerate(w):\n",
      "        print wd.ljust(lens[i]) , \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "    for i, t in enumerate(tg):\n",
      "        print set2str(t).ljust(lens[i]), \"|\",\n",
      "    print \"\"\n",
      "    \n",
      "def extract_features(window, feat_vals):\n",
      "    feats = [idgen.get_key(i) for i,val in enumerate(feat_vals) if val]\n",
      "    \n",
      "    wd_feats = []\n",
      "    for win in window:\n",
      "        wd, tgs = win\n",
      "        if STEM:\n",
      "            match = filter(lambda feat: \" \" + stemmer.stem(wd) + \" \" in \" \" + feat + \" \", feats)\n",
      "        else:\n",
      "            match = filter(lambda feat: \" \" + wd + \" \" in \" \" + feat + \" \", feats)\n",
      "        wd_feats.append((wd, match))\n",
      "    return wd_feats\n",
      "\n",
      "def print_features(wf):\n",
      "    w_f = wf\n",
      "    for w,ft in w_f:\n",
      "        print w.ljust(10), map(lambda s:s.ljust(10), sorted(ft, key=lambda s:(len(s),s)))\n",
      "    print \"\"\n",
      "\n",
      "#uncomment to verify code output\n",
      "\n",
      "sentence_no = 101\n",
      "print \"Tagged Windows\"\n",
      "for win in ix2windows[sentence_no][:5]:\n",
      "    print_window(win)\n",
      "print \"\"    \n",
      "\n",
      "print \"Features\"\n",
      "def prn_sent_features(sentence_num):\n",
      "    win = ix2windows[sentence_num]\n",
      "    for i in range(len(win)):\n",
      "        print \"[%s]\" % str(i)\n",
      "        wf = extract_features(win[i], ix2xs[sentence_num][i])\n",
      "        print_features(wf)\n",
      "\n",
      "prn_sent_features(sentence_no)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tagged Windows\n",
        "<START> | <START> | <START> | so | they | need | to | \n",
        "{}      | {}      | {}      | {} | {}   | {}   | {} | \n",
        "<START> | <START> | so | they | need | to | have | \n",
        "{}      | {}      | {} | {}   | {}   | {} | {}   | \n",
        "<START> | so | they | need | to | have | light | \n",
        "{}      | {} | {}   | {}   | {} | {}   | {}    | \n",
        "so | they | need | to | have | light | to | \n",
        "{} | {}   | {}   | {} | {}   | {}    | {} | \n",
        "they | need | to | have | light | to | eat | \n",
        "{}   | {}   | {} | {}   | {}    | {} | {}  | \n",
        "\n",
        "Features\n",
        "[0]\n",
        "<START>    [u'<START>   ', u'WD:-1 <START>', u'WD:-2 <START>', u'WD:-3 <START>', u'BI:-1 <START> | so', u'BI:-2 <START> | <START>', u'BI:-3 <START> | <START>']\n",
        "<START>    [u'<START>   ', u'WD:-1 <START>', u'WD:-2 <START>', u'WD:-3 <START>', u'BI:-1 <START> | so', u'BI:-2 <START> | <START>', u'BI:-3 <START> | <START>']\n",
        "<START>    [u'<START>   ', u'WD:-1 <START>', u'WD:-2 <START>', u'WD:-3 <START>', u'BI:-1 <START> | so', u'BI:-2 <START> | <START>', u'BI:-3 <START> | <START>']\n",
        "so         [u'so        ', u'WD:0 so   ', u'BI:0 so | they', u'BI:-1 <START> | so']\n",
        "they       [u'they      ', u'WD:1 they ', u'BI:0 so | they', u'BI:1 they | need']\n",
        "need       [u'need      ', u'WD:2 need ', u'BI:2 need | to', u'BI:1 they | need']\n",
        "to         [u'to        ', u'WD:3 to   ', u'BI:2 need | to']\n",
        "\n",
        "[1]\n",
        "<START>    [u'<START>   ', u'WD:-2 <START>', u'WD:-3 <START>', u'BI:-2 <START> | so', u'BI:-3 <START> | <START>']\n",
        "<START>    [u'<START>   ', u'WD:-2 <START>', u'WD:-3 <START>', u'BI:-2 <START> | so', u'BI:-3 <START> | <START>']\n",
        "so         [u'so        ', u'WD:-1 so  ', u'BI:-1 so | they', u'BI:-2 <START> | so']\n",
        "they       [u'they      ', u'WD:0 they ', u'BI:-1 so | they', u'BI:0 they | need']\n",
        "need       [u'need      ', u'WD:1 need ', u'BI:1 need | to', u'BI:0 they | need']\n",
        "to         [u'to        ', u'WD:2 to   ', u'BI:1 need | to', u'BI:2 to | have']\n",
        "have       [u'have      ', u'WD:3 have ', u'BI:2 to | have']\n",
        "\n",
        "[2]\n",
        "<START>    [u'<START>   ', u'WD:-3 <START>', u'BI:-3 <START> | so']\n",
        "so         [u'so        ', u'WD:-2 so  ', u'BI:-2 so | they', u'BI:-3 <START> | so']\n",
        "they       [u'they      ', u'WD:-1 they', u'BI:-2 so | they', u'BI:-1 they | need']\n",
        "need       [u'need      ', u'WD:0 need ', u'BI:0 need | to', u'BI:-1 they | need']\n",
        "to         [u'to        ', u'WD:1 to   ', u'BI:0 need | to', u'BI:1 to | have']\n",
        "have       [u'have      ', u'WD:2 have ', u'BI:1 to | have']\n",
        "light      [u'light     ', u'WD:3 light']\n",
        "\n",
        "[3]\n",
        "so         [u'so        ', u'WD:-3 so  ', u'BI:-3 so | they']\n",
        "they       [u'they      ', u'WD:-2 they', u'BI:-3 so | they', u'BI:-2 they | need']\n",
        "need       [u'need      ', u'WD:-1 need', u'BI:-1 need | to', u'BI:-2 they | need']\n",
        "to         [u'to        ', u'WD:0 to   ', u'WD:3 to   ', u'BI:0 to | have', u'BI:-1 need | to', u'BI:2 light | to']\n",
        "have       [u'have      ', u'WD:1 have ', u'BI:0 to | have']\n",
        "light      [u'light     ', u'WD:2 light', u'BI:2 light | to']\n",
        "to         [u'to        ', u'WD:0 to   ', u'WD:3 to   ', u'BI:0 to | have', u'BI:-1 need | to', u'BI:2 light | to']\n",
        "\n",
        "[4]\n",
        "they       [u'they      ', u'WD:-3 they', u'BI:-3 they | need']\n",
        "need       [u'need      ', u'WD:-2 need', u'BI:-2 need | to', u'BI:-3 they | need']\n",
        "to         [u'to        ', u'WD:2 to   ', u'WD:-1 to  ', u'BI:2 to | eat', u'BI:-1 to | have', u'BI:-2 need | to', u'BI:1 light | to']\n",
        "have       [u'have      ', u'WD:0 have ', u'BI:-1 to | have']\n",
        "light      [u'light     ', u'WD:1 light', u'BI:1 light | to']\n",
        "to         [u'to        ', u'WD:2 to   ', u'WD:-1 to  ', u'BI:2 to | eat', u'BI:-1 to | have', u'BI:-2 need | to', u'BI:1 light | to']\n",
        "eat        [u'eat       ', u'WD:3 eat  ', u'BI:2 to | eat']\n",
        "\n",
        "[5]\n",
        "need       [u'need      ', u'WD:-3 need', u'BI:-3 need | to']\n",
        "to         [u'to        ', u'WD:1 to   ', u'WD:-2 to  ', u'BI:1 to | eat', u'BI:-2 to | have', u'BI:-3 need | to', u'BI:0 light | to']\n",
        "have       [u'have      ', u'WD:-1 have', u'BI:-2 to | have']\n",
        "light      [u'light     ', u'WD:0 light', u'BI:0 light | to']\n",
        "to         [u'to        ', u'WD:1 to   ', u'WD:-2 to  ', u'BI:1 to | eat', u'BI:-2 to | have', u'BI:-3 need | to', u'BI:0 light | to']\n",
        "eat        [u'eat       ', u'WD:2 eat  ', u'BI:2 eat | .', u'BI:1 to | eat']\n",
        ".          [u'.         ', u'WD:3 .    ', u'BI:2 eat | .']\n",
        "\n",
        "[6]\n",
        "to         [u'to        ', u'WD:0 to   ', u'WD:-3 to  ', u'BI:0 to | eat', u'BI:-3 to | have', u'BI:-1 light | to']\n",
        "have       [u'have      ', u'WD:-2 have', u'BI:-3 to | have']\n",
        "light      [u'light     ', u'WD:-1 light', u'BI:-1 light | to']\n",
        "to         [u'to        ', u'WD:0 to   ', u'WD:-3 to  ', u'BI:0 to | eat', u'BI:-3 to | have', u'BI:-1 light | to']\n",
        "eat        [u'eat       ', u'WD:1 eat  ', u'BI:1 eat | .', u'BI:0 to | eat']\n",
        ".          [u'.         ', u'WD:2 .    ', u'BI:1 eat | .', u'BI:2 . | <END>']\n",
        "<END>      [u'<END>     ', u'WD:3 <END>', u'BI:2 . | <END>']\n",
        "\n",
        "[7]\n",
        "have       [u'have      ', u'WD:-3 have']\n",
        "light      [u'light     ', u'WD:-2 light', u'BI:-2 light | to']\n",
        "to         [u'to        ', u'WD:-1 to  ', u'BI:-1 to | eat', u'BI:-2 light | to']\n",
        "eat        [u'eat       ', u'WD:0 eat  ', u'BI:0 eat | .', u'BI:-1 to | eat']\n",
        ".          [u'.         ', u'WD:1 .    ', u'BI:0 eat | .', u'BI:1 . | <END>']\n",
        "<END>      [u'<END>     ', u'WD:2 <END>', u'WD:3 <END>', u'BI:1 . | <END>', u'BI:2 <END> | <END>']\n",
        "<END>      [u'<END>     ', u'WD:2 <END>', u'WD:3 <END>', u'BI:1 . | <END>', u'BI:2 <END> | <END>']\n",
        "\n",
        "[8]\n",
        "light      [u'light     ', u'WD:-3 light', u'BI:-3 light | to']\n",
        "to         [u'to        ', u'WD:-2 to  ', u'BI:-2 to | eat', u'BI:-3 light | to']\n",
        "eat        [u'eat       ', u'WD:-1 eat ', u'BI:-1 eat | .', u'BI:-2 to | eat']\n",
        ".          [u'.         ', u'WD:0 .    ', u'BI:-1 eat | .', u'BI:0 . | <END>']\n",
        "<END>      [u'<END>     ', u'WD:1 <END>', u'WD:2 <END>', u'WD:3 <END>', u'BI:0 . | <END>', u'BI:1 <END> | <END>', u'BI:2 <END> | <END>']\n",
        "<END>      [u'<END>     ', u'WD:1 <END>', u'WD:2 <END>', u'WD:3 <END>', u'BI:0 . | <END>', u'BI:1 <END> | <END>', u'BI:2 <END> | <END>']\n",
        "<END>      [u'<END>     ', u'WD:1 <END>', u'WD:2 <END>', u'WD:3 <END>', u'BI:0 . | <END>', u'BI:1 <END> | <END>', u'BI:2 <END> | <END>']\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the Data\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_xs_ys(ixs, ixTOxs, ixTOys, codes):\n",
      "    xs = []\n",
      "    ysByCode = defaultdict(list)\n",
      "    for i in ixs:\n",
      "        xs_tmp = ixTOxs[i]\n",
      "        xs.extend(xs_tmp)\n",
      "        ysByCode_tmp = ixTOys[i]\n",
      "        for code in codes:\n",
      "            ysByCode[code].extend(ysByCode_tmp[code])\n",
      "    return (np.array(xs), ysByCode)\n",
      "\n",
      "num_train = int(len(sentences) * (1.0 - PCT_VALIDATION))\n",
      "\n",
      "ixtest  = ix2sents.keys()[:num_train]\n",
      "ixvalid = ix2sents.keys()[num_train:]\n",
      "\n",
      "# Extract flattened windows for training data as xs and ys\n",
      "x_t, yByCode_t = extract_xs_ys(ixtest,ix2xs, ix2ys, all_codes)\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"#Sentences : \" + str(len(sentences))\n",
      "print \"\"\n",
      "\n",
      "all_codes = sorted(all_codes, key= lambda s :(len(s), s))\n",
      "for code in all_codes:\n",
      "    print code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#Sentences : 2712\n",
        "\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "50\n",
        "5b\n",
        "it\n",
        "other\n",
        "Causer\n",
        "Result\n",
        "Anaphor\n",
        "explicit\n",
        "rhetorical\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train\n",
      "====="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class factMach(object):\n",
      "    def __init__(self):\n",
      "        self.fm = pylibfm.FM(num_factors=50, num_iter=10, task=\"regression\", shuffle_training=True)\n",
      "        \n",
      "    def __to_sparse_(self, xs):\n",
      "        from scipy import sparse\n",
      "        return sparse.csr_matrix(np.asarray(xs, dtype=np.double))\n",
      "    \n",
      "    def fit(self, xs, ys):\n",
      "        return self.fm.fit(self.__to_sparse_(xs), np.asarray(ys, dtype=np.double))\n",
      "    \n",
      "    def predict(self, xs):\n",
      "        return np.round(self.fm.predict(self.__to_sparse_(xs)))\n",
      "        #return self.fm.predict(self.__to_sparse_(xs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" TRAIN \"\"\"\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "map_svm = lambda y: -1 if y < 0 else 1\n",
      "map_reg = lambda y: y\n",
      "\n",
      "#map_y = map_svm\n",
      "map_y = map_reg\n",
      "\n",
      "def make_cls():\n",
      "    #cls = DecisionTreeClassifier(max_depth=10, min_samples_leaf=10, criterion=\"entropy\")\n",
      "    #cls = DecisionTreeClassifier(criterion=\"entropy\")\n",
      "    #cls = LogisticRegression()\n",
      "    #cls = RidgeClassifier()\n",
      "    #cls = KNeighborsClassifier(n_neighbors=5) # TOO SLOW!\n",
      "    #cls = LDA()\n",
      "    #cls = SVC()\n",
      "    #cls = RandomForestClassifier(n_jobs=-1, max_depth=100, n_estimators=10)\n",
      "    #cls = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=1)\n",
      "    #cls = Ridge()\n",
      "    cls = LinearSVC()\n",
      "    #cls = factMach()\n",
      "    return cls\n",
      "\n",
      "print \"Starting Training\"\n",
      "reg_codes = [c for c in all_codes if c.isdigit() or c == \"explicit\"]\n",
      "\n",
      "def train(codes, xs, yByCode, fn_create_cls):\n",
      "    code2classifier = {}\n",
      "    for code in codes:\n",
      "        print \"Training for :\", code   \n",
      "        cls = fn_create_cls()\n",
      "        code2classifier[code] = cls\n",
      "        ys = np.asarray(yByCode[code])    \n",
      "        ys = map(map_y, ys)\n",
      "        cls.fit(xs, ys)\n",
      "    return code2classifier\n",
      "\n",
      "code2cls = train(all_codes, x_t, yByCode_t, make_cls)\n",
      "print cls\n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting Training\n",
        "Training for : 1\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "GradientBoostingClassifier(init=None, learning_rate=0.5, loss='deviance',\n",
        "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
        "              min_samples_leaf=1, min_samples_split=2, n_estimators=25,\n",
        "              random_state=None, subsample=1.0, verbose=0,\n",
        "              warm_start=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classify\n",
      "--------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Get sentence level classification performance \"\"\"\n",
      "def test_for_code(code, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    cls = codeToClassifier[code]\n",
      "    \n",
      "    try:\n",
      "        cls.n_jobs = 1\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "    act_ys  = []\n",
      "    pred_ys = []\n",
      "    for ix in ixs:\n",
      "        xs = ixToXs[ix]\n",
      "        ysByCode = ixToYs[ix]\n",
      "        \n",
      "        ys = np.asarray(ysByCode[code])\n",
      "        ys = map(map_y, ys)\n",
      "        pred = cls.predict(xs)\n",
      "        \n",
      "        # Flatten predictions to sentence level by taking the max values\n",
      "        # over all windows\n",
      "        act_ys.append(max(ys))\n",
      "        pred_ys.append(max(pred))\n",
      "    \n",
      "    num_codes = len([y for y in act_ys if y == 1])\n",
      "    r,p,f1,a = rpf1a(act_ys, pred_ys)\n",
      "    print \"code:      \", code\n",
      "    print \"recall:    \", r\n",
      "    print \"precision: \", p\n",
      "    print \"f1:        \", f1\n",
      "    print \"accuracy:  \", a\n",
      "    print \"sentences: \", num_codes\n",
      "    print \"\"\n",
      "    return rpfa(r,p,f1,a,num_codes)\n",
      "\n",
      "print \"\"\n",
      "print \"total sent:\", len(ixvalid)\n",
      "print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "total sent: 678\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training Data Performance\n",
      "-------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test(codes, ixs, ixToXs, ixToYs, codeToClassifier):\n",
      "    td_metrics = []\n",
      "    for c in codes:\n",
      "        cls = codeToClassifier[c]\n",
      "        td_metrics.append(test_for_code(c, ixs, ixToXs, ixToYs, codeToClassifier))\n",
      "    td_wt_mn_prfa = weighted_mean_rpfa(td_metrics)\n",
      "    print type(cls), td_wt_mn_prfa\n",
      "    return td_wt_mn_prfa\n",
      "\n",
      "print \"Training Data: \"\n",
      "metrics = test(all_codes, ixtest, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     0.990909090909\n",
        "precision:  0.935622317597\n",
        "f1:         0.962472406181\n",
        "accuracy:   0.991642084562\n",
        "sentences:  220\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.901960784314\n",
        "precision:  0.836363636364\n",
        "f1:         0.867924528302\n",
        "accuracy:   0.993117010816\n",
        "sentences:  51\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.982014388489\n",
        "precision:  0.886363636364\n",
        "f1:         0.931740614334\n",
        "accuracy:   0.980334316618\n",
        "sentences:  278\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     1.0\n",
        "precision:  0.872727272727\n",
        "f1:         0.932038834951\n",
        "accuracy:   0.996558505408\n",
        "sentences:  48\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     0.727272727273\n",
        "precision:  0.972972972973\n",
        "f1:         0.832369942197\n",
        "accuracy:   0.985742379548\n",
        "sentences:  99\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     0.703703703704\n",
        "precision:  0.174311926606\n",
        "f1:         0.279411764706\n",
        "accuracy:   0.951819075713\n",
        "sentences:  27\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     0.96875\n",
        "precision:  0.81045751634\n",
        "f1:         0.88256227758\n",
        "accuracy:   0.983775811209\n",
        "sentences:  128\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     0.979591836735\n",
        "precision:  1.0\n",
        "f1:         0.989690721649\n",
        "accuracy:   0.999508357915\n",
        "sentences:  49\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     0.727272727273\n",
        "precision:  1.0\n",
        "f1:         0.842105263158\n",
        "accuracy:   0.997050147493\n",
        "sentences:  22\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     0.881355932203\n",
        "precision:  0.881355932203\n",
        "f1:         0.881355932203\n",
        "accuracy:   0.993117010816\n",
        "sentences:  59\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     0.904761904762\n",
        "precision:  0.633333333333\n",
        "f1:         0.745098039216\n",
        "accuracy:   0.993608652901\n",
        "sentences:  21\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.979139504563\n",
        "precision:  0.943467336683\n",
        "f1:         0.960972488804\n",
        "accuracy:   0.970009832842\n",
        "sentences:  767\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5b\n",
        "recall:     0.909090909091\n",
        "precision:  0.714285714286\n",
        "f1:         0.8\n",
        "accuracy:   0.997541789577\n",
        "sentences:  11\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " it\n",
        "recall:     1.0\n",
        "precision:  1.0\n",
        "f1:         1.0\n",
        "accuracy:   1.0\n",
        "sentences:  1\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " other\n",
        "recall:     0.105555555556\n",
        "precision:  0.863636363636\n",
        "f1:         0.188118811881\n",
        "accuracy:   0.919370698132\n",
        "sentences:  180\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Causer\n",
        "recall:     0.616113744076\n",
        "precision:  0.899653979239\n",
        "f1:         0.731364275668\n",
        "accuracy:   0.906096361849\n",
        "sentences:  422\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Result\n",
        "recall:     0.619489559165\n",
        "precision:  0.652811735941\n",
        "f1:         0.635714285714\n",
        "accuracy:   0.849557522124\n",
        "sentences:  431\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Anaphor\n",
        "recall:     0.169811320755\n",
        "precision:  0.310344827586\n",
        "f1:         0.219512195122\n",
        "accuracy:   0.937069813176\n",
        "sentences:  106\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.563926940639\n",
        "precision:  0.904761904762\n",
        "f1:         0.694796061885\n",
        "accuracy:   0.89331366765\n",
        "sentences:  438\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rhetorical\n",
        "recall:     0.839160839161\n",
        "precision:  0.845070422535\n",
        "f1:         0.842105263158\n",
        "accuracy:   0.977876106195\n",
        "sentences:  143\n",
        "\n",
        "<class '__main__.factMach'> Recall: 0.7506, Precision: 0.8503, F1: 0.7737, Accuracy: 0.9395, Codes:  3501\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Validation Data Performance\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data: \"\n",
      "test(reg_codes, ixvalid, ix2xs, ix2ys, code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "recall:     0.946808510638\n",
        "precision:  0.760683760684\n",
        "f1:         0.843601895735\n",
        "accuracy:   0.951327433628\n",
        "sentences:  94\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "recall:     0.58064516129\n",
        "precision:  0.620689655172\n",
        "f1:         0.6\n",
        "accuracy:   0.964601769912\n",
        "sentences:  31\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "recall:     0.866141732283\n",
        "precision:  0.658682634731\n",
        "f1:         0.748299319728\n",
        "accuracy:   0.890855457227\n",
        "sentences:  127\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "recall:     0.913043478261\n",
        "precision:  0.7\n",
        "f1:         0.792452830189\n",
        "accuracy:   0.983775811209\n",
        "sentences:  23\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "recall:     0.8\n",
        "precision:  0.5\n",
        "f1:         0.615384615385\n",
        "accuracy:   0.933628318584\n",
        "sentences:  45\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "recall:     1.0\n",
        "precision:  0.4\n",
        "f1:         0.571428571429\n",
        "accuracy:   0.986725663717\n",
        "sentences:  6\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "recall:     0.80303030303\n",
        "precision:  0.552083333333\n",
        "f1:         0.654320987654\n",
        "accuracy:   0.917404129794\n",
        "sentences:  66\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "recall:     0.823529411765\n",
        "precision:  1.0\n",
        "f1:         0.903225806452\n",
        "accuracy:   0.995575221239\n",
        "sentences:  17\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "recall:     0.857142857143\n",
        "precision:  1.0\n",
        "f1:         0.923076923077\n",
        "accuracy:   0.997050147493\n",
        "sentences:  14\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "recall:     0.866666666667\n",
        "precision:  0.742857142857\n",
        "f1:         0.8\n",
        "accuracy:   0.980825958702\n",
        "sentences:  30\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "recall:     0.8125\n",
        "precision:  0.764705882353\n",
        "f1:         0.787878787879\n",
        "accuracy:   0.989675516224\n",
        "sentences:  16\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50\n",
        "recall:     0.979452054795\n",
        "precision:  0.913738019169\n",
        "f1:         0.945454545455\n",
        "accuracy:   0.951327433628\n",
        "sentences:  292\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.649122807018\n",
        "precision:  0.506849315068\n",
        "f1:         0.569230769231\n",
        "accuracy:   0.752212389381\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.8530, Precision: 0.7198, F1: 0.7766, Accuracy: 0.9079, Codes:   932\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "Recall: 0.8530, Precision: 0.7198, F1: 0.7766, Accuracy: 0.9079, Codes:   932"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Window - 5, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LDA:      Recall: 0.8927, Precision: 0.6974, F1: 0.7675, Accuracy: 0.8823, Codes:   792\n",
      "LinSVC:   Recall: 0.7601, Precision: 0.7655, F1: 0.7563, Accuracy: 0.9048, Codes:   792\n",
      "DT:       Recall: 0.7462, Precision: 0.6890, F1: 0.7063, Accuracy: 0.8766, Codes:   792\n",
      "RidgeClf: Recall: 0.6843, Precision: 0.8359, F1: 0.6874, Accuracy: 0.9036, Codes:   795\n",
      "\n",
      "LinSVC\n",
      "Window - 7, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "LinSVC: Recall: 0.7937, Precision: 0.7522, F1: 0.7677, Accuracy: 0.9037, Codes:   795\n",
      "\n",
      "Window - 9, Min sent freq - 6, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.7887, Precision: 0.7338, F1: 0.7555, Accuracy: 0.8929, Codes:   795\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "Recall: 0.8058, Precision: 0.7559, F1: 0.7756, Accuracy: 0.9046, Codes:   798\n",
      "\n",
      "-- Starting adding new features, messing with feature freq\n",
      "Window - 5, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8008, Precision: 0.7369, F1: 0.7625, Accuracy: 0.9008, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 10\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8120, Precision: 0.7535, F1: 0.7779, Accuracy: 0.9066, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - ***15***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8145, Precision: 0.7460, F1: 0.7744, Accuracy: 0.9040, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 20\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7982, Precision: 0.7496, F1: 0.7685, Accuracy: 0.9025, Codes:   798\n",
      "\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 25\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.8070, Precision: 0.7485, F1: 0.7732, Accuracy: 0.9047, Codes:   798\n",
      "\n",
      "***\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 5 ***\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "    + Positional BI-GRAMS ****\n",
      "Recall: 0.8145, Precision: 0.7642, F1: 0.7831, Accuracy: 0.9070, Codes:   798\n",
      "***\n",
      "\n",
      "Logistic Regression\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7306, Precision: 0.8298, F1: 0.7672, Accuracy: 0.9150, Codes:   798\n",
      "\n",
      "Window - 9, Min sent freq - 2, 'reg codes (numeric and 'explicit') Min Feature Freq - 15\n",
      "    + ALL WDS IN WINDOW (ingoring posn)\n",
      "Recall: 0.7206, Precision: 0.8232, F1: 0.7580, Accuracy: 0.9121, Codes:   798\n",
      "\n",
      "RF\n",
      "Window - 7, Min sent freq - 2, 'reg codes (numeric and 'explicit')\n",
      "Recall: 0.6028, Precision: 0.8071, F1: 0.6570, Accuracy: 0.8978, Codes:   798"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train Stacked Classifier\n",
      "========================"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Create Data Using Previous Classifier \"\"\"\n",
      "ix2newxs = {}\n",
      "ix2newys = {} #dict to dict to list\n",
      "\n",
      "CAUSAL_REL = \"CRel\"\n",
      "RESULT_REL = \"RRel\"\n",
      "CAUSE_RESULT = \"C->R\"\n",
      "\n",
      "cr_codes = [CAUSAL_REL, RESULT_REL, CAUSE_RESULT]\n",
      "tally = defaultdict(lambda: defaultdict(int))\n",
      "codes_per_row = []\n",
      "str_codes = []\n",
      "for i,xs in ix2xs.items():\n",
      "    \n",
      "    tmp_xs = []\n",
      "    tmp_ys = []\n",
      "    tmp_ys_by_code = defaultdict(list)\n",
      "\n",
      "    # add BOW features\n",
      "    tmp_xs.extend(ix2vector[i])\n",
      "    \n",
      "    un_codes = set()\n",
      "    un_pred_codes = set()\n",
      "    s_codes = \"|\"\n",
      "    for code in all_codes:\n",
      "        cls = code2cls[code]\n",
      "        pred = cls.decision_function(xs)\n",
      "        # add min and max values\n",
      "        mx = max(pred)\n",
      "        mn = min(pred)\n",
      "        diff = mx - mn\n",
      "        yes_no = max(cls.predict(xs))\n",
      "        \n",
      "        tmp_xs.append(mx)\n",
      "        tmp_xs.append(mn)\n",
      "        #tmp_xs.append(diff)\n",
      "        tmp_xs.append(yes_no)\n",
      "        \n",
      "        y_val = max(ix2ys[i][code])\n",
      "        tmp_ys_by_code[code] = np.array([y_val])\n",
      "        if y_val > 0:\n",
      "            un_codes.add(code)\n",
      "\n",
      "        if yes_no > 0:\n",
      "            un_pred_codes.add(code)\n",
      "            s_codes += code + \"|\"\n",
      "    codes_per_row.append(un_pred_codes)\n",
      "    str_codes.append(s_codes)\n",
      "    \n",
      "    #add 2 way feature combos\n",
      "    for a in all_codes:\n",
      "        for b in all_codes:\n",
      "            if b < a:\n",
      "                if a in un_pred_codes and b in un_pred_codes:\n",
      "                    tmp_xs.append(1)\n",
      "                else:\n",
      "                    tmp_xs.append(0)\n",
      "            #if (\"|%s|%s|\" %(a,b)) in s_codes:\n",
      "            #    tmp_xs.append(1)\n",
      "            #else:\n",
      "            #    tmp_xs.append(0)            \n",
      "            \n",
      "    tmp_ys_by_code[CAUSAL_REL] = np.array([ 1 if \"Causer\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[RESULT_REL] = np.array([ 1 if \"Result\" in un_codes and \"explicit\" in un_codes else 0 ])\n",
      "    tmp_ys_by_code[CAUSE_RESULT] = np.array([ 1 if (\"Result\" in un_codes and \"explicit\" in un_codes and \"Causer\" in un_codes) else 0 ])\n",
      "    \n",
      "    for k,v in tmp_ys_by_code.items():\n",
      "        tally[k][max(v)] += 1\n",
      "        \n",
      "    ix2newxs[i] = np.array([tmp_xs])\n",
      "    ix2newys[i] = tmp_ys_by_code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,s in enumerate(str_codes):\n",
      "    print str(i).ljust(5), s\n",
      "    if i > 200:\n",
      "        #break\n",
      "        pass\n",
      "#print ix2newxs[15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     |50|\n",
        "1     |50|\n",
        "2     |\n",
        "3     |\n",
        "4     |\n",
        "5     |1|\n",
        "6     |\n",
        "7     |\n",
        "8     |\n",
        "9     |\n",
        "10    |\n",
        "11    |\n",
        "12    |\n",
        "13    |\n",
        "14    |\n",
        "15    |7|50|Causer|Result|explicit|\n",
        "16    |50|\n",
        "17    |1|\n",
        "18    |2|\n",
        "19    |\n",
        "20    |\n",
        "21    |\n",
        "22    |\n",
        "23    |\n",
        "24    |\n",
        "25    |7|50|Causer|Result|explicit|\n",
        "26    |50|\n",
        "27    |7|50|Causer|Result|explicit|\n",
        "28    |50|\n",
        "29    |50|\n",
        "30    |7|50|Causer|Result|explicit|\n",
        "31    |\n",
        "32    |50|\n",
        "33    |3|Causer|rhetorical|\n",
        "34    |\n",
        "35    |\n",
        "36    |\n",
        "37    |6|50|Causer|Result|explicit|rhetorical|\n",
        "38    |\n",
        "39    |\n",
        "40    |\n",
        "41    |\n",
        "42    |\n",
        "43    |50|\n",
        "44    |\n",
        "45    |\n",
        "46    |50|\n",
        "47    |3|\n",
        "48    |1|50|Causer|Result|explicit|\n",
        "49    |1|50|Causer|Result|explicit|\n",
        "50    |1|3|50|Causer|Result|explicit|rhetorical|\n",
        "51    |3|\n",
        "52    |2|3|Causer|Result|explicit|\n",
        "53    |1|3|Causer|Result|explicit|\n",
        "54    |3|50|explicit|\n",
        "55    |50|Result|\n",
        "56    |\n",
        "57    |Causer|Result|Anaphor|explicit|rhetorical|\n",
        "58    |1|2|Anaphor|\n",
        "59    |explicit|\n",
        "60    |1|other|rhetorical|\n",
        "61    |3|explicit|rhetorical|\n",
        "62    |\n",
        "63    |1|50|\n",
        "64    |1|\n",
        "65    |\n",
        "66    |\n",
        "67    |3|50|Causer|Result|explicit|\n",
        "68    |50|\n",
        "69    |\n",
        "70    |50|\n",
        "71    |50|\n",
        "72    |50|\n",
        "73    |50|\n",
        "74    |50|\n",
        "75    |50|\n",
        "76    |50|\n",
        "77    |\n",
        "78    |50|\n",
        "79    |\n",
        "80    |\n",
        "81    |\n",
        "82    |\n",
        "83    |\n",
        "84    |7|50|Causer|explicit|\n",
        "85    |\n",
        "86    |7|50|other|Causer|Result|explicit|rhetorical|\n",
        "87    |\n",
        "88    |\n",
        "89    |\n",
        "90    |\n",
        "91    |50|\n",
        "92    |50|\n",
        "93    |\n",
        "94    |\n",
        "95    |\n",
        "96    |\n",
        "97    |\n",
        "98    |50|\n",
        "99    |\n",
        "100   |\n",
        "101   |\n",
        "102   |1|other|\n",
        "103   |50|Causer|Result|explicit|rhetorical|\n",
        "104   |\n",
        "105   |50|\n",
        "106   |7|50|Causer|Result|explicit|\n",
        "107   |\n",
        "108   |50|\n",
        "109   |\n",
        "110   |50|\n",
        "111   |\n",
        "112   |7|50|other|Causer|Result|explicit|\n",
        "113   |50|Causer|Result|explicit|rhetorical|\n",
        "114   |\n",
        "115   |\n",
        "116   |Result|rhetorical|\n",
        "117   |\n",
        "118   |3|4|Causer|Result|explicit|\n",
        "119   |7|50|Result|explicit|\n",
        "120   |3|50|Causer|Result|explicit|\n",
        "121   |1|\n",
        "122   |\n",
        "123   |\n",
        "124   |50|\n",
        "125   |50|\n",
        "126   |50|\n",
        "127   |7|50|Causer|Result|explicit|\n",
        "128   |7|50|Causer|Result|explicit|\n",
        "129   |\n",
        "130   |\n",
        "131   |11|\n",
        "132   |50|\n",
        "133   |50|\n",
        "134   |\n",
        "135   |\n",
        "136   |\n",
        "137   |\n",
        "138   |50|\n",
        "139   |\n",
        "140   |\n",
        "141   |\n",
        "142   |3|\n",
        "143   |\n",
        "144   |\n",
        "145   |50|\n",
        "146   |50|\n",
        "147   |\n",
        "148   |\n",
        "149   |50|\n",
        "150   |\n",
        "151   |50|Result|\n",
        "152   |1|Causer|Result|explicit|rhetorical|\n",
        "153   |3|\n",
        "154   |50|\n",
        "155   |1|3|\n",
        "156   |1|\n",
        "157   |3|\n",
        "158   |\n",
        "159   |4|50|other|Causer|Result|explicit|\n",
        "160   |4|50|Causer|Result|explicit|rhetorical|\n",
        "161   |50|\n",
        "162   |\n",
        "163   |\n",
        "164   |\n",
        "165   |\n",
        "166   |Anaphor|\n",
        "167   |\n",
        "168   |Anaphor|\n",
        "169   |Anaphor|\n",
        "170   |\n",
        "171   |3|50|Causer|Result|explicit|\n",
        "172   |\n",
        "173   |50|\n",
        "174   |50|\n",
        "175   |1|50|\n",
        "176   |50|\n",
        "177   |\n",
        "178   |1|50|Causer|Result|explicit|\n",
        "179   |\n",
        "180   |\n",
        "181   |\n",
        "182   |1|\n",
        "183   |\n",
        "184   |\n",
        "185   |50|Result|\n",
        "186   |\n",
        "187   |\n",
        "188   |50|\n",
        "189   |50|\n",
        "190   |50|\n",
        "191   |50|\n",
        "192   |50|\n",
        "193   |50|\n",
        "194   |50|\n",
        "195   |50|\n",
        "196   |50|\n",
        "197   |\n",
        "198   |\n",
        "199   |\n",
        "200   |\n",
        "201   |50|\n",
        "202   |\n",
        "203   |\n",
        "204   |\n",
        "205   |\n",
        "206   |\n",
        "207   |\n",
        "208   |\n",
        "209   |\n",
        "210   |\n",
        "211   |50|\n",
        "212   |\n",
        "213   |50|\n",
        "214   |3|50|Result|explicit|\n",
        "215   |\n",
        "216   |\n",
        "217   |\n",
        "218   |11|50|Causer|Result|explicit|\n",
        "219   |\n",
        "220   |13|\n",
        "221   |\n",
        "222   |1|50|Causer|explicit|\n",
        "223   |\n",
        "224   |1|\n",
        "225   |\n",
        "226   |50|\n",
        "227   |\n",
        "228   |\n",
        "229   |\n",
        "230   |\n",
        "231   |50|Causer|Anaphor|explicit|\n",
        "232   |Causer|Anaphor|\n",
        "233   |\n",
        "234   |\n",
        "235   |50|\n",
        "236   |50|Result|\n",
        "237   |1|Causer|\n",
        "238   |3|Causer|Result|explicit|rhetorical|\n",
        "239   |\n",
        "240   |\n",
        "241   |\n",
        "242   |50|\n",
        "243   |\n",
        "244   |\n",
        "245   |13|\n",
        "246   |\n",
        "247   |11|12|Causer|Result|explicit|\n",
        "248   |13|\n",
        "249   |\n",
        "250   |Anaphor|\n",
        "251   |\n",
        "252   |\n",
        "253   |11|Anaphor|\n",
        "254   |50|\n",
        "255   |3|50|Causer|Result|explicit|\n",
        "256   |1|\n",
        "257   |\n",
        "258   |3|\n",
        "259   |\n",
        "260   |\n",
        "261   |\n",
        "262   |1|\n",
        "263   |1|\n",
        "264   |\n",
        "265   |1|\n",
        "266   |\n",
        "267   |\n",
        "268   |3|\n",
        "269   |50|\n",
        "270   |\n",
        "271   |\n",
        "272   |50|\n",
        "273   |\n",
        "274   |\n",
        "275   |11|\n",
        "276   |1|50|Causer|explicit|\n",
        "277   |1|\n",
        "278   |50|\n",
        "279   |50|\n",
        "280   |\n",
        "281   |\n",
        "282   |\n",
        "283   |\n",
        "284   |50|\n",
        "285   |50|\n",
        "286   |\n",
        "287   |50|Result|\n",
        "288   |\n",
        "289   |5|\n",
        "290   |\n",
        "291   |\n",
        "292   |\n",
        "293   |11|Causer|explicit|\n",
        "294   |12|Result|explicit|\n",
        "295   |13|14|Result|\n",
        "296   |\n",
        "297   |\n",
        "298   |\n",
        "299   |\n",
        "300   |1|\n",
        "301   |\n",
        "302   |\n",
        "303   |50|\n",
        "304   |50|\n",
        "305   |\n",
        "306   |\n",
        "307   |\n",
        "308   |50|\n",
        "309   |50|\n",
        "310   |6|7|Causer|Result|explicit|\n",
        "311   |50|\n",
        "312   |50|\n",
        "313   |\n",
        "314   |50|\n",
        "315   |50|\n",
        "316   |50|\n",
        "317   |50|\n",
        "318   |\n",
        "319   |50|\n",
        "320   |\n",
        "321   |\n",
        "322   |\n",
        "323   |\n",
        "324   |\n",
        "325   |\n",
        "326   |\n",
        "327   |\n",
        "328   |\n",
        "329   |\n",
        "330   |50|\n",
        "331   |50|Result|\n",
        "332   |\n",
        "333   |\n",
        "334   |\n",
        "335   |\n",
        "336   |\n",
        "337   |50|\n",
        "338   |\n",
        "339   |\n",
        "340   |\n",
        "341   |\n",
        "342   |\n",
        "343   |50|\n",
        "344   |50|\n",
        "345   |\n",
        "346   |\n",
        "347   |50|\n",
        "348   |50|\n",
        "349   |\n",
        "350   |\n",
        "351   |1|3|50|Causer|Result|explicit|\n",
        "352   |3|50|\n",
        "353   |1|3|\n",
        "354   |\n",
        "355   |50|\n",
        "356   |50|\n",
        "357   |\n",
        "358   |1|Causer|Anaphor|\n",
        "359   |1|50|\n",
        "360   |1|50|Causer|Result|explicit|\n",
        "361   |1|50|Causer|Result|explicit|\n",
        "362   |3|50|\n",
        "363   |3|50|\n",
        "364   |3|50|Causer|Result|explicit|\n",
        "365   |\n",
        "366   |1|3|50|other|Causer|Result|explicit|\n",
        "367   |50|Causer|Result|explicit|rhetorical|\n",
        "368   |\n",
        "369   |50|\n",
        "370   |\n",
        "371   |other|\n",
        "372   |\n",
        "373   |other|rhetorical|\n",
        "374   |\n",
        "375   |\n",
        "376   |Result|\n",
        "377   |\n",
        "378   |\n",
        "379   |\n",
        "380   |\n",
        "381   |\n",
        "382   |50|\n",
        "383   |\n",
        "384   |50|\n",
        "385   |\n",
        "386   |\n",
        "387   |\n",
        "388   |\n",
        "389   |\n",
        "390   |\n",
        "391   |50|\n",
        "392   |\n",
        "393   |1|50|Causer|Result|explicit|\n",
        "394   |1|\n",
        "395   |\n",
        "396   |\n",
        "397   |5|\n",
        "398   |\n",
        "399   |\n",
        "400   |\n",
        "401   |\n",
        "402   |50|\n",
        "403   |50|\n",
        "404   |1|3|50|Causer|explicit|\n",
        "405   |1|3|\n",
        "406   |\n",
        "407   |\n",
        "408   |\n",
        "409   |50|\n",
        "410   |\n",
        "411   |\n",
        "412   |1|3|\n",
        "413   |\n",
        "414   |\n",
        "415   |50|\n",
        "416   |1|3|50|Causer|Result|explicit|\n",
        "417   |1|3|50|Causer|Result|explicit|\n",
        "418   |50|\n",
        "419   |\n",
        "420   |50|\n",
        "421   |\n",
        "422   |\n",
        "423   |\n",
        "424   |\n",
        "425   |\n",
        "426   |50|Result|\n",
        "427   |\n",
        "428   |\n",
        "429   |\n",
        "430   |\n",
        "431   |\n",
        "432   |\n",
        "433   |\n",
        "434   |\n",
        "435   |\n",
        "436   |\n",
        "437   |1|\n",
        "438   |\n",
        "439   |3|\n",
        "440   |\n",
        "441   |50|\n",
        "442   |\n",
        "443   |\n",
        "444   |50|\n",
        "445   |50|other|\n",
        "446   |50|\n",
        "447   |50|\n",
        "448   |50|\n",
        "449   |50|\n",
        "450   |\n",
        "451   |1|50|Causer|explicit|\n",
        "452   |\n",
        "453   |3|\n",
        "454   |\n",
        "455   |1|3|\n",
        "456   |\n",
        "457   |\n",
        "458   |50|\n",
        "459   |\n",
        "460   |1|Causer|explicit|rhetorical|\n",
        "461   |50|Anaphor|\n",
        "462   |50|\n",
        "463   |3|\n",
        "464   |7|other|Causer|Result|explicit|rhetorical|\n",
        "465   |50|Causer|Result|explicit|rhetorical|\n",
        "466   |50|\n",
        "467   |50|explicit|\n",
        "468   |11|12|13|Causer|Result|explicit|\n",
        "469   |explicit|\n",
        "470   |50|explicit|\n",
        "471   |\n",
        "472   |7|50|Causer|\n",
        "473   |50|\n",
        "474   |\n",
        "475   |\n",
        "476   |1|Causer|\n",
        "477   |3|4|other|Causer|Result|explicit|\n",
        "478   |\n",
        "479   |13|other|Causer|Result|explicit|\n",
        "480   |50|\n",
        "481   |50|\n",
        "482   |\n",
        "483   |\n",
        "484   |50|\n",
        "485   |50|\n",
        "486   |50|\n",
        "487   |\n",
        "488   |\n",
        "489   |\n",
        "490   |\n",
        "491   |\n",
        "492   |\n",
        "493   |\n",
        "494   |\n",
        "495   |50|\n",
        "496   |1|\n",
        "497   |1|\n",
        "498   |\n",
        "499   |2|3|Causer|Result|explicit|\n",
        "500   |3|\n",
        "501   |3|5|50|explicit|rhetorical|\n",
        "502   |3|4|Causer|Result|explicit|\n",
        "503   |4|5|Causer|Result|explicit|\n",
        "504   |50|\n",
        "505   |\n",
        "506   |7|50|Causer|Result|explicit|\n",
        "507   |6|7|50|Causer|explicit|\n",
        "508   |\n",
        "509   |50|other|Causer|explicit|\n",
        "510   |1|50|\n",
        "511   |1|rhetorical|\n",
        "512   |2|Causer|Result|explicit|rhetorical|\n",
        "513   |3|Causer|Result|explicit|rhetorical|\n",
        "514   |1|3|Causer|Result|explicit|\n",
        "515   |1|3|50|Causer|Result|explicit|\n",
        "516   |\n",
        "517   |3|\n",
        "518   |11|\n",
        "519   |50|\n",
        "520   |50|\n",
        "521   |\n",
        "522   |50|\n",
        "523   |50|\n",
        "524   |\n",
        "525   |\n",
        "526   |3|\n",
        "527   |5|5b|\n",
        "528   |\n",
        "529   |11|12|13|Causer|Result|explicit|\n",
        "530   |13|14|Result|\n",
        "531   |50|\n",
        "532   |\n",
        "533   |\n",
        "534   |\n",
        "535   |\n",
        "536   |\n",
        "537   |50|\n",
        "538   |50|Anaphor|\n",
        "539   |6|7|Causer|Result|explicit|\n",
        "540   |50|Causer|Result|Anaphor|explicit|\n",
        "541   |7|50|Causer|Result|\n",
        "542   |50|\n",
        "543   |\n",
        "544   |50|5b|Causer|Result|explicit|\n",
        "545   |7|50|Causer|Result|explicit|\n",
        "546   |3|50|Causer|Result|explicit|rhetorical|\n",
        "547   |1|3|5|Causer|Result|explicit|\n",
        "548   |50|Causer|explicit|\n",
        "549   |1|3|Causer|Result|explicit|\n",
        "550   |1|3|\n",
        "551   |50|\n",
        "552   |\n",
        "553   |50|\n",
        "554   |\n",
        "555   |50|\n",
        "556   |50|other|rhetorical|\n",
        "557   |\n",
        "558   |50|rhetorical|\n",
        "559   |1|50|Causer|Result|explicit|rhetorical|\n",
        "560   |3|rhetorical|\n",
        "561   |2|\n",
        "562   |1|50|Causer|Result|explicit|rhetorical|\n",
        "563   |1|3|Causer|Result|explicit|\n",
        "564   |3|5|Causer|Result|explicit|\n",
        "565   |1|Causer|\n",
        "566   |1|50|Causer|explicit|\n",
        "567   |\n",
        "568   |3|50|\n",
        "569   |3|4|14|50|Causer|Result|explicit|\n",
        "570   |11|12|13|14|Causer|Result|explicit|\n",
        "571   |5|7|\n",
        "572   |50|\n",
        "573   |50|other|Result|rhetorical|\n",
        "574   |3|4|14|50|Causer|Result|explicit|\n",
        "575   |11|13|Causer|Result|explicit|\n",
        "576   |13|other|\n",
        "577   |5|\n",
        "578   |\n",
        "579   |3|50|Causer|Result|explicit|\n",
        "580   |1|2|\n",
        "581   |\n",
        "582   |3|5|\n",
        "583   |Result|\n",
        "584   |3|50|other|\n",
        "585   |50|Result|\n",
        "586   |other|\n",
        "587   |1|3|50|other|Causer|Result|explicit|\n",
        "588   |\n",
        "589   |50|\n",
        "590   |other|\n",
        "591   |50|\n",
        "592   |50|\n",
        "593   |\n",
        "594   |50|other|\n",
        "595   |50|\n",
        "596   |\n",
        "597   |7|50|other|Causer|Result|explicit|\n",
        "598   |50|other|\n",
        "599   |50|\n",
        "600   |3|\n",
        "601   |3|4|Causer|Result|explicit|\n",
        "602   |4|5|other|Causer|Result|explicit|\n",
        "603   |50|other|Causer|Result|Anaphor|explicit|\n",
        "604   |\n",
        "605   |50|Result|\n",
        "606   |50|\n",
        "607   |\n",
        "608   |\n",
        "609   |6|7|50|other|Causer|Result|Anaphor|explicit|\n",
        "610   |\n",
        "611   |50|\n",
        "612   |7|\n",
        "613   |50|\n",
        "614   |50|\n",
        "615   |3|50|\n",
        "616   |\n",
        "617   |\n",
        "618   |\n",
        "619   |6|50|Causer|Result|explicit|\n",
        "620   |6|7|Causer|Result|explicit|\n",
        "621   |50|\n",
        "622   |50|other|\n",
        "623   |\n",
        "624   |50|\n",
        "625   |50|\n",
        "626   |50|\n",
        "627   |other|\n",
        "628   |\n",
        "629   |1|50|Causer|Result|explicit|\n",
        "630   |other|\n",
        "631   |50|\n",
        "632   |\n",
        "633   |\n",
        "634   |50|\n",
        "635   |\n",
        "636   |2|\n",
        "637   |\n",
        "638   |50|\n",
        "639   |50|\n",
        "640   |other|\n",
        "641   |\n",
        "642   |50|\n",
        "643   |50|other|\n",
        "644   |50|\n",
        "645   |\n",
        "646   |5|\n",
        "647   |other|\n",
        "648   |\n",
        "649   |50|other|\n",
        "650   |50|\n",
        "651   |3|\n",
        "652   |3|\n",
        "653   |\n",
        "654   |\n",
        "655   |5|\n",
        "656   |50|other|Causer|Result|explicit|\n",
        "657   |50|other|explicit|\n",
        "658   |\n",
        "659   |\n",
        "660   |\n",
        "661   |\n",
        "662   |\n",
        "663   |7|50|Causer|Result|explicit|\n",
        "664   |50|\n",
        "665   |\n",
        "666   |50|\n",
        "667   |7|\n",
        "668   |\n",
        "669   |\n",
        "670   |\n",
        "671   |\n",
        "672   |7|\n",
        "673   |\n",
        "674   |7|50|other|Causer|Result|explicit|\n",
        "675   |3|50|Causer|Result|explicit|\n",
        "676   |50|\n",
        "677   |\n",
        "678   |\n",
        "679   |\n",
        "680   |\n",
        "681   |50|\n",
        "682   |50|\n",
        "683   |\n",
        "684   |\n",
        "685   |\n",
        "686   |50|\n",
        "687   |50|\n",
        "688   |\n",
        "689   |\n",
        "690   |6|7|50|Causer|Result|Anaphor|explicit|\n",
        "691   |50|Causer|Result|Anaphor|explicit|\n",
        "692   |50|\n",
        "693   |\n",
        "694   |\n",
        "695   |\n",
        "696   |\n",
        "697   |3|\n",
        "698   |50|\n",
        "699   |6|5b|Causer|Result|explicit|\n",
        "700   |other|\n",
        "701   |50|\n",
        "702   |50|\n",
        "703   |\n",
        "704   |\n",
        "705   |50|\n",
        "706   |\n",
        "707   |50|\n",
        "708   |\n",
        "709   |\n",
        "710   |\n",
        "711   |other|\n",
        "712   |\n",
        "713   |\n",
        "714   |\n",
        "715   |\n",
        "716   |\n",
        "717   |50|\n",
        "718   |\n",
        "719   |50|\n",
        "720   |1|50|\n",
        "721   |50|\n",
        "722   |50|\n",
        "723   |other|\n",
        "724   |\n",
        "725   |other|\n",
        "726   |50|rhetorical|\n",
        "727   |50|rhetorical|\n",
        "728   |\n",
        "729   |\n",
        "730   |1|3|Causer|\n",
        "731   |50|Causer|Anaphor|explicit|rhetorical|\n",
        "732   |\n",
        "733   |5|\n",
        "734   |50|\n",
        "735   |\n",
        "736   |5|50|\n",
        "737   |50|\n",
        "738   |50|other|\n",
        "739   |3|\n",
        "740   |\n",
        "741   |7|\n",
        "742   |50|\n",
        "743   |\n",
        "744   |4|50|Causer|Result|explicit|\n",
        "745   |4|Causer|\n",
        "746   |\n",
        "747   |\n",
        "748   |4|\n",
        "749   |1|50|Causer|Result|explicit|rhetorical|\n",
        "750   |\n",
        "751   |1|3|50|other|Causer|Result|explicit|\n",
        "752   |\n",
        "753   |\n",
        "754   |\n",
        "755   |1|50|Causer|explicit|\n",
        "756   |1|\n",
        "757   |\n",
        "758   |\n",
        "759   |\n",
        "760   |7|Causer|Result|Anaphor|explicit|\n",
        "761   |\n",
        "762   |4|5|50|other|Causer|Result|explicit|\n",
        "763   |\n",
        "764   |\n",
        "765   |\n",
        "766   |1|Anaphor|\n",
        "767   |other|\n",
        "768   |50|\n",
        "769   |1|50|Causer|Result|explicit|\n",
        "770   |\n",
        "771   |1|50|Causer|Result|explicit|\n",
        "772   |2|3|Causer|Result|explicit|\n",
        "773   |\n",
        "774   |3|\n",
        "775   |\n",
        "776   |\n",
        "777   |\n",
        "778   |\n",
        "779   |\n",
        "780   |\n",
        "781   |\n",
        "782   |\n",
        "783   |50|\n",
        "784   |50|\n",
        "785   |1|\n",
        "786   |\n",
        "787   |\n",
        "788   |11|12|13|Causer|Result|explicit|\n",
        "789   |13|14|\n",
        "790   |\n",
        "791   |11|12|13|Causer|Result|explicit|\n",
        "792   |13|\n",
        "793   |50|\n",
        "794   |50|\n",
        "795   |7|50|Causer|Result|explicit|\n",
        "796   |50|\n",
        "797   |1|3|Causer|rhetorical|\n",
        "798   |\n",
        "799   |\n",
        "800   |\n",
        "801   |\n",
        "802   |Result|\n",
        "803   |1|\n",
        "804   |1|3|Causer|Result|explicit|\n",
        "805   |3|50|\n",
        "806   |3|\n",
        "807   |\n",
        "808   |1|3|50|Causer|rhetorical|\n",
        "809   |\n",
        "810   |3|50|\n",
        "811   |50|\n",
        "812   |50|\n",
        "813   |50|\n",
        "814   |\n",
        "815   |50|\n",
        "816   |6|50|Causer|Result|explicit|\n",
        "817   |\n",
        "818   |\n",
        "819   |1|50|Causer|\n",
        "820   |1|3|Causer|Result|explicit|\n",
        "821   |1|3|Causer|Result|explicit|\n",
        "822   |3|\n",
        "823   |3|5|Causer|Result|explicit|\n",
        "824   |3|4|5|Causer|Result|explicit|\n",
        "825   |\n",
        "826   |50|\n",
        "827   |\n",
        "828   |50|Result|\n",
        "829   |7|50|Causer|Result|explicit|\n",
        "830   |7|50|Causer|Result|explicit|\n",
        "831   |\n",
        "832   |\n",
        "833   |\n",
        "834   |6|7|50|Causer|Result|explicit|rhetorical|\n",
        "835   |50|\n",
        "836   |50|other|Causer|Result|Anaphor|explicit|\n",
        "837   |3|Anaphor|\n",
        "838   |3|50|\n",
        "839   |3|\n",
        "840   |2|\n",
        "841   |1|2|other|Result|rhetorical|\n",
        "842   |3|Causer|Result|explicit|rhetorical|\n",
        "843   |1|3|Causer|Result|explicit|\n",
        "844   |50|\n",
        "845   |3|50|\n",
        "846   |\n",
        "847   |\n",
        "848   |\n",
        "849   |3|Causer|\n",
        "850   |7|Result|explicit|\n",
        "851   |50|other|explicit|rhetorical|\n",
        "852   |\n",
        "853   |7|50|Result|\n",
        "854   |\n",
        "855   |\n",
        "856   |\n",
        "857   |\n",
        "858   |50|\n",
        "859   |50|\n",
        "860   |\n",
        "861   |7|50|Causer|Result|explicit|\n",
        "862   |\n",
        "863   |11|13|Causer|Result|explicit|\n",
        "864   |\n",
        "865   |50|\n",
        "866   |50|\n",
        "867   |50|\n",
        "868   |\n",
        "869   |\n",
        "870   |\n",
        "871   |\n",
        "872   |3|5|\n",
        "873   |1|\n",
        "874   |50|\n",
        "875   |\n",
        "876   |\n",
        "877   |5|\n",
        "878   |\n",
        "879   |\n",
        "880   |50|\n",
        "881   |50|\n",
        "882   |\n",
        "883   |\n",
        "884   |\n",
        "885   |\n",
        "886   |\n",
        "887   |50|other|\n",
        "888   |50|\n",
        "889   |50|\n",
        "890   |\n",
        "891   |1|\n",
        "892   |\n",
        "893   |\n",
        "894   |\n",
        "895   |2|3|Causer|Result|explicit|\n",
        "896   |\n",
        "897   |\n",
        "898   |\n",
        "899   |\n",
        "900   |\n",
        "901   |\n",
        "902   |\n",
        "903   |\n",
        "904   |\n",
        "905   |\n",
        "906   |\n",
        "907   |50|other|\n",
        "908   |50|rhetorical|\n",
        "909   |50|\n",
        "910   |50|\n",
        "911   |\n",
        "912   |3|\n",
        "913   |\n",
        "914   |6|7|Causer|Result|explicit|\n",
        "915   |50|Causer|Result|explicit|rhetorical|\n",
        "916   |50|\n",
        "917   |50|\n",
        "918   |\n",
        "919   |3|Result|\n",
        "920   |50|\n",
        "921   |\n",
        "922   |\n",
        "923   |\n",
        "924   |50|\n",
        "925   |\n",
        "926   |50|\n",
        "927   |5|\n",
        "928   |3|5|Causer|explicit|\n",
        "929   |\n",
        "930   |3|50|Causer|Result|explicit|\n",
        "931   |\n",
        "932   |50|\n",
        "933   |50|\n",
        "934   |\n",
        "935   |\n",
        "936   |50|\n",
        "937   |\n",
        "938   |\n",
        "939   |\n",
        "940   |\n",
        "941   |\n",
        "942   |50|\n",
        "943   |\n",
        "944   |\n",
        "945   |\n",
        "946   |\n",
        "947   |\n",
        "948   |50|\n",
        "949   |\n",
        "950   |3|4|50|Causer|Result|explicit|\n",
        "951   |4|5|Causer|Result|explicit|\n",
        "952   |\n",
        "953   |6|7|50|Causer|Result|explicit|\n",
        "954   |\n",
        "955   |50|\n",
        "956   |50|\n",
        "957   |\n",
        "958   |1|50|\n",
        "959   |50|\n",
        "960   |\n",
        "961   |5|\n",
        "962   |50|\n",
        "963   |\n",
        "964   |1|3|\n",
        "965   |\n",
        "966   |\n",
        "967   |1|\n",
        "968   |\n",
        "969   |50|\n",
        "970   |11|\n",
        "971   |\n",
        "972   |1|50|\n",
        "973   |\n",
        "974   |50|\n",
        "975   |1|\n",
        "976   |\n",
        "977   |3|13|50|Causer|Result|explicit|\n",
        "978   |3|13|\n",
        "979   |11|13|Causer|Result|explicit|\n",
        "980   |50|\n",
        "981   |\n",
        "982   |\n",
        "983   |\n",
        "984   |\n",
        "985   |7|50|Causer|Result|explicit|\n",
        "986   |7|50|Causer|explicit|\n",
        "987   |50|Result|\n",
        "988   |50|\n",
        "989   |50|\n",
        "990   |\n",
        "991   |\n",
        "992   |\n",
        "993   |\n",
        "994   |50|\n",
        "995   |6|7|50|Causer|Result|explicit|\n",
        "996   |50|Causer|Result|explicit|rhetorical|\n",
        "997   |50|\n",
        "998   |50|\n",
        "999   |\n",
        "1000  |50|\n",
        "1001  |\n",
        "1002  |1|\n",
        "1003  |50|\n",
        "1004  |3|50|rhetorical|\n",
        "1005  |50|\n",
        "1006  |3|50|Causer|Result|explicit|\n",
        "1007  |50|\n",
        "1008  |\n",
        "1009  |\n",
        "1010  |7|50|Causer|Result|explicit|rhetorical|\n",
        "1011  |explicit|\n",
        "1012  |\n",
        "1013  |50|\n",
        "1014  |\n",
        "1015  |50|\n",
        "1016  |\n",
        "1017  |\n",
        "1018  |\n",
        "1019  |50|\n",
        "1020  |50|\n",
        "1021  |7|50|Causer|explicit|\n",
        "1022  |1|50|Causer|Result|explicit|\n",
        "1023  |\n",
        "1024  |\n",
        "1025  |50|\n",
        "1026  |1|3|Causer|Result|explicit|\n",
        "1027  |\n",
        "1028  |50|\n",
        "1029  |1|3|50|other|Causer|Result|explicit|rhetorical|\n",
        "1030  |\n",
        "1031  |13|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1032  |11|12|Causer|Result|explicit|\n",
        "1033  |7|50|Causer|Result|explicit|\n",
        "1034  |\n",
        "1035  |3|11|\n",
        "1036  |\n",
        "1037  |7|50|other|Causer|Result|explicit|\n",
        "1038  |7|50|Causer|Result|Anaphor|explicit|\n",
        "1039  |7|rhetorical|\n",
        "1040  |3|5|Causer|Result|explicit|\n",
        "1041  |\n",
        "1042  |\n",
        "1043  |\n",
        "1044  |11|12|13|Causer|Result|explicit|\n",
        "1045  |7|13|Causer|Result|explicit|\n",
        "1046  |\n",
        "1047  |50|\n",
        "1048  |\n",
        "1049  |\n",
        "1050  |50|\n",
        "1051  |\n",
        "1052  |1|3|\n",
        "1053  |50|\n",
        "1054  |\n",
        "1055  |other|\n",
        "1056  |3|explicit|\n",
        "1057  |50|\n",
        "1058  |\n",
        "1059  |\n",
        "1060  |\n",
        "1061  |\n",
        "1062  |\n",
        "1063  |\n",
        "1064  |1|3|\n",
        "1065  |50|\n",
        "1066  |50|\n",
        "1067  |\n",
        "1068  |50|\n",
        "1069  |50|\n",
        "1070  |\n",
        "1071  |\n",
        "1072  |1|\n",
        "1073  |\n",
        "1074  |\n",
        "1075  |\n",
        "1076  |\n",
        "1077  |50|\n",
        "1078  |\n",
        "1079  |1|50|Causer|explicit|\n",
        "1080  |50|\n",
        "1081  |\n",
        "1082  |\n",
        "1083  |\n",
        "1084  |11|12|13|Causer|Result|explicit|\n",
        "1085  |13|14|\n",
        "1086  |50|\n",
        "1087  |\n",
        "1088  |\n",
        "1089  |6|7|other|Causer|Result|explicit|\n",
        "1090  |50|Causer|Result|explicit|rhetorical|\n",
        "1091  |50|\n",
        "1092  |7|other|\n",
        "1093  |1|50|Result|\n",
        "1094  |\n",
        "1095  |1|\n",
        "1096  |1|\n",
        "1097  |\n",
        "1098  |1|\n",
        "1099  |1|50|Causer|Result|explicit|\n",
        "1100  |50|\n",
        "1101  |\n",
        "1102  |\n",
        "1103  |50|\n",
        "1104  |\n",
        "1105  |\n",
        "1106  |\n",
        "1107  |\n",
        "1108  |\n",
        "1109  |1|3|other|Causer|Result|explicit|\n",
        "1110  |50|\n",
        "1111  |\n",
        "1112  |\n",
        "1113  |\n",
        "1114  |\n",
        "1115  |\n",
        "1116  |\n",
        "1117  |5|\n",
        "1118  |\n",
        "1119  |1|3|50|Causer|explicit|\n",
        "1120  |50|\n",
        "1121  |1|3|50|other|Causer|Result|explicit|\n",
        "1122  |1|3|50|Causer|explicit|\n",
        "1123  |1|3|Causer|\n",
        "1124  |50|Causer|Result|Anaphor|explicit|\n",
        "1125  |1|3|\n",
        "1126  |\n",
        "1127  |\n",
        "1128  |\n",
        "1129  |13|50|other|Causer|Result|explicit|\n",
        "1130  |1|3|50|Causer|Result|explicit|\n",
        "1131  |50|\n",
        "1132  |1|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1133  |1|3|\n",
        "1134  |1|3|\n",
        "1135  |1|Causer|\n",
        "1136  |2|Result|explicit|rhetorical|\n",
        "1137  |2|\n",
        "1138  |50|Result|Anaphor|explicit|\n",
        "1139  |1|\n",
        "1140  |\n",
        "1141  |\n",
        "1142  |3|4|5|Causer|Result|explicit|\n",
        "1143  |5|14|other|Causer|Result|explicit|\n",
        "1144  |1|3|50|Causer|Result|explicit|\n",
        "1145  |\n",
        "1146  |\n",
        "1147  |3|4|5|Causer|Result|explicit|\n",
        "1148  |5|\n",
        "1149  |50|Causer|Result|Anaphor|explicit|\n",
        "1150  |50|other|\n",
        "1151  |50|\n",
        "1152  |rhetorical|\n",
        "1153  |\n",
        "1154  |\n",
        "1155  |\n",
        "1156  |50|Result|rhetorical|\n",
        "1157  |5|\n",
        "1158  |1|Causer|Result|Anaphor|explicit|\n",
        "1159  |\n",
        "1160  |other|\n",
        "1161  |50|\n",
        "1162  |50|other|Anaphor|\n",
        "1163  |50|\n",
        "1164  |\n",
        "1165  |3|13|50|other|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1166  |50|5b|other|Causer|Result|Anaphor|explicit|\n",
        "1167  |50|Anaphor|rhetorical|\n",
        "1168  |rhetorical|\n",
        "1169  |11|50|other|Causer|Result|Anaphor|explicit|\n",
        "1170  |50|rhetorical|\n",
        "1171  |4|50|Causer|Result|explicit|\n",
        "1172  |50|rhetorical|\n",
        "1173  |50|\n",
        "1174  |50|\n",
        "1175  |\n",
        "1176  |\n",
        "1177  |50|Result|\n",
        "1178  |other|\n",
        "1179  |3|Anaphor|\n",
        "1180  |rhetorical|\n",
        "1181  |other|\n",
        "1182  |50|\n",
        "1183  |7|\n",
        "1184  |50|Causer|\n",
        "1185  |50|\n",
        "1186  |1|6|7|50|Causer|Result|explicit|\n",
        "1187  |50|\n",
        "1188  |1|7|50|other|Causer|Result|explicit|\n",
        "1189  |50|Causer|explicit|\n",
        "1190  |5|\n",
        "1191  |50|\n",
        "1192  |50|\n",
        "1193  |50|\n",
        "1194  |\n",
        "1195  |\n",
        "1196  |\n",
        "1197  |11|\n",
        "1198  |\n",
        "1199  |\n",
        "1200  |other|\n",
        "1201  |50|other|\n",
        "1202  |50|\n",
        "1203  |\n",
        "1204  |7|50|explicit|\n",
        "1205  |7|5b|\n",
        "1206  |7|\n",
        "1207  |11|12|Causer|Result|explicit|rhetorical|\n",
        "1208  |50|Causer|Result|Anaphor|explicit|\n",
        "1209  |\n",
        "1210  |5|other|\n",
        "1211  |\n",
        "1212  |50|\n",
        "1213  |\n",
        "1214  |50|\n",
        "1215  |50|Result|\n",
        "1216  |\n",
        "1217  |\n",
        "1218  |6|\n",
        "1219  |6|50|other|Causer|Result|explicit|\n",
        "1220  |50|\n",
        "1221  |\n",
        "1222  |1|3|50|Causer|Result|explicit|rhetorical|\n",
        "1223  |1|3|\n",
        "1224  |50|\n",
        "1225  |1|3|50|Causer|Result|explicit|rhetorical|\n",
        "1226  |7|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1227  |7|50|Causer|Result|explicit|\n",
        "1228  |7|\n",
        "1229  |1|50|Causer|Result|explicit|rhetorical|\n",
        "1230  |50|\n",
        "1231  |1|\n",
        "1232  |50|other|rhetorical|\n",
        "1233  |50|explicit|rhetorical|\n",
        "1234  |1|\n",
        "1235  |1|3|Causer|Result|explicit|\n",
        "1236  |1|3|Causer|Result|explicit|\n",
        "1237  |\n",
        "1238  |3|50|Causer|Result|explicit|\n",
        "1239  |7|50|Causer|explicit|\n",
        "1240  |50|Causer|Result|Anaphor|explicit|\n",
        "1241  |other|\n",
        "1242  |50|Result|Anaphor|explicit|rhetorical|\n",
        "1243  |7|Causer|Anaphor|\n",
        "1244  |\n",
        "1245  |7|50|Causer|Result|explicit|\n",
        "1246  |2|rhetorical|\n",
        "1247  |rhetorical|\n",
        "1248  |7|50|other|Causer|Result|explicit|rhetorical|\n",
        "1249  |other|Causer|Result|Anaphor|explicit|\n",
        "1250  |50|\n",
        "1251  |50|\n",
        "1252  |50|other|Anaphor|\n",
        "1253  |50|\n",
        "1254  |1|\n",
        "1255  |3|\n",
        "1256  |3|\n",
        "1257  |5|\n",
        "1258  |\n",
        "1259  |\n",
        "1260  |11|12|13|other|Causer|Result|Anaphor|explicit|\n",
        "1261  |50|Result|Anaphor|explicit|rhetorical|\n",
        "1262  |50|\n",
        "1263  |1|3|\n",
        "1264  |3|4|Causer|Result|explicit|\n",
        "1265  |5|\n",
        "1266  |rhetorical|\n",
        "1267  |other|\n",
        "1268  |5|Anaphor|\n",
        "1269  |5|50|\n",
        "1270  |50|\n",
        "1271  |7|50|Causer|Result|explicit|rhetorical|\n",
        "1272  |7|\n",
        "1273  |1|2|3|\n",
        "1274  |\n",
        "1275  |3|Causer|\n",
        "1276  |\n",
        "1277  |\n",
        "1278  |\n",
        "1279  |3|rhetorical|\n",
        "1280  |1|\n",
        "1281  |3|Anaphor|\n",
        "1282  |2|explicit|\n",
        "1283  |rhetorical|\n",
        "1284  |\n",
        "1285  |\n",
        "1286  |\n",
        "1287  |50|\n",
        "1288  |1|2|3|rhetorical|\n",
        "1289  |\n",
        "1290  |other|\n",
        "1291  |5|7|50|Causer|Result|Anaphor|explicit|\n",
        "1292  |7|50|Causer|Result|explicit|rhetorical|\n",
        "1293  |\n",
        "1294  |50|\n",
        "1295  |11|13|\n",
        "1296  |7|14|Causer|Result|Anaphor|explicit|\n",
        "1297  |50|other|Result|Anaphor|explicit|\n",
        "1298  |50|\n",
        "1299  |\n",
        "1300  |\n",
        "1301  |\n",
        "1302  |50|\n",
        "1303  |\n",
        "1304  |2|\n",
        "1305  |3|\n",
        "1306  |3|\n",
        "1307  |\n",
        "1308  |\n",
        "1309  |\n",
        "1310  |\n",
        "1311  |\n",
        "1312  |11|12|13|Causer|Result|explicit|rhetorical|\n",
        "1313  |50|\n",
        "1314  |50|Result|\n",
        "1315  |1|50|Causer|Result|Anaphor|explicit|\n",
        "1316  |\n",
        "1317  |\n",
        "1318  |3|\n",
        "1319  |3|50|Causer|Result|explicit|\n",
        "1320  |50|\n",
        "1321  |1|Causer|explicit|\n",
        "1322  |1|\n",
        "1323  |\n",
        "1324  |1|\n",
        "1325  |\n",
        "1326  |\n",
        "1327  |rhetorical|\n",
        "1328  |\n",
        "1329  |50|\n",
        "1330  |7|13|50|Causer|Result|explicit|\n",
        "1331  |7|50|Causer|Result|explicit|\n",
        "1332  |11|13|50|Causer|Result|explicit|\n",
        "1333  |1|3|50|Causer|Result|explicit|\n",
        "1334  |50|\n",
        "1335  |7|50|Causer|Result|explicit|\n",
        "1336  |5|50|other|rhetorical|\n",
        "1337  |1|3|7|50|Causer|explicit|\n",
        "1338  |rhetorical|\n",
        "1339  |1|50|Causer|Result|explicit|\n",
        "1340  |1|7|Causer|Result|explicit|\n",
        "1341  |3|50|Causer|Result|explicit|\n",
        "1342  |other|\n",
        "1343  |5|7|5b|Causer|Result|Anaphor|explicit|\n",
        "1344  |7|50|other|Causer|Result|Anaphor|explicit|\n",
        "1345  |50|\n",
        "1346  |4|\n",
        "1347  |7|5b|Causer|Result|explicit|\n",
        "1348  |3|5|7|Causer|Result|Anaphor|explicit|\n",
        "1349  |50|Causer|Result|Anaphor|explicit|\n",
        "1350  |7|50|Causer|explicit|\n",
        "1351  |50|rhetorical|\n",
        "1352  |50|\n",
        "1353  |1|50|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1354  |1|3|Causer|Result|explicit|\n",
        "1355  |3|50|5b|other|Causer|Result|explicit|\n",
        "1356  |50|other|Anaphor|\n",
        "1357  |50|Result|\n",
        "1358  |1|3|13|\n",
        "1359  |50|\n",
        "1360  |50|Result|\n",
        "1361  |1|Causer|explicit|\n",
        "1362  |50|\n",
        "1363  |50|\n",
        "1364  |50|\n",
        "1365  |3|Causer|Anaphor|\n",
        "1366  |3|4|Causer|Result|explicit|\n",
        "1367  |4|5|Causer|Result|explicit|\n",
        "1368  |5|Result|\n",
        "1369  |50|Causer|Result|Anaphor|explicit|\n",
        "1370  |50|other|\n",
        "1371  |\n",
        "1372  |50|\n",
        "1373  |3|Causer|Result|Anaphor|explicit|\n",
        "1374  |3|4|Causer|Result|explicit|\n",
        "1375  |\n",
        "1376  |\n",
        "1377  |5|\n",
        "1378  |\n",
        "1379  |\n",
        "1380  |4|other|Anaphor|\n",
        "1381  |11|12|other|Causer|Result|explicit|\n",
        "1382  |13|Causer|Result|Anaphor|explicit|\n",
        "1383  |6|50|Causer|Result|explicit|\n",
        "1384  |50|\n",
        "1385  |3|50|Causer|Result|explicit|\n",
        "1386  |rhetorical|\n",
        "1387  |50|rhetorical|\n",
        "1388  |\n",
        "1389  |\n",
        "1390  |50|rhetorical|\n",
        "1391  |\n",
        "1392  |3|Causer|\n",
        "1393  |50|\n",
        "1394  |11|other|\n",
        "1395  |3|50|Causer|Result|explicit|\n",
        "1396  |4|5|Causer|Result|Anaphor|explicit|\n",
        "1397  |3|\n",
        "1398  |50|Result|\n",
        "1399  |\n",
        "1400  |7|50|Result|explicit|rhetorical|\n",
        "1401  |7|Causer|\n",
        "1402  |3|13|14|\n",
        "1403  |50|\n",
        "1404  |1|50|Causer|Result|explicit|\n",
        "1405  |\n",
        "1406  |5|7|50|Causer|Result|explicit|\n",
        "1407  |3|7|Causer|Result|explicit|rhetorical|\n",
        "1408  |50|\n",
        "1409  |50|\n",
        "1410  |5|\n",
        "1411  |5|other|\n",
        "1412  |3|5|50|other|Causer|Anaphor|explicit|\n",
        "1413  |5|50|Causer|Result|explicit|\n",
        "1414  |\n",
        "1415  |7|50|Causer|Result|explicit|rhetorical|\n",
        "1416  |7|50|\n",
        "1417  |7|50|it|Causer|Result|explicit|\n",
        "1418  |13|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "1419  |13|50|other|Causer|Result|explicit|rhetorical|\n",
        "1420  |13|50|Causer|Result|explicit|\n",
        "1421  |\n",
        "1422  |11|\n",
        "1423  |50|\n",
        "1424  |\n",
        "1425  |\n",
        "1426  |11|13|Causer|Result|explicit|\n",
        "1427  |\n",
        "1428  |50|\n",
        "1429  |7|\n",
        "1430  |5|\n",
        "1431  |\n",
        "1432  |\n",
        "1433  |\n",
        "1434  |50|rhetorical|\n",
        "1435  |\n",
        "1436  |50|rhetorical|\n",
        "1437  |rhetorical|\n",
        "1438  |\n",
        "1439  |\n",
        "1440  |\n",
        "1441  |11|rhetorical|\n",
        "1442  |11|12|13|Causer|Result|explicit|\n",
        "1443  |\n",
        "1444  |\n",
        "1445  |rhetorical|\n",
        "1446  |\n",
        "1447  |7|\n",
        "1448  |7|11|50|other|Causer|Result|Anaphor|explicit|\n",
        "1449  |3|50|Causer|explicit|\n",
        "1450  |50|\n",
        "1451  |1|50|\n",
        "1452  |3|\n",
        "1453  |50|rhetorical|\n",
        "1454  |\n",
        "1455  |\n",
        "1456  |\n",
        "1457  |50|\n",
        "1458  |50|other|\n",
        "1459  |50|\n",
        "1460  |3|50|Causer|Result|explicit|\n",
        "1461  |50|\n",
        "1462  |50|\n",
        "1463  |\n",
        "1464  |\n",
        "1465  |2|3|Causer|Result|Anaphor|explicit|\n",
        "1466  |\n",
        "1467  |50|\n",
        "1468  |50|\n",
        "1469  |\n",
        "1470  |\n",
        "1471  |50|other|\n",
        "1472  |1|3|50|Causer|explicit|\n",
        "1473  |\n",
        "1474  |1|3|Causer|Result|explicit|\n",
        "1475  |\n",
        "1476  |5|\n",
        "1477  |3|7|Causer|Result|explicit|\n",
        "1478  |50|other|Causer|Result|Anaphor|explicit|\n",
        "1479  |3|13|50|Causer|Result|explicit|\n",
        "1480  |3|\n",
        "1481  |5|7|\n",
        "1482  |5|\n",
        "1483  |5b|\n",
        "1484  |13|14|Causer|Result|rhetorical|\n",
        "1485  |11|13|Causer|Result|explicit|\n",
        "1486  |50|Causer|Result|Anaphor|explicit|\n",
        "1487  |13|50|Causer|Result|explicit|\n",
        "1488  |7|50|Causer|explicit|\n",
        "1489  |50|rhetorical|\n",
        "1490  |\n",
        "1491  |11|\n",
        "1492  |4|13|Causer|\n",
        "1493  |5|other|\n",
        "1494  |3|Anaphor|\n",
        "1495  |3|5|Causer|Result|explicit|\n",
        "1496  |50|other|Anaphor|rhetorical|\n",
        "1497  |50|other|\n",
        "1498  |50|rhetorical|\n",
        "1499  |1|2|\n",
        "1500  |1|\n",
        "1501  |3|Causer|Result|Anaphor|explicit|\n",
        "1502  |3|\n",
        "1503  |2|\n",
        "1504  |\n",
        "1505  |5|7|\n",
        "1506  |3|\n",
        "1507  |3|4|5|14|Causer|Result|explicit|\n",
        "1508  |50|other|rhetorical|\n",
        "1509  |50|\n",
        "1510  |5|\n",
        "1511  |\n",
        "1512  |5|\n",
        "1513  |\n",
        "1514  |\n",
        "1515  |\n",
        "1516  |3|4|5|Causer|Result|explicit|\n",
        "1517  |11|13|Causer|Result|explicit|\n",
        "1518  |12|explicit|\n",
        "1519  |12|13|14|Causer|Result|explicit|\n",
        "1520  |\n",
        "1521  |\n",
        "1522  |7|\n",
        "1523  |7|50|Causer|Result|explicit|\n",
        "1524  |50|other|rhetorical|\n",
        "1525  |50|Causer|Result|Anaphor|explicit|\n",
        "1526  |1|50|\n",
        "1527  |1|3|5|Causer|Result|explicit|\n",
        "1528  |\n",
        "1529  |\n",
        "1530  |3|5|7|Causer|Result|explicit|\n",
        "1531  |7|50|other|Causer|Result|Anaphor|explicit|\n",
        "1532  |50|other|\n",
        "1533  |1|50|explicit|\n",
        "1534  |2|rhetorical|\n",
        "1535  |3|\n",
        "1536  |1|2|Causer|Result|explicit|\n",
        "1537  |3|Result|Anaphor|explicit|\n",
        "1538  |\n",
        "1539  |\n",
        "1540  |3|4|5|Causer|Result|Anaphor|explicit|\n",
        "1541  |3|7|50|other|Causer|Result|Anaphor|explicit|\n",
        "1542  |7|Causer|\n",
        "1543  |\n",
        "1544  |50|other|\n",
        "1545  |1|3|50|Causer|Anaphor|explicit|\n",
        "1546  |50|\n",
        "1547  |\n",
        "1548  |\n",
        "1549  |6|7|50|Causer|Result|explicit|\n",
        "1550  |3|\n",
        "1551  |3|50|Causer|Result|explicit|\n",
        "1552  |1|3|Causer|Result|explicit|rhetorical|\n",
        "1553  |\n",
        "1554  |50|\n",
        "1555  |50|Result|rhetorical|\n",
        "1556  |1|3|other|Causer|Anaphor|explicit|\n",
        "1557  |50|\n",
        "1558  |Causer|\n",
        "1559  |3|Causer|Result|rhetorical|\n",
        "1560  |50|\n",
        "1561  |50|\n",
        "1562  |5|50|Causer|Result|explicit|\n",
        "1563  |4|7|50|other|Causer|Result|Anaphor|explicit|\n",
        "1564  |\n",
        "1565  |3|\n",
        "1566  |3|\n",
        "1567  |3|\n",
        "1568  |50|other|Result|\n",
        "1569  |6|13|50|Causer|Result|Anaphor|explicit|\n",
        "1570  |50|\n",
        "1571  |50|other|Anaphor|\n",
        "1572  |3|50|Causer|Result|Anaphor|explicit|\n",
        "1573  |2|\n",
        "1574  |\n",
        "1575  |3|\n",
        "1576  |3|5|Causer|Result|explicit|\n",
        "1577  |\n",
        "1578  |13|Causer|\n",
        "1579  |5|\n",
        "1580  |11|13|Causer|Result|explicit|\n",
        "1581  |11|12|13|Causer|Result|explicit|\n",
        "1582  |5|7|50|Causer|Result|explicit|\n",
        "1583  |\n",
        "1584  |50|\n",
        "1585  |3|11|50|Causer|Result|explicit|\n",
        "1586  |50|\n",
        "1587  |50|other|\n",
        "1588  |1|3|50|Causer|Result|explicit|\n",
        "1589  |2|\n",
        "1590  |1|\n",
        "1591  |1|\n",
        "1592  |1|3|Causer|Result|explicit|\n",
        "1593  |3|\n",
        "1594  |3|4|Causer|Result|explicit|\n",
        "1595  |14|Result|\n",
        "1596  |11|13|14|Causer|Result|explicit|\n",
        "1597  |5|\n",
        "1598  |6|7|50|Causer|explicit|\n",
        "1599  |\n",
        "1600  |50|\n",
        "1601  |7|Causer|Anaphor|explicit|\n",
        "1602  |6|7|Causer|Result|explicit|\n",
        "1603  |7|50|Causer|Result|explicit|\n",
        "1604  |50|\n",
        "1605  |1|3|50|Causer|Result|explicit|\n",
        "1606  |1|50|Causer|Result|explicit|\n",
        "1607  |2|50|Anaphor|\n",
        "1608  |50|\n",
        "1609  |5|50|other|Causer|Result|Anaphor|explicit|\n",
        "1610  |\n",
        "1611  |50|\n",
        "1612  |50|other|\n",
        "1613  |7|50|Causer|Result|explicit|\n",
        "1614  |50|rhetorical|\n",
        "1615  |3|50|Causer|Result|explicit|\n",
        "1616  |\n",
        "1617  |50|\n",
        "1618  |\n",
        "1619  |\n",
        "1620  |50|other|rhetorical|\n",
        "1621  |50|\n",
        "1622  |3|7|Causer|Result|explicit|\n",
        "1623  |7|50|Causer|Result|explicit|\n",
        "1624  |\n",
        "1625  |50|other|\n",
        "1626  |7|50|Causer|explicit|\n",
        "1627  |6|7|Causer|Result|explicit|\n",
        "1628  |\n",
        "1629  |50|\n",
        "1630  |3|\n",
        "1631  |1|2|Causer|Result|explicit|\n",
        "1632  |2|3|Causer|Result|explicit|\n",
        "1633  |\n",
        "1634  |\n",
        "1635  |1|3|Causer|Result|explicit|\n",
        "1636  |50|rhetorical|\n",
        "1637  |2|3|other|Causer|Result|explicit|\n",
        "1638  |50|\n",
        "1639  |50|\n",
        "1640  |7|50|Causer|Result|explicit|\n",
        "1641  |5|\n",
        "1642  |50|Result|explicit|rhetorical|\n",
        "1643  |rhetorical|\n",
        "1644  |1|3|Causer|\n",
        "1645  |3|5|Causer|Result|explicit|\n",
        "1646  |11|13|50|Causer|Result|explicit|\n",
        "1647  |other|\n",
        "1648  |50|\n",
        "1649  |rhetorical|\n",
        "1650  |\n",
        "1651  |5|rhetorical|\n",
        "1652  |5|7|\n",
        "1653  |\n",
        "1654  |5|50|rhetorical|\n",
        "1655  |50|other|Anaphor|\n",
        "1656  |50|rhetorical|\n",
        "1657  |\n",
        "1658  |\n",
        "1659  |5|\n",
        "1660  |\n",
        "1661  |5|\n",
        "1662  |\n",
        "1663  |\n",
        "1664  |\n",
        "1665  |\n",
        "1666  |50|\n",
        "1667  |other|\n",
        "1668  |7|50|Causer|Result|explicit|\n",
        "1669  |\n",
        "1670  |\n",
        "1671  |\n",
        "1672  |\n",
        "1673  |3|4|Causer|Result|explicit|\n",
        "1674  |5|Causer|Result|Anaphor|explicit|\n",
        "1675  |14|Causer|Result|Anaphor|explicit|\n",
        "1676  |3|50|Causer|Result|explicit|\n",
        "1677  |3|50|other|\n",
        "1678  |50|\n",
        "1679  |\n",
        "1680  |1|3|50|Causer|Result|explicit|\n",
        "1681  |\n",
        "1682  |1|50|Causer|Result|Anaphor|explicit|\n",
        "1683  |2|rhetorical|\n",
        "1684  |1|\n",
        "1685  |1|3|Causer|Result|explicit|\n",
        "1686  |\n",
        "1687  |1|Causer|\n",
        "1688  |50|\n",
        "1689  |50|rhetorical|\n",
        "1690  |5|\n",
        "1691  |4|Anaphor|\n",
        "1692  |3|4|Causer|Result|explicit|\n",
        "1693  |5|50|other|Causer|Result|Anaphor|explicit|\n",
        "1694  |1|3|50|Causer|Result|explicit|\n",
        "1695  |1|3|50|\n",
        "1696  |5|5b|Causer|Result|explicit|\n",
        "1697  |50|Result|\n",
        "1698  |3|Causer|explicit|\n",
        "1699  |3|4|5|Causer|Result|explicit|\n",
        "1700  |50|Result|explicit|\n",
        "1701  |50|\n",
        "1702  |1|3|50|Causer|Result|explicit|\n",
        "1703  |3|50|Causer|Result|explicit|\n",
        "1704  |\n",
        "1705  |5|\n",
        "1706  |3|4|Causer|Result|explicit|\n",
        "1707  |4|5|14|Causer|Result|explicit|\n",
        "1708  |1|3|50|Causer|explicit|\n",
        "1709  |2|\n",
        "1710  |1|\n",
        "1711  |1|2|\n",
        "1712  |2|3|50|Causer|Result|Anaphor|explicit|\n",
        "1713  |\n",
        "1714  |2|3|Causer|Result|explicit|\n",
        "1715  |\n",
        "1716  |1|3|50|Causer|Result|explicit|\n",
        "1717  |50|\n",
        "1718  |\n",
        "1719  |50|\n",
        "1720  |\n",
        "1721  |\n",
        "1722  |50|\n",
        "1723  |\n",
        "1724  |1|3|Causer|explicit|\n",
        "1725  |\n",
        "1726  |\n",
        "1727  |50|\n",
        "1728  |\n",
        "1729  |\n",
        "1730  |\n",
        "1731  |50|\n",
        "1732  |50|\n",
        "1733  |\n",
        "1734  |3|50|Causer|explicit|\n",
        "1735  |13|50|\n",
        "1736  |1|50|Causer|\n",
        "1737  |1|3|50|Causer|Result|explicit|\n",
        "1738  |50|\n",
        "1739  |50|\n",
        "1740  |\n",
        "1741  |\n",
        "1742  |5|\n",
        "1743  |1|\n",
        "1744  |\n",
        "1745  |2|3|Causer|Result|explicit|\n",
        "1746  |\n",
        "1747  |\n",
        "1748  |\n",
        "1749  |50|\n",
        "1750  |50|\n",
        "1751  |50|other|\n",
        "1752  |1|3|50|other|Causer|Result|Anaphor|explicit|\n",
        "1753  |3|50|\n",
        "1754  |1|3|50|Causer|Result|\n",
        "1755  |\n",
        "1756  |\n",
        "1757  |other|\n",
        "1758  |\n",
        "1759  |3|\n",
        "1760  |\n",
        "1761  |3|5|\n",
        "1762  |3|4|5|Causer|Result|explicit|\n",
        "1763  |14|Result|\n",
        "1764  |11|12|13|other|Causer|Result|explicit|\n",
        "1765  |50|\n",
        "1766  |7|50|Causer|Result|explicit|\n",
        "1767  |3|6|Causer|Result|explicit|\n",
        "1768  |3|7|other|Causer|Result|explicit|\n",
        "1769  |50|\n",
        "1770  |\n",
        "1771  |other|\n",
        "1772  |50|\n",
        "1773  |rhetorical|\n",
        "1774  |1|3|50|Causer|Result|explicit|\n",
        "1775  |50|\n",
        "1776  |50|\n",
        "1777  |50|\n",
        "1778  |3|\n",
        "1779  |3|5|Causer|Result|Anaphor|explicit|\n",
        "1780  |3|4|Causer|Result|explicit|\n",
        "1781  |4|50|Causer|Result|explicit|\n",
        "1782  |14|50|Causer|Result|explicit|\n",
        "1783  |50|\n",
        "1784  |\n",
        "1785  |1|50|Causer|explicit|\n",
        "1786  |50|\n",
        "1787  |1|3|\n",
        "1788  |\n",
        "1789  |50|\n",
        "1790  |1|50|Causer|Result|explicit|\n",
        "1791  |1|50|\n",
        "1792  |1|11|13|Causer|Result|explicit|\n",
        "1793  |14|other|rhetorical|\n",
        "1794  |50|\n",
        "1795  |rhetorical|\n",
        "1796  |1|3|50|Causer|Result|explicit|\n",
        "1797  |50|\n",
        "1798  |50|other|\n",
        "1799  |\n",
        "1800  |\n",
        "1801  |3|\n",
        "1802  |5|Causer|Result|explicit|\n",
        "1803  |14|Result|\n",
        "1804  |\n",
        "1805  |3|50|other|Causer|Result|explicit|rhetorical|\n",
        "1806  |7|50|Causer|explicit|\n",
        "1807  |\n",
        "1808  |\n",
        "1809  |50|\n",
        "1810  |\n",
        "1811  |\n",
        "1812  |\n",
        "1813  |7|50|Causer|Result|explicit|\n",
        "1814  |3|4|Causer|Result|explicit|rhetorical|\n",
        "1815  |4|5|50|Causer|Result|explicit|\n",
        "1816  |3|50|Causer|Result|explicit|\n",
        "1817  |2|3|\n",
        "1818  |1|2|other|Causer|Result|explicit|\n",
        "1819  |50|\n",
        "1820  |1|3|50|Causer|Result|explicit|\n",
        "1821  |\n",
        "1822  |1|3|50|Causer|Result|explicit|\n",
        "1823  |1|3|50|Causer|Result|explicit|\n",
        "1824  |2|\n",
        "1825  |2|3|50|other|Causer|Result|Anaphor|explicit|\n",
        "1826  |50|\n",
        "1827  |11|13|50|Causer|Result|explicit|\n",
        "1828  |4|5|50|Causer|Result|explicit|rhetorical|\n",
        "1829  |3|50|Causer|Result|explicit|rhetorical|\n",
        "1830  |3|50|\n",
        "1831  |\n",
        "1832  |50|\n",
        "1833  |50|other|\n",
        "1834  |7|50|other|Causer|Result|Anaphor|explicit|\n",
        "1835  |5|50|\n",
        "1836  |50|\n",
        "1837  |\n",
        "1838  |\n",
        "1839  |3|11|12|50|Causer|explicit|\n",
        "1840  |\n",
        "1841  |3|\n",
        "1842  |11|12|Causer|Result|explicit|\n",
        "1843  |other|\n",
        "1844  |50|\n",
        "1845  |50|\n",
        "1846  |50|\n",
        "1847  |\n",
        "1848  |\n",
        "1849  |3|\n",
        "1850  |\n",
        "1851  |1|50|Causer|Result|explicit|\n",
        "1852  |1|2|Causer|Result|explicit|\n",
        "1853  |3|other|Result|explicit|\n",
        "1854  |1|50|explicit|\n",
        "1855  |\n",
        "1856  |3|\n",
        "1857  |50|\n",
        "1858  |\n",
        "1859  |50|\n",
        "1860  |50|\n",
        "1861  |50|\n",
        "1862  |\n",
        "1863  |5|\n",
        "1864  |\n",
        "1865  |\n",
        "1866  |50|\n",
        "1867  |7|\n",
        "1868  |50|other|rhetorical|\n",
        "1869  |\n",
        "1870  |4|50|other|Causer|Result|explicit|\n",
        "1871  |50|\n",
        "1872  |\n",
        "1873  |1|\n",
        "1874  |1|3|Causer|Result|explicit|\n",
        "1875  |\n",
        "1876  |\n",
        "1877  |\n",
        "1878  |50|\n",
        "1879  |\n",
        "1880  |\n",
        "1881  |\n",
        "1882  |\n",
        "1883  |50|other|\n",
        "1884  |50|rhetorical|\n",
        "1885  |Causer|\n",
        "1886  |\n",
        "1887  |\n",
        "1888  |3|rhetorical|\n",
        "1889  |3|\n",
        "1890  |1|3|Causer|Result|explicit|\n",
        "1891  |1|50|Causer|Result|rhetorical|\n",
        "1892  |2|\n",
        "1893  |2|\n",
        "1894  |50|rhetorical|\n",
        "1895  |\n",
        "1896  |50|\n",
        "1897  |50|other|\n",
        "1898  |50|\n",
        "1899  |50|\n",
        "1900  |50|\n",
        "1901  |1|3|\n",
        "1902  |1|2|Causer|Result|explicit|\n",
        "1903  |2|3|Causer|Result|explicit|\n",
        "1904  |3|\n",
        "1905  |\n",
        "1906  |\n",
        "1907  |\n",
        "1908  |50|\n",
        "1909  |1|2|\n",
        "1910  |1|\n",
        "1911  |7|50|other|Causer|Result|explicit|rhetorical|\n",
        "1912  |50|\n",
        "1913  |5|\n",
        "1914  |\n",
        "1915  |\n",
        "1916  |50|\n",
        "1917  |5|Result|\n",
        "1918  |\n",
        "1919  |50|\n",
        "1920  |50|\n",
        "1921  |50|\n",
        "1922  |\n",
        "1923  |50|other|\n",
        "1924  |rhetorical|\n",
        "1925  |\n",
        "1926  |\n",
        "1927  |3|4|5|14|Causer|Result|explicit|\n",
        "1928  |rhetorical|\n",
        "1929  |\n",
        "1930  |\n",
        "1931  |\n",
        "1932  |\n",
        "1933  |7|50|Causer|Result|explicit|\n",
        "1934  |6|7|50|Causer|Result|explicit|\n",
        "1935  |\n",
        "1936  |5|\n",
        "1937  |50|\n",
        "1938  |7|50|rhetorical|\n",
        "1939  |other|rhetorical|\n",
        "1940  |1|50|Causer|explicit|\n",
        "1941  |3|5|rhetorical|\n",
        "1942  |1|2|3|Causer|Result|explicit|\n",
        "1943  |5|\n",
        "1944  |\n",
        "1945  |\n",
        "1946  |7|Result|\n",
        "1947  |50|Causer|Result|Anaphor|explicit|\n",
        "1948  |1|7|50|other|Causer|Result|explicit|rhetorical|\n",
        "1949  |50|\n",
        "1950  |3|5|50|Causer|rhetorical|\n",
        "1951  |7|50|Causer|\n",
        "1952  |6|50|Causer|Result|explicit|\n",
        "1953  |\n",
        "1954  |50|other|\n",
        "1955  |50|\n",
        "1956  |\n",
        "1957  |3|50|\n",
        "1958  |50|\n",
        "1959  |other|\n",
        "1960  |1|rhetorical|\n",
        "1961  |\n",
        "1962  |1|\n",
        "1963  |1|Causer|\n",
        "1964  |14|Result|\n",
        "1965  |3|\n",
        "1966  |1|3|Causer|\n",
        "1967  |5|50|Causer|Result|Anaphor|explicit|\n",
        "1968  |50|\n",
        "1969  |1|50|other|Causer|Result|explicit|\n",
        "1970  |50|\n",
        "1971  |7|50|Causer|Result|explicit|\n",
        "1972  |other|\n",
        "1973  |50|\n",
        "1974  |3|50|Causer|Result|explicit|rhetorical|\n",
        "1975  |\n",
        "1976  |11|13|Causer|Result|explicit|\n",
        "1977  |14|Causer|Result|Anaphor|explicit|\n",
        "1978  |1|50|Causer|explicit|\n",
        "1979  |1|3|Causer|Result|explicit|\n",
        "1980  |\n",
        "1981  |1|3|Causer|Result|explicit|\n",
        "1982  |\n",
        "1983  |50|other|rhetorical|\n",
        "1984  |50|\n",
        "1985  |3|50|Causer|Result|explicit|\n",
        "1986  |3|50|Causer|Result|explicit|\n",
        "1987  |\n",
        "1988  |13|other|\n",
        "1989  |50|rhetorical|\n",
        "1990  |2|\n",
        "1991  |1|5|Causer|Result|explicit|\n",
        "1992  |rhetorical|\n",
        "1993  |5|\n",
        "1994  |\n",
        "1995  |50|\n",
        "1996  |rhetorical|\n",
        "1997  |\n",
        "1998  |\n",
        "1999  |\n",
        "2000  |50|rhetorical|\n",
        "2001  |50|other|\n",
        "2002  |50|\n",
        "2003  |1|3|50|Causer|Result|explicit|\n",
        "2004  |3|4|Causer|Result|explicit|\n",
        "2005  |14|Causer|Result|Anaphor|explicit|\n",
        "2006  |\n",
        "2007  |11|12|Causer|Result|explicit|\n",
        "2008  |1|3|Causer|Result|explicit|\n",
        "2009  |50|other|rhetorical|\n",
        "2010  |50|\n",
        "2011  |50|\n",
        "2012  |50|\n",
        "2013  |\n",
        "2014  |3|\n",
        "2015  |2|\n",
        "2016  |\n",
        "2017  |1|\n",
        "2018  |50|Anaphor|\n",
        "2019  |50|rhetorical|\n",
        "2020  |5|\n",
        "2021  |\n",
        "2022  |5|explicit|\n",
        "2023  |50|other|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "2024  |5|50|\n",
        "2025  |50|\n",
        "2026  |\n",
        "2027  |50|\n",
        "2028  |\n",
        "2029  |\n",
        "2030  |2|\n",
        "2031  |2|\n",
        "2032  |3|\n",
        "2033  |50|\n",
        "2034  |3|50|Causer|Result|explicit|rhetorical|\n",
        "2035  |50|Result|\n",
        "2036  |7|50|Causer|explicit|\n",
        "2037  |5|Causer|\n",
        "2038  |\n",
        "2039  |11|13|Causer|Result|\n",
        "2040  |12|13|14|Causer|Result|explicit|\n",
        "2041  |1|3|50|Causer|Result|explicit|\n",
        "2042  |1|\n",
        "2043  |Causer|\n",
        "2044  |\n",
        "2045  |1|50|\n",
        "2046  |50|Result|\n",
        "2047  |\n",
        "2048  |1|50|Causer|Result|explicit|\n",
        "2049  |3|50|Causer|Result|explicit|\n",
        "2050  |3|5|Result|\n",
        "2051  |7|5b|\n",
        "2052  |50|explicit|\n",
        "2053  |1|3|Causer|explicit|\n",
        "2054  |5|other|Causer|\n",
        "2055  |5|\n",
        "2056  |\n",
        "2057  |11|12|13|Causer|Result|explicit|\n",
        "2058  |5|5b|\n",
        "2059  |other|\n",
        "2060  |3|50|Causer|\n",
        "2061  |3|\n",
        "2062  |7|\n",
        "2063  |7|50|Causer|explicit|\n",
        "2064  |7|\n",
        "2065  |\n",
        "2066  |explicit|\n",
        "2067  |1|3|Causer|rhetorical|\n",
        "2068  |\n",
        "2069  |50|\n",
        "2070  |1|3|Causer|rhetorical|\n",
        "2071  |1|3|50|explicit|\n",
        "2072  |1|Causer|\n",
        "2073  |1|2|Causer|Result|\n",
        "2074  |2|Causer|Result|Anaphor|explicit|\n",
        "2075  |50|explicit|\n",
        "2076  |50|\n",
        "2077  |7|50|Causer|Result|explicit|\n",
        "2078  |50|\n",
        "2079  |\n",
        "2080  |\n",
        "2081  |1|50|Causer|Result|rhetorical|\n",
        "2082  |7|50|Causer|explicit|\n",
        "2083  |50|\n",
        "2084  |7|50|Causer|Result|\n",
        "2085  |3|50|explicit|\n",
        "2086  |\n",
        "2087  |5|\n",
        "2088  |\n",
        "2089  |\n",
        "2090  |1|50|Causer|\n",
        "2091  |1|3|Causer|Result|explicit|\n",
        "2092  |7|13|50|Causer|\n",
        "2093  |7|50|other|Causer|Result|\n",
        "2094  |3|4|5|Causer|Result|explicit|\n",
        "2095  |14|Result|\n",
        "2096  |50|\n",
        "2097  |50|\n",
        "2098  |1|Causer|explicit|\n",
        "2099  |3|50|5b|Causer|explicit|\n",
        "2100  |\n",
        "2101  |5b|\n",
        "2102  |50|\n",
        "2103  |50|\n",
        "2104  |2|\n",
        "2105  |1|\n",
        "2106  |1|2|Result|\n",
        "2107  |3|\n",
        "2108  |\n",
        "2109  |\n",
        "2110  |Causer|\n",
        "2111  |\n",
        "2112  |3|\n",
        "2113  |3|4|5|Causer|Result|explicit|\n",
        "2114  |\n",
        "2115  |5|explicit|\n",
        "2116  |Causer|\n",
        "2117  |7|50|Causer|Result|explicit|\n",
        "2118  |50|Result|\n",
        "2119  |50|\n",
        "2120  |50|\n",
        "2121  |1|3|50|Causer|explicit|\n",
        "2122  |50|Causer|rhetorical|\n",
        "2123  |3|Causer|\n",
        "2124  |explicit|rhetorical|\n",
        "2125  |3|Causer|explicit|\n",
        "2126  |\n",
        "2127  |\n",
        "2128  |50|\n",
        "2129  |50|Causer|Result|explicit|\n",
        "2130  |1|3|50|Causer|\n",
        "2131  |50|\n",
        "2132  |3|\n",
        "2133  |50|\n",
        "2134  |1|3|11|12|13|14|50|Causer|Result|explicit|\n",
        "2135  |50|\n",
        "2136  |3|Causer|\n",
        "2137  |1|3|50|other|Causer|Result|rhetorical|\n",
        "2138  |\n",
        "2139  |3|4|50|other|Causer|Result|explicit|\n",
        "2140  |1|50|other|Result|explicit|\n",
        "2141  |50|rhetorical|\n",
        "2142  |1|other|Causer|rhetorical|\n",
        "2143  |50|other|Causer|Anaphor|rhetorical|\n",
        "2144  |1|2|50|Causer|Result|\n",
        "2145  |50|Causer|Result|explicit|\n",
        "2146  |1|Causer|explicit|\n",
        "2147  |50|rhetorical|\n",
        "2148  |1|2|50|Causer|explicit|\n",
        "2149  |1|3|Causer|explicit|\n",
        "2150  |1|50|Causer|Result|explicit|\n",
        "2151  |3|50|Causer|Result|explicit|\n",
        "2152  |5|7|50|other|Causer|Result|explicit|\n",
        "2153  |50|Result|\n",
        "2154  |7|50|Causer|Result|Anaphor|\n",
        "2155  |3|\n",
        "2156  |1|3|Result|explicit|\n",
        "2157  |3|7|50|Causer|explicit|\n",
        "2158  |50|Result|explicit|\n",
        "2159  |13|50|\n",
        "2160  |50|5b|Causer|Result|Anaphor|explicit|rhetorical|\n",
        "2161  |7|\n",
        "2162  |3|Causer|Anaphor|\n",
        "2163  |1|2|3|7|explicit|\n",
        "2164  |7|Causer|explicit|rhetorical|\n",
        "2165  |7|50|Result|explicit|\n",
        "2166  |1|3|50|Causer|Anaphor|\n",
        "2167  |50|\n",
        "2168  |50|Result|explicit|\n",
        "2169  |50|Result|rhetorical|\n",
        "2170  |11|12|13|Causer|Result|explicit|\n",
        "2171  |Result|\n",
        "2172  |5|7|50|Causer|explicit|\n",
        "2173  |\n",
        "2174  |50|Result|\n",
        "2175  |6|7|50|other|Causer|Result|explicit|\n",
        "2176  |50|\n",
        "2177  |Result|explicit|\n",
        "2178  |\n",
        "2179  |\n",
        "2180  |5|7|50|Causer|\n",
        "2181  |7|50|other|Causer|Result|\n",
        "2182  |50|\n",
        "2183  |6|Causer|\n",
        "2184  |7|50|Causer|Result|explicit|\n",
        "2185  |7|50|Result|\n",
        "2186  |50|Result|\n",
        "2187  |\n",
        "2188  |\n",
        "2189  |\n",
        "2190  |\n",
        "2191  |50|Causer|\n",
        "2192  |50|\n",
        "2193  |1|3|50|other|Causer|Result|explicit|\n",
        "2194  |\n",
        "2195  |3|Causer|Result|explicit|\n",
        "2196  |50|Result|rhetorical|\n",
        "2197  |50|Result|explicit|\n",
        "2198  |1|50|Causer|explicit|\n",
        "2199  |2|3|50|Causer|Result|explicit|\n",
        "2200  |2|Causer|\n",
        "2201  |\n",
        "2202  |other|Causer|\n",
        "2203  |7|50|Result|\n",
        "2204  |1|\n",
        "2205  |2|3|other|Result|\n",
        "2206  |50|\n",
        "2207  |3|5|Result|explicit|\n",
        "2208  |50|Result|rhetorical|\n",
        "2209  |50|Causer|Result|\n",
        "2210  |5|7|50|Causer|Result|explicit|\n",
        "2211  |5|Causer|explicit|\n",
        "2212  |3|50|Causer|Result|explicit|rhetorical|\n",
        "2213  |5|Causer|explicit|\n",
        "2214  |other|explicit|\n",
        "2215  |3|4|7|Causer|Result|\n",
        "2216  |5|Result|\n",
        "2217  |\n",
        "2218  |50|Causer|Result|explicit|\n",
        "2219  |3|5|7|50|other|Causer|Result|explicit|\n",
        "2220  |5|7|50|Result|\n",
        "2221  |3|5|other|\n",
        "2222  |3|5|50|explicit|\n",
        "2223  |3|4|Causer|Result|Anaphor|explicit|\n",
        "2224  |3|4|Causer|Result|explicit|\n",
        "2225  |5|Causer|Result|\n",
        "2226  |4|50|Result|\n",
        "2227  |50|\n",
        "2228  |1|3|50|Causer|\n",
        "2229  |50|\n",
        "2230  |1|3|other|Causer|\n",
        "2231  |50|\n",
        "2232  |50|\n",
        "2233  |50|\n",
        "2234  |\n",
        "2235  |\n",
        "2236  |3|\n",
        "2237  |3|Causer|\n",
        "2238  |50|Result|explicit|\n",
        "2239  |5|6|7|50|Causer|Result|\n",
        "2240  |Anaphor|\n",
        "2241  |Causer|Anaphor|explicit|\n",
        "2242  |1|3|50|Causer|Result|explicit|rhetorical|\n",
        "2243  |1|3|50|Causer|Result|\n",
        "2244  |3|Result|\n",
        "2245  |4|Causer|Result|\n",
        "2246  |\n",
        "2247  |50|\n",
        "2248  |50|\n",
        "2249  |rhetorical|\n",
        "2250  |50|rhetorical|\n",
        "2251  |50|Result|rhetorical|\n",
        "2252  |50|Result|\n",
        "2253  |50|rhetorical|\n",
        "2254  |1|rhetorical|\n",
        "2255  |50|\n",
        "2256  |3|\n",
        "2257  |5|50|Causer|Result|\n",
        "2258  |50|Result|\n",
        "2259  |\n",
        "2260  |50|Causer|\n",
        "2261  |7|5b|Causer|\n",
        "2262  |Result|\n",
        "2263  |7|50|Causer|Result|explicit|\n",
        "2264  |50|Result|explicit|\n",
        "2265  |5|50|Result|\n",
        "2266  |1|3|13|50|Causer|Result|explicit|\n",
        "2267  |50|other|rhetorical|\n",
        "2268  |13|\n",
        "2269  |\n",
        "2270  |3|11|13|Causer|\n",
        "2271  |11|12|13|Causer|Result|explicit|\n",
        "2272  |13|50|Result|explicit|\n",
        "2273  |1|3|50|Causer|Result|rhetorical|\n",
        "2274  |1|50|Causer|Result|explicit|\n",
        "2275  |1|Causer|explicit|\n",
        "2276  |3|4|explicit|\n",
        "2277  |3|50|Causer|explicit|\n",
        "2278  |50|other|\n",
        "2279  |50|\n",
        "2280  |50|\n",
        "2281  |7|50|Causer|explicit|\n",
        "2282  |50|\n",
        "2283  |\n",
        "2284  |\n",
        "2285  |\n",
        "2286  |7|50|Result|explicit|\n",
        "2287  |7|50|Causer|\n",
        "2288  |2|3|50|Causer|\n",
        "2289  |1|Causer|\n",
        "2290  |\n",
        "2291  |\n",
        "2292  |3|50|\n",
        "2293  |1|3|50|Causer|explicit|\n",
        "2294  |50|\n",
        "2295  |3|Causer|\n",
        "2296  |\n",
        "2297  |rhetorical|\n",
        "2298  |3|Causer|Result|explicit|rhetorical|\n",
        "2299  |5|Causer|Result|\n",
        "2300  |4|5|Causer|Result|\n",
        "2301  |1|2|Causer|\n",
        "2302  |1|2|Result|\n",
        "2303  |3|Result|explicit|rhetorical|\n",
        "2304  |3|Causer|Result|\n",
        "2305  |3|50|\n",
        "2306  |Causer|explicit|\n",
        "2307  |50|\n",
        "2308  |1|3|Causer|Result|\n",
        "2309  |50|\n",
        "2310  |3|Causer|explicit|\n",
        "2311  |1|3|Causer|Result|explicit|\n",
        "2312  |1|3|Causer|Result|explicit|\n",
        "2313  |2|3|\n",
        "2314  |3|50|Causer|Result|explicit|\n",
        "2315  |50|explicit|\n",
        "2316  |7|Causer|\n",
        "2317  |2|3|Causer|Result|explicit|\n",
        "2318  |50|Causer|\n",
        "2319  |\n",
        "2320  |1|Result|\n",
        "2321  |3|other|Causer|explicit|\n",
        "2322  |4|5|14|Result|explicit|\n",
        "2323  |5b|\n",
        "2324  |11|Causer|explicit|\n",
        "2325  |50|Causer|Result|\n",
        "2326  |50|\n",
        "2327  |50|explicit|rhetorical|\n",
        "2328  |\n",
        "2329  |50|\n",
        "2330  |\n",
        "2331  |3|5|Result|\n",
        "2332  |3|4|5|Causer|Result|explicit|\n",
        "2333  |1|3|4|Causer|\n",
        "2334  |1|3|Causer|\n",
        "2335  |1|50|Causer|Result|\n",
        "2336  |5|7|14|Causer|Result|explicit|\n",
        "2337  |7|50|Causer|explicit|\n",
        "2338  |50|\n",
        "2339  |7|\n",
        "2340  |Causer|Result|explicit|\n",
        "2341  |\n",
        "2342  |3|50|Result|explicit|\n",
        "2343  |Causer|\n",
        "2344  |Causer|\n",
        "2345  |50|Result|\n",
        "2346  |1|50|Causer|\n",
        "2347  |1|3|7|50|Causer|Result|explicit|\n",
        "2348  |3|5|explicit|\n",
        "2349  |4|5|Causer|Result|explicit|\n",
        "2350  |14|Causer|Result|explicit|\n",
        "2351  |3|4|Causer|Result|explicit|\n",
        "2352  |13|14|\n",
        "2353  |13|Causer|Result|explicit|\n",
        "2354  |50|Causer|explicit|\n",
        "2355  |7|50|Causer|Result|explicit|\n",
        "2356  |7|\n",
        "2357  |50|Result|\n",
        "2358  |50|explicit|\n",
        "2359  |3|\n",
        "2360  |3|Causer|Result|rhetorical|\n",
        "2361  |1|2|50|\n",
        "2362  |3|Causer|\n",
        "2363  |3|50|Result|\n",
        "2364  |explicit|rhetorical|\n",
        "2365  |11|13|Causer|explicit|\n",
        "2366  |50|Result|\n",
        "2367  |1|3|50|Causer|explicit|\n",
        "2368  |5|\n",
        "2369  |1|Causer|explicit|\n",
        "2370  |1|3|Causer|explicit|\n",
        "2371  |3|4|Causer|Result|explicit|\n",
        "2372  |5|14|Causer|Result|explicit|\n",
        "2373  |3|Causer|\n",
        "2374  |4|5|7|50|5b|other|Causer|Result|\n",
        "2375  |3|4|7|14|50|Causer|Result|explicit|rhetorical|\n",
        "2376  |50|\n",
        "2377  |\n",
        "2378  |50|\n",
        "2379  |\n",
        "2380  |3|5|50|Causer|explicit|\n",
        "2381  |5|\n",
        "2382  |4|5|7|13|Causer|Result|explicit|\n",
        "2383  |5|5b|\n",
        "2384  |\n",
        "2385  |7|50|Causer|explicit|\n",
        "2386  |\n",
        "2387  |7|50|Causer|Result|explicit|\n",
        "2388  |50|Result|\n",
        "2389  |Causer|\n",
        "2390  |\n",
        "2391  |50|\n",
        "2392  |50|rhetorical|\n",
        "2393  |\n",
        "2394  |5|\n",
        "2395  |11|12|13|Causer|Result|\n",
        "2396  |13|Causer|explicit|\n",
        "2397  |\n",
        "2398  |50|\n",
        "2399  |4|7|\n",
        "2400  |50|Result|\n",
        "2401  |Causer|\n",
        "2402  |50|Result|\n",
        "2403  |3|50|Causer|explicit|\n",
        "2404  |3|50|other|Causer|Result|\n",
        "2405  |3|5|7|Causer|Result|\n",
        "2406  |1|50|Causer|\n",
        "2407  |3|50|Causer|explicit|\n",
        "2408  |3|5|Causer|explicit|\n",
        "2409  |7|50|\n",
        "2410  |5|50|Result|\n",
        "2411  |5|50|Causer|\n",
        "2412  |5|\n",
        "2413  |\n",
        "2414  |50|\n",
        "2415  |7|Causer|\n",
        "2416  |50|Result|\n",
        "2417  |5|Causer|\n",
        "2418  |5|\n",
        "2419  |50|\n",
        "2420  |7|Causer|Result|Anaphor|explicit|\n",
        "2421  |1|50|Causer|explicit|\n",
        "2422  |2|7|Causer|Result|explicit|\n",
        "2423  |7|Causer|\n",
        "2424  |7|50|\n",
        "2425  |3|50|Anaphor|explicit|rhetorical|\n",
        "2426  |3|50|Causer|explicit|\n",
        "2427  |3|50|explicit|\n",
        "2428  |3|50|other|Causer|Result|\n",
        "2429  |3|50|Causer|explicit|\n",
        "2430  |1|3|50|\n",
        "2431  |50|\n",
        "2432  |1|50|Result|explicit|\n",
        "2433  |6|7|Causer|Result|explicit|\n",
        "2434  |50|Causer|Result|Anaphor|explicit|\n",
        "2435  |6|\n",
        "2436  |1|Causer|Result|explicit|\n",
        "2437  |Result|\n",
        "2438  |50|rhetorical|\n",
        "2439  |\n",
        "2440  |3|50|Causer|Result|\n",
        "2441  |3|50|Result|\n",
        "2442  |other|\n",
        "2443  |3|\n",
        "2444  |3|50|Causer|Result|\n",
        "2445  |13|\n",
        "2446  |50|Causer|\n",
        "2447  |1|3|Causer|\n",
        "2448  |3|\n",
        "2449  |11|12|13|50|Causer|Result|explicit|\n",
        "2450  |4|\n",
        "2451  |\n",
        "2452  |7|50|Result|Anaphor|explicit|\n",
        "2453  |50|Result|\n",
        "2454  |Result|\n",
        "2455  |3|Causer|rhetorical|\n",
        "2456  |\n",
        "2457  |\n",
        "2458  |\n",
        "2459  |explicit|\n",
        "2460  |\n",
        "2461  |\n",
        "2462  |3|\n",
        "2463  |1|\n",
        "2464  |1|3|50|Causer|explicit|\n",
        "2465  |1|3|50|Causer|Result|explicit|\n",
        "2466  |\n",
        "2467  |3|4|5|14|50|Causer|Result|Anaphor|explicit|\n",
        "2468  |1|3|Causer|Result|explicit|\n",
        "2469  |1|3|7|Causer|explicit|\n",
        "2470  |50|Result|\n",
        "2471  |7|Causer|\n",
        "2472  |50|Result|\n",
        "2473  |3|5|Causer|\n",
        "2474  |50|rhetorical|\n",
        "2475  |\n",
        "2476  |3|50|other|Result|explicit|\n",
        "2477  |2|3|50|Causer|Result|explicit|\n",
        "2478  |50|\n",
        "2479  |50|Causer|Result|\n",
        "2480  |7|explicit|\n",
        "2481  |50|\n",
        "2482  |3|\n",
        "2483  |1|2|Causer|explicit|\n",
        "2484  |1|3|Causer|Result|explicit|\n",
        "2485  |7|50|Causer|Result|explicit|\n",
        "2486  |5|\n",
        "2487  |3|5|50|Causer|Result|explicit|\n",
        "2488  |\n",
        "2489  |50|\n",
        "2490  |50|rhetorical|\n",
        "2491  |1|\n",
        "2492  |1|3|other|Causer|Anaphor|explicit|\n",
        "2493  |50|Result|explicit|\n",
        "2494  |7|\n",
        "2495  |7|other|Causer|Result|\n",
        "2496  |7|50|other|Causer|Anaphor|rhetorical|\n",
        "2497  |\n",
        "2498  |\n",
        "2499  |Causer|Anaphor|\n",
        "2500  |Causer|Result|\n",
        "2501  |\n",
        "2502  |3|4|Causer|Result|explicit|\n",
        "2503  |\n",
        "2504  |50|other|\n",
        "2505  |50|\n",
        "2506  |\n",
        "2507  |7|\n",
        "2508  |\n",
        "2509  |7|\n",
        "2510  |6|50|Causer|rhetorical|\n",
        "2511  |7|Causer|\n",
        "2512  |6|7|Causer|Result|explicit|\n",
        "2513  |50|Result|explicit|\n",
        "2514  |6|\n",
        "2515  |\n",
        "2516  |6|7|Causer|explicit|rhetorical|\n",
        "2517  |\n",
        "2518  |1|2|3|explicit|\n",
        "2519  |1|3|Causer|rhetorical|\n",
        "2520  |\n",
        "2521  |1|6|50|Causer|Result|explicit|\n",
        "2522  |5|Result|\n",
        "2523  |5b|Causer|Result|\n",
        "2524  |1|6|7|Causer|Result|\n",
        "2525  |1|3|50|other|Causer|Result|explicit|\n",
        "2526  |3|5|50|Causer|explicit|\n",
        "2527  |50|Result|\n",
        "2528  |\n",
        "2529  |Causer|\n",
        "2530  |50|Result|\n",
        "2531  |3|50|Causer|Result|explicit|\n",
        "2532  |\n",
        "2533  |7|50|Causer|Result|explicit|rhetorical|\n",
        "2534  |6|7|other|Causer|Result|\n",
        "2535  |7|Causer|Result|explicit|\n",
        "2536  |50|\n",
        "2537  |\n",
        "2538  |13|Causer|explicit|rhetorical|\n",
        "2539  |\n",
        "2540  |4|7|11|12|13|Causer|Result|explicit|\n",
        "2541  |5|\n",
        "2542  |5|Result|explicit|\n",
        "2543  |3|Causer|explicit|\n",
        "2544  |1|Causer|\n",
        "2545  |7|50|Causer|Result|explicit|rhetorical|\n",
        "2546  |5|\n",
        "2547  |50|Result|explicit|\n",
        "2548  |50|\n",
        "2549  |\n",
        "2550  |5|5b|\n",
        "2551  |50|rhetorical|\n",
        "2552  |\n",
        "2553  |50|explicit|\n",
        "2554  |rhetorical|\n",
        "2555  |1|50|\n",
        "2556  |1|2|Result|\n",
        "2557  |2|3|Causer|Result|explicit|rhetorical|\n",
        "2558  |3|\n",
        "2559  |3|5|Causer|Result|explicit|\n",
        "2560  |\n",
        "2561  |1|3|Causer|Result|explicit|\n",
        "2562  |1|Causer|explicit|\n",
        "2563  |50|\n",
        "2564  |50|Anaphor|explicit|rhetorical|\n",
        "2565  |7|other|rhetorical|\n",
        "2566  |5|50|Causer|Result|rhetorical|\n",
        "2567  |6|50|\n",
        "2568  |\n",
        "2569  |7|50|Result|\n",
        "2570  |5|7|50|Result|explicit|\n",
        "2571  |50|\n",
        "2572  |\n",
        "2573  |1|7|Causer|Result|explicit|\n",
        "2574  |6|7|50|other|Causer|Result|Anaphor|explicit|\n",
        "2575  |\n",
        "2576  |1|2|3|Causer|Result|\n",
        "2577  |\n",
        "2578  |\n",
        "2579  |50|\n",
        "2580  |50|\n",
        "2581  |\n",
        "2582  |3|Causer|explicit|\n",
        "2583  |3|\n",
        "2584  |2|3|Causer|Result|explicit|\n",
        "2585  |3|\n",
        "2586  |50|\n",
        "2587  |\n",
        "2588  |rhetorical|\n",
        "2589  |7|\n",
        "2590  |50|other|Causer|Result|Anaphor|explicit|\n",
        "2591  |50|rhetorical|\n",
        "2592  |1|3|50|Causer|Result|explicit|\n",
        "2593  |50|\n",
        "2594  |1|3|Causer|Result|\n",
        "2595  |3|5|Causer|Result|explicit|\n",
        "2596  |7|50|\n",
        "2597  |50|\n",
        "2598  |1|3|50|Causer|explicit|\n",
        "2599  |\n",
        "2600  |\n",
        "2601  |\n",
        "2602  |50|\n",
        "2603  |50|Result|rhetorical|\n",
        "2604  |5|50|Result|\n",
        "2605  |1|2|50|Result|explicit|\n",
        "2606  |1|Causer|\n",
        "2607  |2|Result|explicit|\n",
        "2608  |5|13|50|Causer|Result|\n",
        "2609  |7|\n",
        "2610  |7|13|50|Causer|Result|explicit|\n",
        "2611  |14|50|Causer|\n",
        "2612  |\n",
        "2613  |3|50|\n",
        "2614  |1|3|Causer|\n",
        "2615  |50|\n",
        "2616  |1|3|50|Causer|Result|explicit|\n",
        "2617  |1|50|Causer|explicit|\n",
        "2618  |1|50|Causer|explicit|\n",
        "2619  |1|3|7|Causer|\n",
        "2620  |1|50|\n",
        "2621  |1|50|Causer|explicit|\n",
        "2622  |50|Result|\n",
        "2623  |Causer|\n",
        "2624  |7|50|Causer|Result|explicit|\n",
        "2625  |50|\n",
        "2626  |1|3|50|Causer|explicit|\n",
        "2627  |3|4|Causer|Result|explicit|\n",
        "2628  |4|5|Causer|Result|explicit|\n",
        "2629  |14|Result|\n",
        "2630  |12|13|50|Causer|Result|explicit|\n",
        "2631  |13|14|Causer|\n",
        "2632  |50|\n",
        "2633  |50|other|Causer|Result|explicit|\n",
        "2634  |50|\n",
        "2635  |explicit|\n",
        "2636  |50|other|Result|\n",
        "2637  |4|7|50|Causer|Result|\n",
        "2638  |13|50|Causer|Result|\n",
        "2639  |7|explicit|\n",
        "2640  |50|other|Result|explicit|\n",
        "2641  |\n",
        "2642  |3|7|50|Result|explicit|\n",
        "2643  |3|4|5|Causer|Result|explicit|\n",
        "2644  |3|50|Causer|Result|explicit|\n",
        "2645  |1|2|\n",
        "2646  |1|50|Causer|explicit|\n",
        "2647  |\n",
        "2648  |7|50|Causer|Result|explicit|\n",
        "2649  |50|\n",
        "2650  |\n",
        "2651  |11|12|13|Causer|Result|explicit|\n",
        "2652  |14|\n",
        "2653  |1|3|50|Causer|\n",
        "2654  |1|2|50|other|Causer|Result|\n",
        "2655  |1|2|3|50|Causer|Result|explicit|\n",
        "2656  |14|Result|\n",
        "2657  |5|6|7|50|Causer|Result|explicit|\n",
        "2658  |7|50|Causer|explicit|\n",
        "2659  |Result|\n",
        "2660  |\n",
        "2661  |7|13|50|Result|\n",
        "2662  |Result|\n",
        "2663  |11|13|Causer|\n",
        "2664  |3|11|12|13|Causer|Result|explicit|\n",
        "2665  |50|Result|\n",
        "2666  |50|Result|Anaphor|\n",
        "2667  |7|50|Causer|Result|explicit|\n",
        "2668  |50|Result|rhetorical|\n",
        "2669  |1|Causer|rhetorical|\n",
        "2670  |50|Causer|Result|rhetorical|\n",
        "2671  |1|3|\n",
        "2672  |\n",
        "2673  |1|\n",
        "2674  |3|other|Result|Anaphor|\n",
        "2675  |\n",
        "2676  |12|13|Causer|Result|explicit|\n",
        "2677  |7|Causer|\n",
        "2678  |1|50|Causer|rhetorical|\n",
        "2679  |3|13|Causer|Result|\n",
        "2680  |3|\n",
        "2681  |1|50|Result|\n",
        "2682  |50|Causer|Result|explicit|rhetorical|\n",
        "2683  |1|3|50|Causer|Result|\n",
        "2684  |1|3|50|Causer|explicit|\n",
        "2685  |3|5|50|Causer|\n",
        "2686  |50|\n",
        "2687  |50|\n",
        "2688  |\n",
        "2689  |50|\n",
        "2690  |\n",
        "2691  |50|\n",
        "2692  |1|other|Causer|explicit|\n",
        "2693  |1|3|50|Result|\n",
        "2694  |5|\n",
        "2695  |3|4|5|Causer|explicit|\n",
        "2696  |14|Result|\n",
        "2697  |5|50|Causer|\n",
        "2698  |50|other|\n",
        "2699  |50|\n",
        "2700  |50|\n",
        "2701  |\n",
        "2702  |\n",
        "2703  |1|Causer|\n",
        "2704  |1|\n",
        "2705  |1|3|50|Result|rhetorical|\n",
        "2706  |13|Causer|Result|\n",
        "2707  |3|4|5|Causer|Result|\n",
        "2708  |1|13|14|Causer|Result|explicit|\n",
        "2709  |\n",
        "2710  |\n",
        "2711  |7|50|other|Causer|Result|explicit|\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_plus_cr = all_codes + cr_codes\n",
      "newx_t, yByCode_t = extract_xs_ys(ixtest, ix2newxs, ix2newys, all_plus_cr)\n",
      "print newx_t[0].shape, \"features\"\n",
      "\n",
      "# SVM Is best when using joint features\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, GradientBoostingClassifier)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, factMach)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LDA)\n",
      "new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LinearSVC)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, LogisticRegression)\n",
      "#new_code2cls = train(cr_codes + [\"explicit\"], newx_t, yByCode_t, DecisionTreeClassifier)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(912,) features\n",
        "Training for : CRel\n",
        "Creating validation dataset of 0.01 of training for adaptive regularization\n",
        "-- Epoch 1\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 2\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 3\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 4\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 5\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 6\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 7\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 8\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 9\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 10\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : RRel\n",
        "Creating validation dataset of 0.01 of training for adaptive regularization\n",
        "-- Epoch 1\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 2\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 3\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 4\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 5\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 6\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 7\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 8\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 9\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 10\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : C->R\n",
        "Creating validation dataset of 0.01 of training for adaptive regularization\n",
        "-- Epoch 1\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 2\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 3\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 4\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 5\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 6\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 7\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 8\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 9\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 10\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training for : explicit\n",
        "Creating validation dataset of 0.01 of training for adaptive regularization\n",
        "-- Epoch 1\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 2\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 3\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 4\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 5\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 6\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 7\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 8\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 9\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- Epoch 10\n",
        "Training RMSE: nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Search for good C values\n",
      "\n",
      "dct = {}\n",
      "codes = cr_codes + [\"explicit\"] #[CAUSE_RESULT]\n",
      "for c in [1.0, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5]:\n",
      "    print \"C\", c\n",
      "    new_code2cls = train(codes, newx_t, yByCode_t, lambda : LinearSVC(C = float(c)))\n",
      "    dct[c] = test(codes, ixvalid, ix2newxs, ix2newys, new_code2cls)\n",
      "\n",
      "print \"\"\n",
      "for k,v in sorted(dct.items()):\n",
      "    print \"C\", str(k).ljust(5), \"Metric:\",v\n",
      "    \n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C 1.0\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.566820276498\n",
        "f1:         0.643979057592\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.530973451327\n",
        "f1:         0.610687022901\n",
        "accuracy:   0.774336283186\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.584158415842\n",
        "f1:         0.643051771117\n",
        "accuracy:   0.806784660767\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.74269005848\n",
        "precision:  0.490347490347\n",
        "f1:         0.590697674419\n",
        "accuracy:   0.740412979351\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7305, Precision: 0.5426, F1: 0.6218, Accuracy: 0.7799, Codes:   668\n",
        "C 1.5\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:       CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.564814814815\n",
        "f1:         0.640419947507\n",
        "accuracy:   0.797935103245\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.521739130435\n",
        "f1:         0.604534005038\n",
        "accuracy:   0.768436578171\n",
        "sentences:  167\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.727272727273\n",
        "precision:  0.56338028169\n",
        "f1:         0.634920634921\n",
        "accuracy:   0.796460176991\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.492307692308\n",
        "f1:         0.593967517401\n",
        "accuracy:   0.741887905605\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7335, Precision: 0.5351, F1: 0.6182, Accuracy: 0.7758, Codes:   668\n",
        "C 1.6\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.567441860465\n",
        "f1:         0.642105263158\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.724550898204\n",
        "precision:  0.526086956522\n",
        "f1:         0.609571788413\n",
        "accuracy:   0.771386430678\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.559241706161\n",
        "f1:         0.627659574468\n",
        "accuracy:   0.793510324484\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.492307692308\n",
        "f1:         0.593967517401\n",
        "accuracy:   0.741887905605\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7320, Precision: 0.5358, F1: 0.6181, Accuracy: 0.7762, Codes:   668\n",
        "C 1.7\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.566820276498\n",
        "f1:         0.643979057592\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.712574850299\n",
        "precision:  0.526548672566\n",
        "f1:         0.605597964377\n",
        "accuracy:   0.771386430678\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.572815533981\n",
        "f1:         0.636118598383\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.496124031008\n",
        "f1:         0.596736596737\n",
        "accuracy:   0.744837758112\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7305, Precision: 0.5401, F1: 0.6203, Accuracy: 0.7788, Codes:   668\n",
        "C 1.8\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.569444444444\n",
        "f1:         0.645669291339\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.74251497006\n",
        "precision:  0.529914529915\n",
        "f1:         0.618453865337\n",
        "accuracy:   0.774336283186\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.567307692308\n",
        "f1:         0.632707774799\n",
        "accuracy:   0.797935103245\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.719298245614\n",
        "precision:  0.523404255319\n",
        "f1:         0.605911330049\n",
        "accuracy:   0.76401179941\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7305, Precision: 0.5472, F1: 0.6255, Accuracy: 0.7841, Codes:   668\n",
        "C 1.9\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.566820276498\n",
        "f1:         0.643979057592\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.736526946108\n",
        "precision:  0.527896995708\n",
        "f1:         0.615\n",
        "accuracy:   0.772861356932\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.727272727273\n",
        "precision:  0.571428571429\n",
        "f1:         0.64\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.492307692308\n",
        "f1:         0.593967517401\n",
        "accuracy:   0.741887905605\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7395, Precision: 0.5392, F1: 0.6229, Accuracy: 0.7784, Codes:   668\n",
        "C 2.0\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:       CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.564220183486\n",
        "f1:         0.642297650131\n",
        "accuracy:   0.797935103245\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.712574850299\n",
        "precision:  0.519650655022\n",
        "f1:         0.60101010101\n",
        "accuracy:   0.766961651917\n",
        "sentences:  167\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.572815533981\n",
        "f1:         0.636118598383\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.494208494208\n",
        "f1:         0.595348837209\n",
        "accuracy:   0.743362831858\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7305, Precision: 0.5373, F1: 0.6184, Accuracy: 0.7770, Codes:   668\n",
        "C 2.1\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:       CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.569444444444\n",
        "f1:         0.645669291339\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.748502994012\n",
        "precision:  0.527426160338\n",
        "f1:         0.618811881188\n",
        "accuracy:   0.772861356932\n",
        "sentences:  167\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.572815533981\n",
        "f1:         0.636118598383\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.760233918129\n",
        "precision:  0.496183206107\n",
        "f1:         0.600461893764\n",
        "accuracy:   0.744837758112\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7425, Precision: 0.5410, F1: 0.6250, Accuracy: 0.7795, Codes:   668\n",
        "C 2.2\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.570093457944\n",
        "f1:         0.643799472296\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.521739130435\n",
        "f1:         0.604534005038\n",
        "accuracy:   0.768436578171\n",
        "sentences:  167\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.572815533981\n",
        "f1:         0.636118598383\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.760233918129\n",
        "precision:  0.496183206107\n",
        "f1:         0.600461893764\n",
        "accuracy:   0.744837758112\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7335, Precision: 0.5398, F1: 0.6210, Accuracy: 0.7784, Codes:   668\n",
        "C 2.3\n",
        "Training for : CRel\n",
        "Training for : RRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "Training for : explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.567441860465\n",
        "f1:         0.642105263158\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.724550898204\n",
        "precision:  0.526086956522\n",
        "f1:         0.609571788413\n",
        "accuracy:   0.771386430678\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.715151515152\n",
        "precision:  0.572815533981\n",
        "f1:         0.636118598383\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.760233918129\n",
        "precision:  0.492424242424\n",
        "f1:         0.597701149425\n",
        "accuracy:   0.741887905605\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7350, Precision: 0.5392, F1: 0.6211, Accuracy: 0.7780, Codes:   668\n",
        "C 2.4\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.745454545455\n",
        "precision:  0.561643835616\n",
        "f1:         0.640625\n",
        "accuracy:   0.796460176991\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.524017467249\n",
        "f1:         0.606060606061\n",
        "accuracy:   0.769911504425\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.727272727273\n",
        "precision:  0.56338028169\n",
        "f1:         0.634920634921\n",
        "accuracy:   0.796460176991\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.754385964912\n",
        "precision:  0.492366412214\n",
        "f1:         0.59584295612\n",
        "accuracy:   0.741887905605\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7365, Precision: 0.5349, F1: 0.6191, Accuracy: 0.7759, Codes:   668\n",
        "C 2.5\n",
        "Training for : CRel\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "Training for : C->R\n",
        "Training for :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.567441860465\n",
        "f1:         0.642105263158\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.524017467249\n",
        "f1:         0.606060606061\n",
        "accuracy:   0.769911504425\n",
        "sentences:  167\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.721212121212\n",
        "precision:  0.572115384615\n",
        "f1:         0.638069705094\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:       explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.498054474708\n",
        "f1:         0.598130841121\n",
        "accuracy:   0.746312684366\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7320, Precision: 0.5400, F1: 0.6208, Accuracy: 0.7788, Codes:   668\n",
        "\n",
        "C 1.0   Metric: Recall: 0.7305, Precision: 0.5426, F1: 0.6218, Accuracy: 0.7799, Codes:   668\n",
        "C 1.5   Metric: Recall: 0.7335, Precision: 0.5351, F1: 0.6182, Accuracy: 0.7758, Codes:   668\n",
        "C 1.6   Metric: Recall: 0.7320, Precision: 0.5358, F1: 0.6181, Accuracy: 0.7762, Codes:   668\n",
        "C 1.7   Metric: Recall: 0.7305, Precision: 0.5401, F1: 0.6203, Accuracy: 0.7788, Codes:   668\n",
        "C 1.8   Metric: Recall: 0.7305, Precision: 0.5472, F1: 0.6255, Accuracy: 0.7841, Codes:   668\n",
        "C 1.9   Metric: Recall: 0.7395, Precision: 0.5392, F1: 0.6229, Accuracy: 0.7784, Codes:   668\n",
        "C 2.0   Metric: Recall: 0.7305, Precision: 0.5373, F1: 0.6184, Accuracy: 0.7770, Codes:   668\n",
        "C 2.1   Metric: Recall: 0.7425, Precision: 0.5410, F1: 0.6250, Accuracy: 0.7795, Codes:   668\n",
        "C 2.2   Metric: Recall: 0.7335, Precision: 0.5398, F1: 0.6210, Accuracy: 0.7784, Codes:   668\n",
        "C 2.3   Metric: Recall: 0.7350, Precision: 0.5392, F1: 0.6211, Accuracy: 0.7780, Codes:   668\n",
        "C 2.4   Metric: Recall: 0.7365, Precision: 0.5349, F1: 0.6191, Accuracy: 0.7759, Codes:   668\n",
        "C 2.5   Metric: Recall: 0.7320, Precision: 0.5400, F1: 0.6208, Accuracy: 0.7788, Codes:   668\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Test Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixtest, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test Data #2: \n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " CRel\n",
        "recall:     0.0\n",
        "precision:  0.0\n",
        "f1:         0.0\n",
        "accuracy:   0.0\n",
        "sentences:  416\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RRel\n",
        "recall:     0.0\n",
        "precision:  0.0\n",
        "f1:         0.0\n",
        "accuracy:   0.0\n",
        "sentences:  418\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " C->R\n",
        "recall:     0.0\n",
        "precision:  0.0\n",
        "f1:         0.0\n",
        "accuracy:   0.0\n",
        "sentences:  403\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.0\n",
        "precision:  0.0\n",
        "f1:         0.0\n",
        "accuracy:   0.0\n",
        "sentences:  438\n",
        "\n",
        "<class '__main__.factMach'> Recall: 0.0000, Precision: 0.0000, F1: 0.0000, Accuracy: 0.0000, Codes:  1675\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Validation Data #2: \"\n",
      "metrics = test(cr_codes + [\"explicit\"], ixvalid, ix2newxs, ix2newys, new_code2cls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Validation Data #2: \n",
        "code:       CRel\n",
        "recall:     0.739393939394\n",
        "precision:  0.567441860465\n",
        "f1:         0.642105263158\n",
        "accuracy:   0.799410029499\n",
        "sentences:  165\n",
        "\n",
        "code:       RRel\n",
        "recall:     0.718562874251\n",
        "precision:  0.524017467249\n",
        "f1:         0.606060606061\n",
        "accuracy:   0.769911504425\n",
        "sentences: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 167\n",
        "\n",
        "code:       C->R\n",
        "recall:     0.721212121212\n",
        "precision:  0.572115384615\n",
        "f1:         0.638069705094\n",
        "accuracy:   0.800884955752\n",
        "sentences:  165\n",
        "\n",
        "code:      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " explicit\n",
        "recall:     0.748538011696\n",
        "precision:  0.498054474708\n",
        "f1:         0.598130841121\n",
        "accuracy:   0.746312684366\n",
        "sentences:  171\n",
        "\n",
        "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.7320, Precision: 0.5400, F1: 0.6208, Accuracy: 0.7788, Codes:   668\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Using Min\\Max Distance from Decision Plane\n",
      "  Single Features\n",
      "***\n",
      "<class 'LDA'> Recall: 0.6797, Precision: 0.6151, F1: 0.6458, Accuracy: 0.7784, Codes:   637\n",
      "***\n",
      "<class 'LinearSVC'> Recall: 0.6562, Precision: 0.6069, F1: 0.6297, Accuracy: 0.7704, Codes:   637\n",
      "<class 'logistic.LogisticRegression'> Recall: 0.6578, Precision: 0.6207, F1: 0.6379, Accuracy: 0.7784, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6185, Precision: 0.6458, F1: 0.6288, Accuracy: 0.7835, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5950, Precision: 0.6334, F1: 0.6118, Accuracy: 0.7755, Codes:   637\n",
      "    \n",
      "  Joint Features\n",
      "<class 'sklearn.lda.LDA'> Recall: 0.5667, Precision: 0.6260, F1: 0.5934, Accuracy: 0.7700, Codes:   637\n",
      "***\n",
      "<class 'sklearn.svm.classes.LinearSVC'> Recall: 0.6703, Precision: 0.6323, F1: 0.6502, Accuracy: 0.7853, Codes:   637\n",
      "***\n",
      "code:       C->R\n",
      "recall:     0.677215189873\n",
      "precision:  0.685897435897\n",
      "f1:         0.68152866242\n",
      "accuracy:   0.813432835821\n",
      "sentences:  158\n",
      "<class 'LogisticRegression'> Recall: 0.6342, Precision: 0.6539, F1: 0.6424, Accuracy: 0.7900, Codes:   637\n",
      "<class 'GradientBoostingClassifier'> Recall: 0.6075, Precision: 0.6396, F1: 0.6196, Accuracy: 0.7793, Codes:   637\n",
      "<class 'DecisionTreeClassifier'> Recall: 0.5651, Precision: 0.6236, F1: 0.5896, Accuracy: 0.7672, Codes:   637"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*** TODO *** - Peter\\Simon 5.14.2014\n",
      "Match Explicit + Cause or Result (or both)\n",
      "Try reading this: http://ceur-ws.org/Vol-1109/paper4.pdf\n",
      "Read Peter's paper\n",
      "\n",
      "1. <s>Try removing commas and '\"''s and other punctuation</s>\n",
      "2. <s>Try skip gram features (Peter)</s>\n",
      "3. Dependency parse \n",
      "    - span of words for the explicit and the concept\n",
      "    - find any depencencies tha join those two groups\n",
      "    - dependency type\n",
      "        - NSUBJ or PREP_TO or CONJ_AND\n",
      "        - OR advmod, conj_and, dobj, prep_of, prep_in\n",
      "        - OR acomp,  advmod\n",
      "4. <s>Read Peter's latest paper </s>\n",
      "5. Read related papers - Semeval 2007 (or close), Rink et al, Girju et al, etc\n",
      "5. <s>Try training a second classifier based on the output of the first including the predictions for the previous and next word</s>\n",
      "6. Add in sentence level features, such as BOW and dependency parse features\n",
      "7. Do some cross validation\n",
      "8. Add in predicted codes from previous \\ next sentence\n",
      "9. Try blending multiple window based classifiers (Log R, SVM, LDA, DT) using a regression model\n",
      "\"\"\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}