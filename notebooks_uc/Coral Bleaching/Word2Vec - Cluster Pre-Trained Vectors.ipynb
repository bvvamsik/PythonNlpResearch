{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's Load the Full Google News Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_FOLDER  = \"/Users/simon.hughes/Google Drive/PhD/Data/CoralBleaching/PhraseExtractionAnalysis\"\n",
    "PHRASES_FILE = \"%s/Phrases.txt\" % ROOT_FOLDER\n",
    "CLUSTER_SYN_FILE = \"%s/word2vec_temp_syns.txt\" % ROOT_FOLDER\n",
    "MODEL_FILE   = \"/Users/simon.hughes/Documents/Dice Data/Word2Vec/GoogleNews-vectors-negative300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class SynonymMapper(object):\n",
    "    def __init__(self, mapper, nested, case_sensitive=False):\n",
    "        self.case_sensitive = case_sensitive\n",
    "        self.mapper = mapper\n",
    "        self.nested = nested\n",
    "        self.synonyms = set()\n",
    "        for rhs in self.mapper.values():\n",
    "            for syn in rhs:\n",
    "                self.synonyms.add(syn)\n",
    "        \n",
    "    def is_synonym(self, term):\n",
    "        return term in self.synonyms\n",
    "        \n",
    "    def map_synonyms(self, tokens, debug=False):\n",
    "        mapped = []\n",
    "        size = len(tokens)\n",
    "        if not self.case_sensitive:\n",
    "            tmp_tokens = map(lambda s: s.lower(), tokens)\n",
    "        else:\n",
    "            tmp_tokens = tokens\n",
    "        ix = 0\n",
    "        while ix < size:\n",
    "            if debug:\n",
    "                print \"ix\", ix\n",
    "            best, best_key = None, None\n",
    "            tmp_ix = ix        \n",
    "            max_ix = ix\n",
    "            current = \"\"\n",
    "            d = self.nested\n",
    "            while tmp_ix < size and tmp_tokens[tmp_ix] in d:\n",
    "                current += tmp_tokens[tmp_ix] + \" \"\n",
    "                key = current.strip()\n",
    "                if key in self.mapper:\n",
    "                    if debug:\n",
    "                        if best is not None:\n",
    "                            print(ix, tmp_ix, \"new best:\", key, \"=>\", self.mapper[key])\n",
    "                        else:\n",
    "                            print(ix, tmp_ix, \"best:\", key, \"=>\", self.mapper[key])\n",
    "                    best = self.mapper[key]\n",
    "                    best_key = key\n",
    "                    max_ix = tmp_ix                    \n",
    "                d = d[tmp_tokens[tmp_ix]]\n",
    "                tmp_ix += 1\n",
    "            if not best:\n",
    "                #retain original casing\n",
    "                mapped.append(tokens[ix])\n",
    "            else:\n",
    "                ix = max_ix\n",
    "                #yields a set\n",
    "                for item in sorted(best):\n",
    "                    mapped.append(item)\n",
    "            ix += 1\n",
    "        return mapped\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Synonym Mapper: %i synonyms mapped\" % len(self.mapper)\n",
    "\n",
    "def build_synonym_filter(files, case_sensitive=False):\n",
    "    # recursively define a defaultdict generator\n",
    "    mapper = defaultdict(set)\n",
    "    def dd():\n",
    "        return defaultdict(dd)\n",
    "    nested_map = defaultdict(dd)\n",
    "    file_locn = dict()\n",
    "    if type(files) == str:\n",
    "        files = [files]\n",
    "    for f in files:\n",
    "        with open(f, \"r+\") as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if len(line) > 0 and not line[0] == \"#\":\n",
    "                    if \"=>\" in line:\n",
    "                        left, right = line.split(\"=>\")\n",
    "                        right = set(right.split(\",\"))\n",
    "                        left_parts = left.split(\",\")\n",
    "                    else:\n",
    "                        left_parts = line.split(\",\")\n",
    "                        right = set(left_parts)\n",
    "\n",
    "                    for syn in left_parts:\n",
    "                        for rhs in right:\n",
    "                            mapper[syn].add(rhs)\n",
    "                        file_locn[syn] = f\n",
    "\n",
    "                        tokens = syn.split(\" \")\n",
    "                        prev = tokens[0]\n",
    "                        d = nested_map[prev]\n",
    "                        for token in tokens[1:]:\n",
    "                            d = d[token]\n",
    "                            prev = token                        \n",
    "    return SynonymMapper(mapper, nested_map, case_sensitive)\n",
    "\n",
    "#String processing\n",
    "def white_space_tokenize(s):\n",
    "    return s.split(\" \")\n",
    "\n",
    "__punct__ = set(\".?!,;:\")\n",
    "def remove_punct_at_end(s):\n",
    "    while len(s) > 1 and s[-1] in __punct__:\n",
    "        s = s[:-1]\n",
    "    return s\n",
    "\n",
    "#Token Filters\n",
    "def fact_len_filter(max_len):\n",
    "    def len_filter(tokens):\n",
    "        return filter(lambda s: len(s) >= max_len, tokens)\n",
    "    return len_filter\n",
    "\n",
    "remove_empty_tokens_filter = fact_len_filter(1)\n",
    "\n",
    "def lower_case_filter(tokens):\n",
    "    if type(tokens) == str:\n",
    "        return tokens.lower()\n",
    "    return map(lambda t: t.lower(), tokens)\n",
    "\n",
    "__punct__ = set(\".?!,;:\")\n",
    "\n",
    "def remove_punct_at_end_filter(tokens):\n",
    "    return map(remove_punct_at_end, tokens)\n",
    "\n",
    "def fact_is_synonym_filter(syn_mapper):\n",
    "    def is_synonym_filter(tokens):\n",
    "        return filter(syn_mapper.is_synonym, tokens)\n",
    "    return is_synonym_filter\n",
    "\n",
    "def is_cluster_filter(tokens):\n",
    "    return filter(lambda s: s.startswith(\"cluster_\"), tokens)\n",
    "\n",
    "def remove_cluster_filter(tokens):\n",
    "    return map(lambda s: s.replace(\"cluster_\",\"\"), tokens)\n",
    "\n",
    "def analyze(s, filters):\n",
    "    temp = s\n",
    "    for f in filters:\n",
    "        temp = f(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "#takes a while to load\n",
    "full_model = Word2Vec.load_word2vec_format(MODEL_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'teeth_whitening', 0.7431495189666748),\n",
       " (u'tooth_whitening', 0.7134369611740112),\n",
       " (u'Teeth_whitening', 0.6533203125),\n",
       " (u'microdermabrasion', 0.6517258882522583),\n",
       " (u'Whitening', 0.6478936672210693),\n",
       " (u'tooth_bleaching', 0.6321505904197693),\n",
       " (u'skin_lightening', 0.6302615404129028),\n",
       " (u'whiten', 0.6267747282981873),\n",
       " (u'whiten_teeth', 0.6228857040405273),\n",
       " (u'whitening_strips', 0.6214999556541443)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.most_similar(\"whitening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Coral_bleaching', 0.6434895992279053),\n",
       " (u'coral_reefs', 0.6368824243545532),\n",
       " (u'bleaching', 0.6276558637619019),\n",
       " (u'algal_blooms', 0.6163963079452515),\n",
       " (u'harmful_algal_blooms', 0.5943963527679443),\n",
       " (u'harmful_algal_bloom', 0.5877514481544495),\n",
       " (u'coral_spawning', 0.5838446617126465),\n",
       " (u'corals', 0.5820288062095642),\n",
       " (u'algal_bloom', 0.5637736916542053),\n",
       " (u'extinctions', 0.5617671012878418),\n",
       " (u'reefs', 0.5594044327735901),\n",
       " (u'mass_extinctions', 0.5590829253196716),\n",
       " (u'Ocean_acidification', 0.551794171333313),\n",
       " (u'acidification', 0.5517348051071167),\n",
       " (u'amphibian_declines', 0.5485835075378418),\n",
       " (u'coral_reef_habitats', 0.547818124294281),\n",
       " (u'Harmful_algal_blooms', 0.5466654300689697),\n",
       " (u'toxic_algae_blooms', 0.5465958118438721),\n",
       " (u'ocean_acidity', 0.5426976680755615),\n",
       " (u'coral', 0.5412527918815613)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.most_similar(\"coral_bleaching\", topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Our Common Terms and Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_stop_words(stop_words_file):\n",
    "    stop_words = set()\n",
    "    with open(stop_words_file) as f:\n",
    "            for line in f:\n",
    "                word = line.strip()\n",
    "                if word[0] != \"#\":\n",
    "                    word = word.lower()\n",
    "                    stop_words.add(word)\n",
    "    return stop_words\n",
    "\n",
    "phrases = load_stop_words(PHRASES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marine_biologist\n",
      "coral_reef\n",
      "delicate_balance\n",
      "tropical_storms\n",
      "shallow_waters\n",
      "bleaching_coral\n",
      "coral_bleaching\n",
      "nutrient_rich\n",
      "symbiotic_relationship\n",
      "coral_polyps\n",
      "stinging_tentacles\n",
      "coral_reefs\n",
      "climate_change\n",
      "marine_biologists\n",
      "bleached_coral\n",
      "coral_polyp\n",
      "negatively_affect\n",
      "ocean_salinity\n",
      "invertebrate_animals\n",
      "carbon_dioxide\n"
     ]
    }
   ],
   "source": [
    "for p in phrases:\n",
    "    if \" \" in p:\n",
    "        p = p.replace(\" \", \"_\")\n",
    "        if p in full_model.vocab or p[0].upper() + p[1:] in full_model.vocab:\n",
    "            print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 680)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total  = 0\n",
    "in_mdl = 0\n",
    "for p in phrases:\n",
    "    if \" \" not in p:\n",
    "        total += 1\n",
    "        if p in full_model.vocab:\n",
    "            in_mdl += 1\n",
    "total, in_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2702089, 3000000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc2key = dict()\n",
    "for key in full_model.vocab.keys():\n",
    "    lckey = key.lower()\n",
    "    if lckey not in lc2key or key > lc2key[lckey]:\n",
    "        lc2key[lckey] = key\n",
    "len(lc2key), len(full_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_vector(item, model):\n",
    "    if item not in model.vocab:\n",
    "        return None\n",
    "    vocab = model.vocab[item]\n",
    "    vector = model.syn0[vocab.index]\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm <=0:\n",
    "        return vector\n",
    "    return vector / norm\n",
    "\n",
    "def extract_clusters(ids, id2kwd):\n",
    "    clusters = defaultdict(set)\n",
    "    for kw_id, label in enumerate(ids):\n",
    "        kw = id2kwd[kw_id]\n",
    "        clusters[label].add(kw)\n",
    "    return clusters\n",
    "\n",
    "vectors = []\n",
    "ix2vec = dict()\n",
    "ix2phrase = dict()\n",
    "phrase2ix = dict()\n",
    "for phrase in phrases:\n",
    "    key = phrase.lower().replace(\" \", \"_\")\n",
    "    if key in lc2key:\n",
    "        full_key = lc2key[key]\n",
    "        vec = get_vector(full_key, full_model)\n",
    "        if vec is None:\n",
    "            continue\n",
    "        ix = len(vectors)\n",
    "        ix2vec[ix] = vec\n",
    "        ix2phrase[ix] = phrase\n",
    "        phrase2ix[phrase] = ix\n",
    "        vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering vectors into clusters via AP\n",
      "Creating 123 clusters took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# don't parallelize (n_jobs = -1), doesn't seem to work\n",
    "print(\"Clustering vectors into clusters via AP\")\n",
    "ap_clusterer = AffinityPropagation()\n",
    "ap_ids = ap_clusterer.fit_predict(vectors)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Creating %i clusters took %i seconds\" % (len(set(ap_ids)), end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "ap_lbl2cluster = extract_clusters(ap_ids, ix2phrase)\n",
    "print len(ap_lbl2cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'body', 'skeleton', 'skeletons'}),\n",
       " (1, {'lead', 'leading', 'leads'}),\n",
       " (2, {'completely', 'drastically', 'greatly', 'overall'}),\n",
       " (3, {'above', 'double', 'high', 'higher', 'lower'}),\n",
       " (4, {'movement', 'phenomena', 'phenomenon'}),\n",
       " (5, {'based', 'depend', 'depending', 'depends', 'relies', 'rely'}),\n",
       " (6, {'climate', 'conditions', 'enviroment', 'environment', 'nature'}),\n",
       " (7, {'plant', 'plants'}),\n",
       " (8,\n",
       "  {'contains',\n",
       "   'covers',\n",
       "   'gives',\n",
       "   'helps',\n",
       "   'produces',\n",
       "   'provide',\n",
       "   'provided',\n",
       "   'provides'}),\n",
       " (9,\n",
       "  {'affect',\n",
       "   'affected',\n",
       "   'affecting',\n",
       "   'affects',\n",
       "   'effected',\n",
       "   'hurt',\n",
       "   'include',\n",
       "   'negatively',\n",
       "   'negatively affect',\n",
       "   'occur',\n",
       "   'weaken'}),\n",
       " (10, {'die', 'dies', 'dying', 'kill', 'sick', 'starvation', 'starve'}),\n",
       " (11, {'large', 'size', 'small', 'tiny'}),\n",
       " (12, {'drag', 'turn', 'turning', 'turns'}),\n",
       " (13, {'play', 'plays', 'role'}),\n",
       " (14, {'forced', 'threaten', 'threatened', 'threatens'}),\n",
       " (15,\n",
       "  {'alter',\n",
       "   'altered',\n",
       "   'change',\n",
       "   'changed',\n",
       "   'changes',\n",
       "   'changing',\n",
       "   'new',\n",
       "   'reverse'}),\n",
       " (16,\n",
       "  {'example',\n",
       "   'examples',\n",
       "   'factor',\n",
       "   'purpose',\n",
       "   'reason',\n",
       "   'reasons',\n",
       "   'source',\n",
       "   'why'}),\n",
       " (17, {'report', 'reported', 'reporting', 'reports'}),\n",
       " (18, {'amount', 'amounts', 'estimate', 'number'}),\n",
       " (19, {'caused', 'combination', 'due', 'result', 'resulted', 'resulting'}),\n",
       " (20, {'delicate', 'hot', 'mouth', 'salt', 'salty', 'shallow', 'unhealthy'}),\n",
       " (21, {'normally', 'often', 'sometimes', 'tend', 'usually'}),\n",
       " (22,\n",
       "  {'alot',\n",
       "   'cant',\n",
       "   'eachother',\n",
       "   'etc',\n",
       "   'f',\n",
       "   'int',\n",
       "   'lastly',\n",
       "   'o2',\n",
       "   'thats',\n",
       "   'wich'}),\n",
       " (23,\n",
       "  {'hurricane',\n",
       "   'hurricanes',\n",
       "   'rain',\n",
       "   'rainfall',\n",
       "   'storm',\n",
       "   'storms',\n",
       "   'tradewinds',\n",
       "   'tropical storms',\n",
       "   'weather',\n",
       "   'wind'}),\n",
       " (24,\n",
       "  {'decrease',\n",
       "   'decreased',\n",
       "   'decreases',\n",
       "   'decreasing',\n",
       "   'increase',\n",
       "   'increased',\n",
       "   'increases',\n",
       "   'increasing'}),\n",
       " (25,\n",
       "  {'alive', 'recover', 'survival', 'survive', 'sustain', 'thrive', 'undergo'}),\n",
       " (26, {'about', 'deeper', 'less', 'more', 'self', 'than'}),\n",
       " (27, {'eject', 'ejected', 'ejecting', 'ejection', 'ejects'}),\n",
       " (28, {'called', 'considered', 'known', 'recognized'}),\n",
       " (29, {'case', 'cases'}),\n",
       " (30, {'animal', 'animals', 'creatures', 'fish', 'food', 'human', 'humans'}),\n",
       " (31, {'made', 'make', 'makes', 'making'}),\n",
       " (32,\n",
       "  {'everything',\n",
       "   'itself',\n",
       "   'nothing',\n",
       "   'something',\n",
       "   'thing',\n",
       "   'things',\n",
       "   'ways',\n",
       "   'what'}),\n",
       " (33, {'allow', 'give', 'given', 'giving', 'put', 'receive', 'take'}),\n",
       " (34, {'dragged', 'drop', 'dropped', 'dropping', 'drops'}),\n",
       " (35, {'big', 'biggest', 'huge', 'main', 'major', 'massive', 'sudden'}),\n",
       " (36, {'mean', 'meaning', 'means', 'now', 'process', 'seems', 'therefore'}),\n",
       " (37,\n",
       "  {'areas', 'countries', 'forces', 'places', 'region', 'regions', 'states'}),\n",
       " (38, {'grow', 'rise', 'rises', 'rose', 'swell'}),\n",
       " (39, {'common', 'different', 'same', 'specific', 'types', 'varying'}),\n",
       " (40, {'deal', 'move', 'moves', 'moving'}),\n",
       " (41, {'times', 'year', 'years'}),\n",
       " (42,\n",
       "  {'after',\n",
       "   'before',\n",
       "   'during',\n",
       "   'finally',\n",
       "   'instead',\n",
       "   'later',\n",
       "   'once',\n",
       "   'since',\n",
       "   'time',\n",
       "   'until',\n",
       "   'while',\n",
       "   'without'}),\n",
       " (43,\n",
       "  {'another reason',\n",
       "   'another thing',\n",
       "   'another way',\n",
       "   'big problem',\n",
       "   'build up',\n",
       "   'cold water',\n",
       "   'every year',\n",
       "   'excessive rainfall',\n",
       "   'fresh water',\n",
       "   'get enough',\n",
       "   'go down',\n",
       "   'go through',\n",
       "   'goes up',\n",
       "   'high water',\n",
       "   'just north',\n",
       "   'know what',\n",
       "   'lower than',\n",
       "   'made up',\n",
       "   'many different',\n",
       "   'many things',\n",
       "   'most common',\n",
       "   'most dangerous',\n",
       "   'much more',\n",
       "   'north america',\n",
       "   'one place',\n",
       "   'one reason',\n",
       "   'one thing',\n",
       "   'one way',\n",
       "   'over time',\n",
       "   'papua new guinea',\n",
       "   'per year',\n",
       "   'reason why',\n",
       "   'salt water',\n",
       "   'sea level',\n",
       "   'south america',\n",
       "   'stay healthy',\n",
       "   'takes place',\n",
       "   'things like',\n",
       "   'trade winds',\n",
       "   'very serious',\n",
       "   'water levels',\n",
       "   'went up',\n",
       "   'worst ever',\n",
       "   'you look'}),\n",
       " (44,\n",
       "  {'circumstances',\n",
       "   'happen',\n",
       "   'happened',\n",
       "   'happening',\n",
       "   'occured',\n",
       "   'occuring',\n",
       "   'place'}),\n",
       " (45,\n",
       "  {'bad', 'better', 'good', 'hard', 'healthy', 'important', 'long', 'well'}),\n",
       " (46,\n",
       "  {'dead',\n",
       "   'death',\n",
       "   'deaths',\n",
       "   'died',\n",
       "   'killed',\n",
       "   'killing',\n",
       "   'kills',\n",
       "   'mistaken'}),\n",
       " (47, {'limestone', 'rock', 'rocks', 'surface'}),\n",
       " (48,\n",
       "  {'cold', 'colder', 'cooler', 'hotter', 'normal', 'warm', 'warmer', 'worse'}),\n",
       " (49, {'merchant', 'trades', 'trading'}),\n",
       " (50,\n",
       "  {'feed',\n",
       "   'glucose',\n",
       "   'natural',\n",
       "   'nutrient',\n",
       "   'nutrient rich',\n",
       "   'nutrients',\n",
       "   'oxygen',\n",
       "   'photosynthesis',\n",
       "   'sugar',\n",
       "   'sugars'}),\n",
       " (51, {'event', 'events'}),\n",
       " (52, {'show', 'showed', 'shown', 'shows'}),\n",
       " (53,\n",
       "  {'able',\n",
       "   'cannot',\n",
       "   'could',\n",
       "   'eventually',\n",
       "   'likely',\n",
       "   'may',\n",
       "   'might',\n",
       "   'must',\n",
       "   'possible',\n",
       "   'possibly',\n",
       "   'should',\n",
       "   'would'}),\n",
       " (54, {'keep', 'keeps', 'stay'}),\n",
       " (55, {'danger', 'risk', 'threat', 'threats'}),\n",
       " (56, {'final', 'first', 'last', 'next', 'second'}),\n",
       " (57, {'another', 'ever', 'every', 'least', 'most', 'one', 'only'}),\n",
       " (58, {'light', 'sun', 'sunlight'}),\n",
       " (59,\n",
       "  {'both', 'couple', 'few', 'many', 'multiple', 'several', 'two', 'various'}),\n",
       " (60,\n",
       "  {'degrees',\n",
       "   'heat',\n",
       "   'ocean salinity',\n",
       "   'salinity',\n",
       "   'temp',\n",
       "   'temperature',\n",
       "   'temperatures'}),\n",
       " (61, {'level', 'levels', 'rate', 'rates'}),\n",
       " (62,\n",
       "  {'actually',\n",
       "   'always',\n",
       "   'basically',\n",
       "   'beautiful',\n",
       "   'just',\n",
       "   'like',\n",
       "   'maybe',\n",
       "   'my',\n",
       "   'our',\n",
       "   'part',\n",
       "   'really',\n",
       "   'so',\n",
       "   'way',\n",
       "   'we'}),\n",
       " (63,\n",
       "  {'blow',\n",
       "   'damage',\n",
       "   'damaged',\n",
       "   'damaging',\n",
       "   'dangerous',\n",
       "   'destructive',\n",
       "   'harm',\n",
       "   'harmful',\n",
       "   'sensitive'}),\n",
       " (64, {'little', 'lot', 'lots', 'much'}),\n",
       " (65, {'relationship', 'symbiotic', 'symbiotic relationship', 'tentacles'}),\n",
       " (66,\n",
       "  {'algae',\n",
       "   'colonies',\n",
       "   'coral polyp',\n",
       "   'coral polyps',\n",
       "   'h2o',\n",
       "   'invertebrate',\n",
       "   'invertebrate animals',\n",
       "   'stinging tentacles',\n",
       "   'zooxanthellae'}),\n",
       " (67, {'pass', 'passage', 'passed', 'passes'}),\n",
       " (68, {'data', 'document', 'documents', 'information'}),\n",
       " (69, {'diameter', 'foot', 'inches'}),\n",
       " (70, {'tourist', 'tourists', 'travel'}),\n",
       " (71, {'bottom', 'chart', 'charts', 'graph', 'graphs', 'guide'}),\n",
       " (72, {'according', 'said', 'says', 'stated', 'stressed'}),\n",
       " (73, {'america', 'asia', 'atlantic', 'australia', 'pacific', 'versa'}),\n",
       " (74, {'climate change', 'enviromental', 'environmental'}),\n",
       " (75, {'upset', 'upsets'}),\n",
       " (76,\n",
       "  {'bleached coral',\n",
       "   'bleaching coral',\n",
       "   'coral bleaching',\n",
       "   'coral reef',\n",
       "   'coral reefs',\n",
       "   'corals',\n",
       "   'marine',\n",
       "   'papua',\n",
       "   'reef',\n",
       "   'reefs',\n",
       "   'tropical'}),\n",
       " (77,\n",
       "  {'benefit',\n",
       "   'benefits',\n",
       "   'difference',\n",
       "   'effect',\n",
       "   'effects',\n",
       "   'impact',\n",
       "   'impacts',\n",
       "   'negative'}),\n",
       " (78, {'world', 'worlds'}),\n",
       " (79, {'inside', 'outside', 'surrounded', 'where'}),\n",
       " (80,\n",
       "  {'any',\n",
       "   'did',\n",
       "   'do',\n",
       "   'does',\n",
       "   'done',\n",
       "   'eat',\n",
       "   'else',\n",
       "   'going',\n",
       "   'let',\n",
       "   'own',\n",
       "   'probably',\n",
       "   'right',\n",
       "   'seem',\n",
       "   'type',\n",
       "   'work',\n",
       "   'wrong',\n",
       "   'you'}),\n",
       " (81,\n",
       "  {'comes',\n",
       "   'go',\n",
       "   'goes',\n",
       "   'gone',\n",
       "   'happens',\n",
       "   'occurs',\n",
       "   'puts',\n",
       "   'takes',\n",
       "   'went'}),\n",
       " (82, {'bring', 'come', 'find', 'get', 'gets', 'getting', 'got', 'recieve'}),\n",
       " (83, {'almost', 'although', 'even', 'fact', 'however', 'still', 'though'}),\n",
       " (84, {'stepping', 'walk', 'walking'}),\n",
       " (85, {'mainly', 'mostly', 'originally', 'partly'}),\n",
       " (86, {'strength', 'strong', 'unbalanced', 'weak', 'weakened', 'weaker'}),\n",
       " (87, {'article', 'articles', 'paragraph'}),\n",
       " (88,\n",
       "  {'background',\n",
       "   'bleached',\n",
       "   'bright',\n",
       "   'color',\n",
       "   'colorful',\n",
       "   'colors',\n",
       "   'red',\n",
       "   'white'}),\n",
       " (89, {'boat', 'boats', 'navigation'}),\n",
       " (90,\n",
       "  {'area',\n",
       "   'central',\n",
       "   'east',\n",
       "   'eastward',\n",
       "   'land',\n",
       "   'located',\n",
       "   'location',\n",
       "   'near',\n",
       "   'north',\n",
       "   'side',\n",
       "   'south',\n",
       "   'west',\n",
       "   'western',\n",
       "   'westward'}),\n",
       " (91, {'add', 'build', 'combine', 'create', 'form', 'formation', 'produce'}),\n",
       " (92,\n",
       "  {'atlantic ocean',\n",
       "   'costal',\n",
       "   'equatorial',\n",
       "   'ocean',\n",
       "   'oceans',\n",
       "   'pacific ocean',\n",
       "   'pool',\n",
       "   'sea',\n",
       "   'seawater',\n",
       "   'shallow waters',\n",
       "   'underwater',\n",
       "   'upwelling',\n",
       "   'water',\n",
       "   'waters'}),\n",
       " (93, {'biologists', 'marine biologist', 'marine biologists', 'scientists'}),\n",
       " (94, {'direction', 'directions', 'towards'}),\n",
       " (95, {'bleach', 'tissue', 'tissues'}),\n",
       " (96, {'anchor', 'anchors'}),\n",
       " (97, {'factors', 'stress', 'stressors'}),\n",
       " (98, {'protect', 'protection', 'protects', 'vulnerable'}),\n",
       " (99, {'certain', 'ones', 'others', 'people', 'those'}),\n",
       " (100, {'shift', 'shifting', 'shifts'}),\n",
       " (101, {'balance', 'balanced', 'delicate balance'}),\n",
       " (102, {'leave', 'leaves', 'leaving', 'left'}),\n",
       " (103, {'read', 'reading', 'text'}),\n",
       " (104, {'pinhead', 'polyp', 'polyps'}),\n",
       " (105, {'extreme', 'mild', 'moderate', 'serious', 'severe'}),\n",
       " (106,\n",
       "  {'colder than',\n",
       "   'different types',\n",
       "   'different ways',\n",
       "   'higher than',\n",
       "   'more than',\n",
       "   'physical damage',\n",
       "   'reasons why',\n",
       "   'serious problem',\n",
       "   'shallow water',\n",
       "   'too much',\n",
       "   'very important'}),\n",
       " (107, {'especially', 'extremely', 'pretty', 'too', 'very'}),\n",
       " (108,\n",
       "  {'believe',\n",
       "   'clear',\n",
       "   'explain',\n",
       "   'figure',\n",
       "   'know',\n",
       "   'learned',\n",
       "   'look',\n",
       "   'matter',\n",
       "   'say',\n",
       "   'see',\n",
       "   'think'}),\n",
       " (109, {'become', 'becomes', 'becoming', 'been'}),\n",
       " (110, {'lack', 'looses', 'lose', 'loses', 'losing', 'loss', 'lost'}),\n",
       " (111,\n",
       "  {'anywhere', 'close', 'over', 'range', 'throughout', 'under', 'within'}),\n",
       " (112,\n",
       "  {'discovered',\n",
       "   'found',\n",
       "   'noticable',\n",
       "   'noticeable',\n",
       "   'noticed',\n",
       "   'observed',\n",
       "   'seen'}),\n",
       " (113, {'begin', 'end', 'finish', 'start', 'started', 'starts', 'stop'}),\n",
       " (114,\n",
       "  {'carbon',\n",
       "   'carbon dioxide',\n",
       "   'carbon dioxide co2',\n",
       "   'chemicals',\n",
       "   'co2',\n",
       "   'energy'}),\n",
       " (115, {'highest', 'low', 'lowest', 'per', 'weakest', 'worst'}),\n",
       " (116, {'differences', 'issue', 'messes', 'problem', 'problems'}),\n",
       " (117, {'disease', 'diseases', 'health'}),\n",
       " (118,\n",
       "  {'around',\n",
       "   'away',\n",
       "   'back',\n",
       "   'down',\n",
       "   'loose',\n",
       "   'off',\n",
       "   'out',\n",
       "   'through',\n",
       "   'together',\n",
       "   'up'}),\n",
       " (119, {'conclude', 'conclusion', 'results'}),\n",
       " (120, {'home', 'life', 'live', 'lives', 'living', 'population'}),\n",
       " (121,\n",
       "  {'enough',\n",
       "   'help',\n",
       "   'necessary',\n",
       "   'need',\n",
       "   'needed',\n",
       "   'needs',\n",
       "   'order',\n",
       "   'required',\n",
       "   'used'}),\n",
       " (122, {'being', 'had', 'having', 'who'})]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_lbl2cluster.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_clusters(lbl2cluster, synonyn_fname):\n",
    "    cluster_label = lambda lbl: \"cluster_\" + str(lbl)\n",
    "    \n",
    "    with open(synonyn_fname, \"w+\") as f:\n",
    "        for lbl, phrases in lbl2cluster.items():\n",
    "            # get top cluster label\n",
    "            for phrase in sorted(phrases):\n",
    "                f.write(\"%s=>%s\\n\" % (phrase, cluster_label(lbl)))\n",
    "\n",
    "write_clusters(ap_lbl2cluster, CLUSTER_SYN_FILE)\n",
    "syn_mapper = build_synonym_filter([CLUSTER_SYN_FILE], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_chain = [\n",
    "                  white_space_tokenize,\n",
    "                  remove_punct_at_end_filter,\n",
    "                  lower_case_filter,\n",
    "                  syn_mapper.map_synonyms,\n",
    "                  is_cluster_filter,\n",
    "                  remove_cluster_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay</th>\n",
       "      <th>Sent Number</th>\n",
       "      <th>Processed Sentence</th>\n",
       "      <th>Concept Codes</th>\n",
       "      <th>Clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05568.ann</td>\n",
       "      <td>1</td>\n",
       "      <td>What leads to differences in the rates of cora...</td>\n",
       "      <td>50</td>\n",
       "      <td>[1, 116, 32, 61, 76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05568.ann</td>\n",
       "      <td>2</td>\n",
       "      <td>Coral is often mistaken for a rock but it is m...</td>\n",
       "      <td></td>\n",
       "      <td>[104, 11, 21, 28, 30, 43, 46, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05568.ann</td>\n",
       "      <td>3</td>\n",
       "      <td>Coral bleaching shows bleaching and healthy bl...</td>\n",
       "      <td>50</td>\n",
       "      <td>[10, 117, 31, 45, 51, 52, 76, 98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05568.ann</td>\n",
       "      <td>4</td>\n",
       "      <td>Coral bleaching is almost noticeable in the pa...</td>\n",
       "      <td>50</td>\n",
       "      <td>[112, 76, 83, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>1</td>\n",
       "      <td>The part of coral called zooanthellae are not ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[28, 58, 62, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>2</td>\n",
       "      <td>And if they get or much sunlight they start to...</td>\n",
       "      <td>5,50,_C-&gt;R,_CRel,_RRel,Causer,Result,Causer:5,...</td>\n",
       "      <td>[110, 113, 58, 64, 82, 88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>3</td>\n",
       "      <td>The reason why is because the zooanthellae if ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[114, 118, 43, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>4</td>\n",
       "      <td>The coral also need INFREQUENT water temperatu...</td>\n",
       "      <td></td>\n",
       "      <td>[121, 60, 63, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>5</td>\n",
       "      <td>Also its a threats for us because means that m...</td>\n",
       "      <td>11</td>\n",
       "      <td>[105, 23, 26, 36, 53, 55, 57, 81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_AEKD_4_CB_ES-05572.ann</td>\n",
       "      <td>6</td>\n",
       "      <td>Also the water us getting to salty</td>\n",
       "      <td>13</td>\n",
       "      <td>[20, 82, 92]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Essay  Sent Number  \\\n",
       "0  EBA1415_AEKD_4_CB_ES-05568.ann            1   \n",
       "1  EBA1415_AEKD_4_CB_ES-05568.ann            2   \n",
       "2  EBA1415_AEKD_4_CB_ES-05568.ann            3   \n",
       "3  EBA1415_AEKD_4_CB_ES-05568.ann            4   \n",
       "4  EBA1415_AEKD_4_CB_ES-05572.ann            1   \n",
       "5  EBA1415_AEKD_4_CB_ES-05572.ann            2   \n",
       "6  EBA1415_AEKD_4_CB_ES-05572.ann            3   \n",
       "7  EBA1415_AEKD_4_CB_ES-05572.ann            4   \n",
       "8  EBA1415_AEKD_4_CB_ES-05572.ann            5   \n",
       "9  EBA1415_AEKD_4_CB_ES-05572.ann            6   \n",
       "\n",
       "                                  Processed Sentence  \\\n",
       "0  What leads to differences in the rates of cora...   \n",
       "1  Coral is often mistaken for a rock but it is m...   \n",
       "2  Coral bleaching shows bleaching and healthy bl...   \n",
       "3  Coral bleaching is almost noticeable in the pa...   \n",
       "4  The part of coral called zooanthellae are not ...   \n",
       "5  And if they get or much sunlight they start to...   \n",
       "6  The reason why is because the zooanthellae if ...   \n",
       "7  The coral also need INFREQUENT water temperatu...   \n",
       "8  Also its a threats for us because means that m...   \n",
       "9                 Also the water us getting to salty   \n",
       "\n",
       "                                       Concept Codes  \\\n",
       "0                                                 50   \n",
       "1                                                      \n",
       "2                                                 50   \n",
       "3                                                 50   \n",
       "4                                                  5   \n",
       "5  5,50,_C->R,_CRel,_RRel,Causer,Result,Causer:5,...   \n",
       "6                                                  4   \n",
       "7                                                      \n",
       "8                                                 11   \n",
       "9                                                 13   \n",
       "\n",
       "                            Clusters  \n",
       "0               [1, 116, 32, 61, 76]  \n",
       "1  [104, 11, 21, 28, 30, 43, 46, 47]  \n",
       "2  [10, 117, 31, 45, 51, 52, 76, 98]  \n",
       "3                  [112, 76, 83, 92]  \n",
       "4                   [28, 58, 62, 82]  \n",
       "5         [110, 113, 58, 64, 82, 88]  \n",
       "6                 [114, 118, 43, 82]  \n",
       "7                  [121, 60, 63, 92]  \n",
       "8  [105, 23, 26, 36, 53, 55, 57, 81]  \n",
       "9                       [20, 82, 92]  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def apply_cluster_extraction(s):\n",
    "    return sorted(analyze(s, analysis_chain))\n",
    "\n",
    "fname = \"/Users/simon.hughes/Google Drive/PhD/Data/CoralBleaching/Results/predictions_causal_and_codes.txt\"\n",
    "data = pd.read_csv(fname, sep=\"|\")\n",
    "data = data[[\"Essay\", \"Sent Number\", \"Processed Sentence\", \"Concept Codes\"]]\n",
    "data[\"Concept Codes\"] = data[\"Concept Codes\"].astype(str).apply(lambda s: \"\" if s == \"nan\" else s)\n",
    "    \n",
    "#data[\"Concept_Codes\"] = data[\"Concept Codes\"].apply(to_concepts_only)\n",
    "#del data[\"Concept Codes\"]\n",
    "data[\"Clusters\"] = data[\"Processed Sentence\"].apply(apply_cluster_extraction)\n",
    "#data[\"Num_Concept_Codes\"] = data[\"set_Concept_Codes\"].apply(lambda st: len(st))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '116', '32', '61', '76'],\n",
       "       ['104', '11', '21', '28', '30', '43', '46', '47'],\n",
       "       ['10', '117', '31', '45', '51', '52', '76', '98'],\n",
       "       ['112', '76', '83', '92'], ['28', '58', '62', '82']], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_tokens = data[\"Clusters\"].values\n",
    "cluster_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model. This could take a while (10-60 mins for moderate collections). Get a coffee\n",
      "Took 54.3845000267 seconds\n"
     ]
    }
   ],
   "source": [
    "import gensim, time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "NEW_MODEL_FILE = \"%s/word2vec_meta_model.w2v\" % ROOT_FOLDER\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Training Model. This could take a while (10-60 mins for moderate collections). Get a coffee\")\n",
    "model = Word2Vec(cluster_tokens, iter=100, size=100, window=5, min_count=5, workers=8, sample=1e-5, hs=0, negative=20)\n",
    "#model.save(NEW_MODEL_FILE)\n",
    "end = time.time()\n",
    "print \"Took %s seconds\" % (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body,skeleton,skeletons\n",
      "0.999792516232 \tabout,deeper,less,more,self,than\n",
      "0.999785363674 \tcalled,considered,known,recognized\n",
      "0.999779939651 \tbottom,chart,charts,graph,graphs,guide\n",
      "0.999778866768 \tlevel,levels,rate,rates\n",
      "0.999771237373 \taccording,said,says,stated,stressed\n",
      "\n",
      "lead,leading,leads\n",
      "0.999781906605 \tcarbon,carbon dioxide,carbon dioxide co2,chemicals,co2,energy\n",
      "0.999781250954 \tamerica,asia,atlantic,australia,pacific,versa\n",
      "0.999776124954 \tlimestone,rock,rocks,surface\n",
      "0.999773979187 \taround,away,back,down,loose,off,out,through,together,up\n",
      "0.999768018723 \tatlantic ocean,costal,equatorial,ocean,oceans,pacific ocean,pool,sea,seawater,shallow waters,underwater,upwelling,water,waters\n",
      "\n",
      "completely,drastically,greatly,overall\n",
      "0.99977850914 \tbelieve,clear,explain,figure,know,learned,look,matter,say,see,think\n",
      "0.999767959118 \taround,away,back,down,loose,off,out,through,together,up\n",
      "0.999761164188 \tbleached coral,bleaching coral,coral bleaching,coral reef,coral reefs,corals,marine,papua,reef,reefs,tropical\n",
      "0.999759793282 \tbad,better,good,hard,healthy,important,long,well\n",
      "0.999749779701 \textreme,mild,moderate,serious,severe\n",
      "\n",
      "above,double,high,higher,lower\n",
      "0.999762773514 \tbleach,tissue,tissues\n",
      "0.999760270119 \tbackground,bleached,bright,color,colorful,colors,red,white\n",
      "0.999754190445 \tanother,ever,every,least,most,one,only\n",
      "0.999753415585 \tabout,deeper,less,more,self,than\n",
      "0.999752879143 \talmost,although,even,fact,however,still,though\n",
      "\n",
      "movement,phenomena,phenomenon\n",
      "0.999749302864 \tafter,before,during,finally,instead,later,once,since,time,until,while,without\n",
      "0.999737083912 \tcalled,considered,known,recognized\n",
      "0.999733924866 \tbleached coral,bleaching coral,coral bleaching,coral reef,coral reefs,corals,marine,papua,reef,reefs,tropical\n",
      "0.999733448029 \tlevel,levels,rate,rates\n",
      "0.999733448029 \tbad,better,good,hard,healthy,important,long,well\n",
      "\n",
      "based,depend,depending,depends,relies,rely\n",
      "0.999712526798 \tmerchant,trades,trading\n",
      "0.999710083008 \tanother reason,another thing,another way,big problem,build up,cold water,every year,excessive rainfall,fresh water,get enough,go down,go through,goes up,high water,just north,know what,lower than,made up,many different,many things,most common,most dangerous,much more,north america,one place,one reason,one thing,one way,over time,papua new guinea,per year,reason why,salt water,sea level,south america,stay healthy,takes place,things like,trade winds,very serious,water levels,went up,worst ever,you look\n",
      "0.99970304966 \tbelieve,clear,explain,figure,know,learned,look,matter,say,see,think\n",
      "0.999695539474 \tbalance,balanced,delicate balance\n",
      "0.999692320824 \tlarge,size,small,tiny\n",
      "\n",
      "climate,conditions,enviroment,environment,nature\n",
      "0.99980199337 \tdegrees,heat,ocean salinity,salinity,temp,temperature,temperatures\n",
      "0.999786138535 \tany,did,do,does,done,eat,else,going,let,own,probably,right,seem,type,work,wrong,you\n",
      "0.999784350395 \tlittle,lot,lots,much\n",
      "0.999784052372 \thome,life,live,lives,living,population\n",
      "0.999782443047 \tanimal,animals,creatures,fish,food,human,humans\n",
      "\n",
      "plant,plants\n",
      "0.999765574932 \tdegrees,heat,ocean salinity,salinity,temp,temperature,temperatures\n",
      "0.999752283096 \tdecrease,decreased,decreases,decreasing,increase,increased,increases,increasing\n",
      "0.999750196934 \tatlantic ocean,costal,equatorial,ocean,oceans,pacific ocean,pool,sea,seawater,shallow waters,underwater,upwelling,water,waters\n",
      "0.999746978283 \tdie,dies,dying,kill,sick,starvation,starve\n",
      "0.999746382236 \talive,recover,survival,survive,sustain,thrive,undergo\n",
      "\n",
      "contains,covers,gives,helps,produces,provide,provided,provides\n",
      "0.999807953835 \tcalled,considered,known,recognized\n",
      "0.99978518486 \tlevel,levels,rate,rates\n",
      "0.999778151512 \tdisease,diseases,health\n",
      "0.999776959419 \talgae,colonies,coral polyp,coral polyps,h2o,invertebrate,invertebrate animals,stinging tentacles,zooxanthellae\n",
      "0.999772489071 \tbelieve,clear,explain,figure,know,learned,look,matter,say,see,think\n",
      "\n",
      "affect,affected,affecting,affects,effected,hurt,include,negatively,negatively affect,occur,weaken\n",
      "0.999829649925 \tespecially,extremely,pretty,too,very\n",
      "0.999827980995 \tanother reason,another thing,another way,big problem,build up,cold water,every year,excessive rainfall,fresh water,get enough,go down,go through,goes up,high water,just north,know what,lower than,made up,many different,many things,most common,most dangerous,much more,north america,one place,one reason,one thing,one way,over time,papua new guinea,per year,reason why,salt water,sea level,south america,stay healthy,takes place,things like,trade winds,very serious,water levels,went up,worst ever,you look\n",
      "0.99979352951 \tbad,better,good,hard,healthy,important,long,well\n",
      "0.999791443348 \thurricane,hurricanes,rain,rainfall,storm,storms,tradewinds,tropical storms,weather,wind\n",
      "0.999789655209 \tcalled,considered,known,recognized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, phrases in ap_lbl2cluster.items()[0:10]:\n",
    "    joined = \",\".join(sorted(phrases))\n",
    "    print joined.strip()\n",
    "    for lbl, sim in model.most_similar(positive=[str(key)], topn=5):\n",
    "        sim_cl = ap_lbl2cluster[int(lbl)]\n",
    "        \n",
    "        joined_2 = \",\".join(sorted(sim_cl))\n",
    "        print sim, \"\\t\" + joined_2\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix2clusterlbl = dict()\n",
    "vectors2 = []\n",
    "for key in model.vocab:\n",
    "    vec = get_vector(key, model)\n",
    "    ix = len(vectors2)\n",
    "    ix2clusterlbl[ix] = key\n",
    "    vectors2.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering vectors into clusters via AP\n",
      "Creating 15 clusters took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# don't parallelize (n_jobs = -1), doesn't seem to work\n",
    "print(\"Clustering vectors into clusters via AP\")\n",
    "ap_clusterer2 = AffinityPropagation()\n",
    "ap2_ids = ap_clusterer2.fit_predict(vectors2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Creating %i clusters took %i seconds\" % (len(set(ap2_ids)), end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ap2_clusters = extract_clusters(ap2_ids, ix2clusterlbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    about,above,algae,alot,anchor,anchors,animal,animals,any,begin,body,bring,cant,cold,colder,colonies,come,conclude,conclusion,cooler,coral polyp,coral polyps,creatures,deeper,did,do,does,done,double,eachother,eat,else,end,etc,f,factors,find,finish,fish,food,forced,get,gets,getting,going,got,h2o,high,higher,hotter,human,humans,int,invertebrate,invertebrate animals,lastly,less,let,lower,mean,meaning,means,more,normal,normally,now,o2,often,own,probably,process,recieve,results,right,seem,seems,self,skeleton,skeletons,sometimes,start,started,starts,stinging tentacles,stop,stress,stressors,tend,than,thats,therefore,threaten,threatened,threatens,type,upset,upsets,usually,warm,warmer,wich,work,world,worlds,worse,wrong,you,zooxanthellae\n",
      "\n",
      "1     case,cases\n",
      "\n",
      "10    bleach,colder than,different types,different ways,dragged,drop,dropped,dropping,drops,extreme,feed,glucose,higher than,home,keep,keeps,lack,life,limestone,live,lives,living,looses,lose,loses,losing,loss,lost,made,make,makes,making,mild,moderate,more than,natural,nutrient,nutrient rich,nutrients,oxygen,photosynthesis,physical damage,population,reasons why,rock,rocks,serious,serious problem,severe,shallow water,stay,sugar,sugars,surface,tissue,tissues,too much,very important\n",
      "\n",
      "1     leave,leaves,leaving,left\n",
      "\n",
      "11    able,boat,boats,called,cannot,considered,could,die,dies,differences,dying,eject,ejected,ejecting,ejection,ejects,eventually,everything,highest,inside,issue,itself,kill,known,likely,little,lot,lots,low,lowest,may,messes,might,much,must,navigation,nothing,outside,per,possible,possibly,problem,problems,recognized,should,sick,something,starvation,starve,stepping,surrounded,thing,things,walk,walking,ways,weakest,what,where,worst,would\n",
      "\n",
      "18    add,alive,america,anywhere,asia,atlantic,atlantic ocean,australia,background,become,becomes,becoming,been,benefit,benefits,bleached,blow,bottom,bright,build,certain,chart,charts,climate,close,color,colorful,colors,combine,conditions,costal,create,damage,damaged,damaging,dangerous,degrees,delicate,destructive,difference,disease,diseases,effect,effects,enviroment,environment,equatorial,event,events,form,formation,graph,graphs,guide,harm,harmful,health,heat,hot,impact,impacts,light,mouth,nature,negative,ocean,ocean salinity,oceans,ones,others,over,pacific,pacific ocean,people,plant,plants,pool,produce,range,recover,red,salinity,salt,salty,sea,seawater,sensitive,shallow,shallow waters,sun,sunlight,survival,survive,sustain,temp,temperature,temperatures,those,thrive,throughout,under,undergo,underwater,unhealthy,upwelling,versa,water,waters,white,within\n",
      "\n",
      "7     according,contains,covers,dead,death,deaths,died,especially,extremely,gives,helps,killed,killing,kills,level,levels,mistaken,movement,phenomena,phenomenon,pretty,produces,provide,provided,provides,rate,rates,said,says,shift,shifting,shifts,stated,stressed,too,very\n",
      "\n",
      "8     actually,always,basically,beautiful,being,carbon,carbon dioxide,carbon dioxide co2,chemicals,co2,comes,energy,go,goes,gone,had,happens,having,hurricane,hurricanes,just,like,maybe,my,occurs,our,part,puts,rain,rainfall,read,reading,really,report,reported,reporting,reports,so,storm,storms,takes,text,tourist,tourists,tradewinds,travel,tropical storms,way,we,weather,went,who,wind\n",
      "\n",
      "1     relationship,symbiotic,symbiotic relationship,tentacles\n",
      "\n",
      "1     pass,passage,passed,passes\n",
      "\n",
      "1     biologists,marine biologist,marine biologists,scientists\n",
      "\n",
      "1     play,plays,role\n",
      "\n",
      "31    affect,affected,affecting,affects,after,allow,almost,alter,altered,although,another,another reason,another thing,another way,area,areas,based,before,believe,big problem,bleached coral,bleaching coral,build up,central,change,changed,changes,changing,clear,climate change,cold water,common,coral bleaching,coral reef,coral reefs,corals,countries,danger,data,decrease,decreased,decreases,decreasing,depend,depending,depends,diameter,different,direction,directions,document,documents,drag,during,east,eastward,effected,enough,enviromental,environmental,even,ever,every,every year,example,examples,excessive rainfall,explain,fact,factor,figure,final,finally,first,foot,forces,fresh water,get enough,give,given,giving,go down,go through,goes up,help,high water,however,hurt,inches,include,increase,increased,increases,increasing,information,instead,just north,know,know what,land,large,last,later,learned,least,located,location,look,lower than,made up,mainly,many different,many things,marine,matter,merchant,most,most common,most dangerous,mostly,much more,near,necessary,need,needed,needs,negatively,negatively affect,new,next,north,north america,occur,once,one,one place,one reason,one thing,one way,only,order,originally,over time,papua,papua new guinea,partly,per year,pinhead,places,polyp,polyps,protect,protection,protects,purpose,put,reason,reason why,reasons,receive,reef,reefs,region,regions,relies,rely,required,reverse,risk,salt water,same,say,sea level,second,see,show,showed,shown,shows,side,since,size,small,source,south,south america,specific,states,stay healthy,still,strength,strong,take,takes place,things like,think,though,threat,threats,time,times,tiny,towards,trade winds,trades,trading,tropical,turn,turning,turns,types,unbalanced,until,used,varying,very serious,vulnerable,water levels,weak,weaken,weakened,weaker,went up,west,western,westward,while,why,without,worst ever,year,years,you look\n",
      "\n",
      "1     deal,move,moves,moving\n",
      "\n",
      "13    amount,amounts,around,article,articles,away,back,bad,balance,balanced,better,big,biggest,both,caused,circumstances,combination,completely,couple,delicate balance,discovered,down,drastically,due,estimate,few,found,good,greatly,grow,happen,happened,happening,hard,healthy,huge,important,lead,leading,leads,long,loose,main,major,many,massive,multiple,noticable,noticeable,noticed,number,observed,occured,occuring,off,out,overall,paragraph,place,result,resulted,resulting,rise,rises,rose,seen,several,sudden,swell,through,together,two,up,various,well\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, items in ap2_clusters.items():\n",
    "    words = set()\n",
    "    for lbl in items:\n",
    "        wds = ap_lbl2cluster[int(lbl)]\n",
    "        words.update(wds)\n",
    "    joined = \",\".join(sorted(words))\n",
    "    print str(len(items)).ljust(5), joined\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
