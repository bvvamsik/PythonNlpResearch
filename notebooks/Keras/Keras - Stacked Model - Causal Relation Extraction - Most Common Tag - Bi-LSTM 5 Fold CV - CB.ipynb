{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is based on this code: https://github.com/codekansas/keras-language-modeling/blob/master/keras_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Check mongo is running\n",
    "import pymongo\n",
    "client = pymongo.MongoClient()\n",
    "db = client.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Note - To Get this working:\n",
    "\n",
    "* Install CUDA and associated libraries, setup path\n",
    "* Install bleeding edge theano (from src)\n",
    "* Make sure the THEANO_FLAGS are set correctly via the environment var, or via the ~/.theanorc file\n",
    "* Install and compile bleeding edge Keras (from src)\n",
    "* `export KERAS_BACKEND=theano`\n",
    "* `export KERAS_IMAGE_DIM_ORDERING='th'`\n",
    "* `sh <project_root>/shell_scipts/setup_environment.sh` to install additional dependencies\n",
    "* **DO NOT SET UNROLL=True** when creating RNN's - causes max recursion issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trouble-Shooting\n",
    "\n",
    "* You may need to clean the theano cache. To do so thoroughly, run this command from the shell:\n",
    " * `theano-cache purge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import dill\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, TimeDistributedDense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from Metrics import rpf1\n",
    "from load_data import load_process_essays\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from IdGenerator import IdGenerator as idGen\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Rpfa import micro_rpfa\n",
    "from collections import defaultdict\n",
    "\n",
    "import Settings\n",
    "import logging\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from Settings import Settings\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/Bi-LSTM_Stacked/\"\n",
    "cv_folder = root_folder + \"CV_Data_Pickled/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "processor = ResultsProcessor()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "tagged_essays_tmp = load_process_essays(**config)\n",
    "\n",
    "with open(training_pickled, \"wb+\") as f:\n",
    "    pickle.dump(tagged_essays_tmp, f)\n",
    "del tagged_essays_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2017-04-30 22:14:47.483305\n"
     ]
    }
   ],
   "source": [
    "import datetime, logging\n",
    "print(\"Started at: \" + str(datetime.datetime.now()))\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "shuffle(tagged_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit()))\n",
    "cr_tags = list((t for t in tag_freq.keys() if ( \"->\" in t) and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "\n",
    "vtags = set(regular_tags)\n",
    "vtags.add(EMPTY_TAG)\n",
    "\n",
    "cr_vtags = set(cr_tags)\n",
    "cr_vtags.add(EMPTY_TAG)\n",
    "\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '5b',\n",
       " '6',\n",
       " '7',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:1->Result:11',\n",
       " 'Causer:1->Result:13',\n",
       " 'Causer:1->Result:14',\n",
       " 'Causer:1->Result:2',\n",
       " 'Causer:1->Result:3',\n",
       " 'Causer:1->Result:4',\n",
       " 'Causer:1->Result:5',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:1->Result:6',\n",
       " 'Causer:1->Result:7',\n",
       " 'Causer:11->Result:11',\n",
       " 'Causer:11->Result:12',\n",
       " 'Causer:11->Result:13',\n",
       " 'Causer:11->Result:14',\n",
       " 'Causer:11->Result:3',\n",
       " 'Causer:11->Result:4',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:11->Result:6',\n",
       " 'Causer:12->Result:11',\n",
       " 'Causer:12->Result:13',\n",
       " 'Causer:12->Result:14',\n",
       " 'Causer:12->Result:50',\n",
       " 'Causer:12->Result:5b',\n",
       " 'Causer:12->Result:7',\n",
       " 'Causer:13->Result:11',\n",
       " 'Causer:13->Result:12',\n",
       " 'Causer:13->Result:14',\n",
       " 'Causer:13->Result:4',\n",
       " 'Causer:13->Result:5',\n",
       " 'Causer:13->Result:50',\n",
       " 'Causer:13->Result:6',\n",
       " 'Causer:13->Result:7',\n",
       " 'Causer:14->Result:50',\n",
       " 'Causer:14->Result:6',\n",
       " 'Causer:14->Result:7',\n",
       " 'Causer:2->Result:1',\n",
       " 'Causer:2->Result:3',\n",
       " 'Causer:2->Result:50',\n",
       " 'Causer:2->Result:6',\n",
       " 'Causer:3->Result:1',\n",
       " 'Causer:3->Result:13',\n",
       " 'Causer:3->Result:14',\n",
       " 'Causer:3->Result:2',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:3->Result:50',\n",
       " 'Causer:3->Result:5b',\n",
       " 'Causer:3->Result:6',\n",
       " 'Causer:3->Result:7',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:4->Result:13',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:4->Result:3',\n",
       " 'Causer:4->Result:5',\n",
       " 'Causer:4->Result:50',\n",
       " 'Causer:4->Result:5b',\n",
       " 'Causer:4->Result:6',\n",
       " 'Causer:4->Result:7',\n",
       " 'Causer:5->Result:13',\n",
       " 'Causer:5->Result:14',\n",
       " 'Causer:5->Result:3',\n",
       " 'Causer:5->Result:4',\n",
       " 'Causer:5->Result:50',\n",
       " 'Causer:5->Result:5b',\n",
       " 'Causer:5->Result:7',\n",
       " 'Causer:50->Result:1',\n",
       " 'Causer:50->Result:3',\n",
       " 'Causer:50->Result:50',\n",
       " 'Causer:50->Result:7',\n",
       " 'Causer:5b->Result:14',\n",
       " 'Causer:5b->Result:5',\n",
       " 'Causer:5b->Result:50',\n",
       " 'Causer:5b->Result:7',\n",
       " 'Causer:6->Result:14',\n",
       " 'Causer:6->Result:50',\n",
       " 'Causer:6->Result:5b',\n",
       " 'Causer:6->Result:7',\n",
       " 'Causer:7->Result:14',\n",
       " 'Causer:7->Result:4',\n",
       " 'Causer:7->Result:5',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:7->Result:5b',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cr_vtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Transform Essays into Training Data (Word Ids)\n",
    "\n",
    "* Computes `xs`, `ys`, `ys_bytag` and `seq_lens`\n",
    "* `ys_bytag` includes **all tags** and does **not** focus only on the most common tag\n",
    "* `ys` only includes the most common tag (so we can use cross entropy)\n",
    "* `seq_lens` is without the start and end tags included (so we have to map back and forth to maintain mappings)\n",
    "* `ys_bytag` also excludes the START and END tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get Max Sequence Length, Generate All Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2tag = {}\n",
    "for ix, t in enumerate(vtags):\n",
    "    ix2tag[ix] = t\n",
    "\n",
    "ix2crtag = {}\n",
    "for ix, t in enumerate(cr_vtags):\n",
    "    ix2crtag[ix] = t\n",
    "    \n",
    "generator = idGen(seed=1) # important as we zero pad sequences\n",
    "\n",
    "maxlen = 0\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "\n",
    "def ids2tags(ids):\n",
    "    return [generator.get_key(j) for j in ids]\n",
    "\n",
    "def lbls2tags(ixs):\n",
    "    return [ix2tag[ix] for ix in ixs]\n",
    "        \n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "START = \"<start>\"\n",
    "END   = \"<end>\"\n",
    "\n",
    "def get_training_data(tessays):\n",
    "    # outputs\n",
    "    xs = []\n",
    "    ys = []\n",
    "    ys_bytag_concept_sent = defaultdict(list)\n",
    "    ys_bytag_cr_sent = defaultdict(list)\n",
    "    seq_lens = []\n",
    "\n",
    "    # cut texts after this number of words (among top max_features most common words)\n",
    "    for essay in tessays:\n",
    "        for sentence in essay.sentences:\n",
    "            row = []\n",
    "            y_found = False\n",
    "            y_seq = []\n",
    "            unique_tags = set() # get all unique tags in sentence\n",
    "            for word, tags in [(START, set())] + sentence + [(END, set())]:\n",
    "                id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "                row.append(id)                \n",
    "                unique_tags.update(tags)\n",
    "                \n",
    "                # remove unwanted tags, filter to concept tags\n",
    "                concept_tags = vtags.intersection(tags)\n",
    "\n",
    "                # encode ys with most common tag only\n",
    "                if len(concept_tags) > 1:\n",
    "                    most_common = max(concept_tags, key=lambda t: tag_freq[t])\n",
    "                    concept_tags = set([most_common])\n",
    "                if len(concept_tags) == 0:\n",
    "                    concept_tags.add(EMPTY_TAG)\n",
    "\n",
    "                one_hot = []\n",
    "                for t in vtags:\n",
    "                    if t in concept_tags:\n",
    "                        one_hot.append(1)\n",
    "                    else:\n",
    "                        one_hot.append(0)\n",
    "                y_seq.append(one_hot)\n",
    "                #end for each word\n",
    "            \n",
    "            # sentence level tags\n",
    "            for tag in vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_concept_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_concept_sent[tag].append(0)\n",
    "            \n",
    "            for tag in cr_vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_cr_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_cr_sent[tag].append(0)\n",
    "                \n",
    "            seq_lens.append(len(row)-2)\n",
    "            ys.append(y_seq)\n",
    "            xs.append(row)\n",
    "    \n",
    "    xs = sequence.pad_sequences(xs, maxlen=maxlen)\n",
    "    ys = sequence.pad_sequences(ys, maxlen=maxlen)\n",
    "    assert xs.shape[0] == ys.shape[0], \"Sequences should have the same number of rows\"\n",
    "    assert xs.shape[1] == ys.shape[1] == maxlen, \"Sequences should have the same lengths\"\n",
    "    return xs, ys, ys_bytag_concept_sent, ys_bytag_cr_sent, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        for pred_tag in pred_ys:\n",
    "            pred_ys_by_tag[pred_tag].append(1)\n",
    "            # for all other tags, a 0\n",
    "            for tag in(vtags - set([EMPTY_TAG, pred_tag])):\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results_sentence_level(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = set(pred_ys[1:-1])\n",
    "        for tag in vtags:\n",
    "            if tag == EMPTY_TAG:\n",
    "                continue\n",
    "            if tag in pred_ys:\n",
    "                pred_ys_by_tag[tag].append(1)\n",
    "            else:\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_dev_split(lst, dev_split):\n",
    "    # random shuffle\n",
    "    shuffle(lst)\n",
    "    num_training = int((1.0 - dev_split) * len(lst))\n",
    "    return lst[:num_training], lst[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.15 s, sys: 326 ms, total: 6.48 s\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this name for a different function later\n",
    "from CrossValidation import cross_validation as cv\n",
    "\n",
    "folds = cv(tagged_essays, CV_FOLDS)\n",
    "fold2training_data = {}\n",
    "fold2dev_data = {}\n",
    "fold2test_data = {}\n",
    "\n",
    "for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "    # further split into train and dev test\n",
    "    essays_train, essays_dev = train_dev_split(essays_TD, DEV_SPLIT)\n",
    "    fold2training_data[i] = get_training_data(essays_train)\n",
    "    fold2dev_data[i]      = get_training_data(essays_dev)\n",
    "    # Test Data\n",
    "    fold2test_data[i]     = get_training_data(essays_VD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(cv_folder + \"td.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_data, f)\n",
    "\n",
    "with open(cv_folder + \"devd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_data, f)\n",
    "\n",
    "with open(cv_folder + \"vd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Glove 100 Dim Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# see /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/DeepLearning/WordVectors/pickle_glove_embedding.py\n",
    "# for creating pre-filtered embeddings file\n",
    "import pickle, os\n",
    "from numpy.linalg import norm\n",
    "\n",
    "embeddings_file = \"/Users/simon.hughes/data/word_embeddings/glove.6B/cb_dict_glove.6B.100d.txt\"\n",
    "# read data file\n",
    "with open(embeddings_file, \"rb+\") as f:\n",
    "    cb_emb_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 1641 2.5 %\n"
     ]
    }
   ],
   "source": [
    "missed = set()\n",
    "for wd in unique_words:\n",
    "    if wd not in cb_emb_index:\n",
    "        missed.add(wd)\n",
    "print(len(missed), len(unique_words), 100.0 * round(len(missed)/  len(unique_words),4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = list(cb_emb_index.values())[0].shape[0]\n",
    "\n",
    "def get_embedding_matrix(words, idgenerator, max_features, init='uniform', unit_length=False):\n",
    "    embedding_dim = list(cb_emb_index.values())[0].shape[0]\n",
    "    # initialize with a uniform distribution\n",
    "    if init == 'uniform':\n",
    "        # NOTE: the max norms for these is quite low relative to the embeddings\n",
    "        embedding_matrix = np.random.uniform(low=-0.05, high=0.05,size=(max_features, embedding_dim))\n",
    "    elif init =='zeros':\n",
    "        embedding_matrix = np.zeros(shape=(max_features, embedding_dim), dtype=np.float32)\n",
    "    elif init == 'normal':\n",
    "        embedding_matrix = np.random.normal(mean, sd, size=(max_features, embedding_dim))\n",
    "    else:\n",
    "        raise Exception(\"Unknown init type\")\n",
    "    for word in words:\n",
    "        i = idgenerator.get_id(word)\n",
    "        embedding_vector = cb_emb_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    if unit_length:\n",
    "        norms = np.linalg.norm(embedding_matrix, axis=1,keepdims=True)\n",
    "        # remove 0 norms to prevent divide by zero\n",
    "        norms[norms == 0.0] = 1.0\n",
    "        embedding_matrix = embedding_matrix / norms\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score_predictions(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict_classes(xs, batch_size=batch_size, verbose=0)   \n",
    "    pred_ys_by_tag = collapse_results_sentence_level(seq_len, preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-04-30 15:52:05.840624', '20170430_155205_840656')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from datetime import datetime\n",
    "\n",
    "def get_ts():\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "def get_file_ts():\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "\n",
    "embedding_size = EMBEDDING_DIM\n",
    "hidden_size    = 128\n",
    "out_size = len(vtags)\n",
    "batch_size = 128\n",
    "\n",
    "get_ts(), get_file_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Bi-Directional LSTM With Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/layers/core.py:1206: UserWarning: `TimeDistributedDense` is deprecated, And will be removed on May 1st, 2017. Please use a `Dense` layer instead.\n",
      "  warnings.warn('`TimeDistributedDense` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "merge_mode = \"sum\"\n",
    "if True:\n",
    "        embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "        embedding_layer = Embedding(max_features,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=maxlen,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "else:\n",
    "    embedding_layer = Embedding(max_features, embedding_size, input_length=maxlen, trainable=True, mask_zero=True)\n",
    "\n",
    "if True:\n",
    "    rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "else:\n",
    "    rnn_layer_fact = lambda : GRU(hidden_size, return_sequences=True, consume_less=\"cpu\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "for i in range(1):\n",
    "    model.add(rnn_layer_fact())\n",
    "\n",
    "model.add(TimeDistributedDense(out_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fold_ix-0_bi_directional-True_hidden_size-128_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    lcls = locals()\n",
    "    s = \"\"\n",
    "    for k, val in sorted(lcls.items(), key = lambda tpl: (0,tpl[0]) if tpl[0] == 'fold_ix' else (1,tpl[0])):\n",
    "        s += \"{key}-{val}_\".format(key=k, val=str(val))\n",
    "    return models_folder + s[:-1] + \".h5\"\n",
    "\n",
    "get_file_name(0, True, True, 2, merge_mode, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_features=len(generator.get_ids())+2 #Need plus one maybe due to masking of sequences\n",
    "\n",
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_fold(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "\n",
    "    if use_pretrained_embedding:\n",
    "        embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "        embedding_layer = Embedding(max_features,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=maxlen,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    else:\n",
    "        embedding_layer = Embedding(max_features, embedding_size, input_length=maxlen, trainable=True, mask_zero=True)\n",
    "\n",
    "    if bi_directional:\n",
    "        rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "    else:\n",
    "        rnn_layer_fact = lambda : GRU(hidden_size, return_sequences=True, consume_less=\"cpu\")\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    X_train, y_train, train_ys_bytag_con_sent, train_ys_by_tag_cr_sent, seq_len_train = fold2training_data[fold_ix]\n",
    "    X_dev,   y_dev,   dev_ys_bytag_con_sent,   dev_ys_by_tag_cr_sent,   seq_len_dev   = fold2dev_data[fold_ix]\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  test_ys_by_tag_cr_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    #for i in range(30):\n",
    "    for i in range(2):\n",
    "        #print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        epochs = 1 # epochs per training instance\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        #print(micro_metrics)\n",
    "        #print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fold2model = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = evaluate_fold(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        fname = get_file_name(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        model.save(fname)    \n",
    "        fold2model[i] = model\n",
    "    return fold2model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Params 2017-04-30 22:13:15.844970 - Embeddings=True, Bi-Direct=True Num_Rnns=1 Hidden_Size=64\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1643 is out of bounds for size 1643\nApply node that caused the error: AdvancedSubtensor1(embedding_10_W, Reshape{1}.0)\nToposort index: 58\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(1643, 100), (11904,)]\nInputs strides: [(400, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 5]\nOutputs clients: [[Reshape{2}(AdvancedSubtensor1.0, TensorConstant{[ -1 100]})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-100-a1d6c1fa6b85>\", line 23, in evaluate_fold\n    model.add(embedding_layer)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/models.py\", line 299, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 401, in create_input_layer\n    self(x)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/backend/theano_backend.py\", line 306, in gather\n    return reference[indices]\n\nDebugprint of the apply node: \nAdvancedSubtensor1 [id A] <TensorType(float32, matrix)> ''   \n |embedding_10_W [id B] <TensorType(float32, matrix)>\n |Reshape{1} [id C] <TensorType(int32, vector)> ''   \n   |embedding_input_18 [id D] <TensorType(int32, matrix)>\n   |TensorConstant{(1,) of -1} [id E] <TensorType(int64, (True,))>\n\nStorage map footprint:\n - activation_9_target, Input, Shape: (128, 93, 14), ElemSize: 4 Byte(s), TotalSize: 666624 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - embedding_10_W, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - Reshape{1}.0, Shape: (11904,), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - Elemwise{Cast{float32}}.0, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - embedding_input_18, Input, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - activation_9_sample_weights, Input, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_h, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_h, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_z, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_r, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_r, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_z, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_z, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_r, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_h, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_z, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_r, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_h, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - Elemwise{neq,no_inplace}.0, Shape: (128, 93), ElemSize: 1 Byte(s), TotalSize: 11904 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - timedistributeddense_9_W, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_r, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_h, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_r, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_h, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_z, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_z, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - timedistributeddense_9_b, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - TensorConstant{[-1 93 64]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(3,) of 64}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[-1 93 14]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[-1 64]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[64 -1]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ -1 100]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{93}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{5952}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{192}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{92}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{100}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-94}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 1e-08}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of -1.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of inf}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 1e-08}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Subtensor{int64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Subtensor{int64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of inf}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of -1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 0.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Sum{acc_dtype=float64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{inf}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Sum{acc_dtype=float64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 1e-07}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 0.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.20000000298023224}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of 0}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{(1, 1) of 1}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 3564600.0 Byte(s) 0.003 GB\n TotalSize inputs: 3505048.0 Byte(s) 0.003 GB\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1643 is out of bounds for size 1643",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-19f236570745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\u001b[0m                          \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pretrained_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_pretrained_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_directional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbi_directional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mfold2model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_pretrained_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_directional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0;31m#print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-24d8eba8191a>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfold2model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pretrained_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_directional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_pretrained_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_directional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-a1d6c1fa6b85>\u001b[0m in \u001b[0;36mevaluate_fold\u001b[0;34m(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# epochs per training instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mmicro_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ys_bytag_con_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1643 is out of bounds for size 1643\nApply node that caused the error: AdvancedSubtensor1(embedding_10_W, Reshape{1}.0)\nToposort index: 58\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(1643, 100), (11904,)]\nInputs strides: [(400, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: [11, 5]\nOutputs clients: [[Reshape{2}(AdvancedSubtensor1.0, TensorConstant{[ -1 100]})]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"<ipython-input-100-a1d6c1fa6b85>\", line 23, in evaluate_fold\n    model.add(embedding_layer)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/models.py\", line 299, in add\n    layer.create_input_layer(batch_input_shape, input_dtype)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 401, in create_input_layer\n    self(x)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/Users/simon.hughes/anaconda3/envs/keras_and_theano_bleeding_edge/lib/python3.5/site-packages/keras/backend/theano_backend.py\", line 306, in gather\n    return reference[indices]\n\nDebugprint of the apply node: \nAdvancedSubtensor1 [id A] <TensorType(float32, matrix)> ''   \n |embedding_10_W [id B] <TensorType(float32, matrix)>\n |Reshape{1} [id C] <TensorType(int32, vector)> ''   \n   |embedding_input_18 [id D] <TensorType(int32, matrix)>\n   |TensorConstant{(1,) of -1} [id E] <TensorType(int64, (True,))>\n\nStorage map footprint:\n - activation_9_target, Input, Shape: (128, 93, 14), ElemSize: 4 Byte(s), TotalSize: 666624 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - embedding_10_W, Shared Input, Shape: (1643, 100), ElemSize: 4 Byte(s), TotalSize: 657200 Byte(s)\n - Reshape{1}.0, Shape: (11904,), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - Elemwise{Cast{float32}}.0, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - embedding_input_18, Input, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - activation_9_sample_weights, Input, Shape: (128, 93), ElemSize: 4 Byte(s), TotalSize: 47616 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_h, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_h, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_z, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - forward_gru_10_W_r, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_r, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - backward_gru_10_W_z, Shared Input, Shape: (100, 64), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_z, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_r, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - backward_gru_10_U_h, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_z, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_r, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - forward_gru_10_U_h, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 64), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - Elemwise{neq,no_inplace}.0, Shape: (128, 93), ElemSize: 1 Byte(s), TotalSize: 11904 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - <TensorType(float32, matrix)>, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - timedistributeddense_9_W, Shared Input, Shape: (64, 14), ElemSize: 4 Byte(s), TotalSize: 3584 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_r, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_h, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_r, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_h, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - forward_gru_10_b_z, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - backward_gru_10_b_z, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - <TensorType(float32, vector)>, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - timedistributeddense_9_b, Shared Input, Shape: (14,), ElemSize: 4 Byte(s), TotalSize: 56 Byte(s)\n - TensorConstant{[-1 93 64]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(3,) of 64}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[-1 93 14]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[-1 64]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[64 -1]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{[ -1 100]}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{93}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{5952}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{192}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{92}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{100}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-94}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{64}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{128}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of 1e-08}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of -1.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1,) of inf}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 1e-08}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Subtensor{int64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Subtensor{int64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of inf}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of -1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 0.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Sum{acc_dtype=float64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{inf}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Sum{acc_dtype=float64}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 0.5}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 1e-07}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - InplaceDimShuffle{x,x,x}.0, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{(1, 1) of 0.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1,) of 0.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.20000000298023224}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of 0}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{(1, 1) of 1}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{64}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 3564600.0 Byte(s) 0.003 GB\n TotalSize inputs: 3505048.0 Byte(s) 0.003 GB\n\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "i = 0\n",
    "for use_pretrained_embedding in [True]:\n",
    "    for bi_directional in [True]:\n",
    "        for num_rnns in [1]:\n",
    "            for merge_mode in [\"sum\"]:\n",
    "                for hidden_size in [64]:\n",
    "\n",
    "                    i += 1\n",
    "                    print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "                          .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))\n",
    "                    fold2model = cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "                    #print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fname = get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return keras.models.load_model(fname)\n",
    "\n",
    "def load_models(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    models_by_fold = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = load_model(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        models_by_fold[i] = model\n",
    "    return models_by_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicts_by_fold = {}\n",
    "for fold_ix in range(CV_FOLDS):\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  test_ys_by_tag_cr_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "    model = models_by_fold[fold_ix]\n",
    "    probs = model.predict_proba(X_test)\n",
    "    predicts_by_fold[fold_ix] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold_ix = 0\n",
    "\n",
    "probs = predicts_by_fold[fold_ix]\n",
    "xs = []\n",
    "for i in range(len(probs)):\n",
    "    preds = probs[i,:]\n",
    "    #print(preds.shape)\n",
    "    #ix2tag\n",
    "    max_preds = np.max(preds, axis=0)\n",
    "    min_preds = np.max(preds, axis=0)\n",
    "    predicted_ixs = set(np.argwhere(max_preds > 0.5).flatten())\n",
    "    binary = [0] * len(max_preds)\n",
    "    for ix in predicted_ixs:\n",
    "        binary[ix] = 1\n",
    "    x = max_preds.tolist() + min_preds.tolist() + binary\n",
    "\n",
    "    # combination tags\n",
    "    ixs = ix2tag.keys()\n",
    "    for a in ixs:\n",
    "        for b in ixs:\n",
    "            if b < a:\n",
    "                if a in predicted_ixs and b in predicted_ixs:\n",
    "                    x.append(1)\n",
    "                else:\n",
    "                    x.append(0)\n",
    "    xs.append(x)\n",
    "return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TODO\n",
    "* Use early stopping criteria\n",
    "* Embeddings:\n",
    " * Don't remove low frequency words\n",
    " * Normalize all vector lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
