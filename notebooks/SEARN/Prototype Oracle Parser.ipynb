{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack(object):\n",
    "    def __init__(self, verbose=False):    \n",
    "        self.stack = []\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def tos(self):\n",
    "        if self.len() == 0:\n",
    "            return None\n",
    "        #assert self.len() > 0, \"Can't peek when stack is empty\"\n",
    "        return self.stack[-1]\n",
    "    \n",
    "    def pop(self):\n",
    "        assert self.len() > 0, \"Can't pop when stack is empty\"\n",
    "        item = self.stack.pop()\n",
    "        if self.verbose:\n",
    "            print(\"POPPING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "        return item\n",
    "    \n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "        if self.verbose:\n",
    "            print(\"PUSHING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.stack)\n",
    "\n",
    "    def contains(self, item):\n",
    "        return item in self.stack\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"|\".join(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = \"root\"\n",
    "\n",
    "def norm_arc(arc):\n",
    "    return tuple(sorted(arc))\n",
    "\n",
    "def norm_arcs(arcs):\n",
    "    return set(map(norm_arc, arcs))\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self, stack):\n",
    "        self.stack = stack\n",
    "        self.arcs = []\n",
    "        self.normed_arcs = set()\n",
    "        # nodes with heads\n",
    "        self.children = set()\n",
    "        self.actions = []\n",
    "\n",
    "    def get_dependencies(self):\n",
    "        return [(l, r) for (l, r) in self.arcs if r != ROOT and l != ROOT]\n",
    "\n",
    "    def left_arc(self, buffer):\n",
    "        tos = self.stack.pop()\n",
    "        # Pre-condition\n",
    "        # assert self.has_head(tos) == False\n",
    "        arc = (tos, buffer)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % str(n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(arc)\n",
    "        self.children.add(tos)\n",
    "        self.actions.append(\"L ARC   : \" + tos + \"->\" + buffer)\n",
    "\n",
    "    def right_arc(self, buffer):\n",
    "        tos = self.stack.tos()\n",
    "        # normalize arc\n",
    "        arc = (buffer, tos)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % str(n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(n_arc)\n",
    "        self.actions.append(\"R ARC   : \" + tos + \"<-\" + buffer)\n",
    "        self.children.add(buffer)\n",
    "        self.stack.push(buffer)\n",
    "\n",
    "    def reduce(self):\n",
    "        tos = self.stack.pop()\n",
    "        # assert self.has_head(tos) == True\n",
    "        self.actions.append(\"REDUCE  : Pop  %s\" % tos)\n",
    "\n",
    "    def shift(self, buffer):\n",
    "        self.stack.push(buffer)\n",
    "        self.actions.append(\"SHIFT   : Push %s\" % buffer)\n",
    "\n",
    "    def skip(self, buffer):\n",
    "        self.actions.append(\"SKIP    : item %s\" % buffer)\n",
    "\n",
    "    def has_head(self, item):\n",
    "        return item in self.children\n",
    "\n",
    "    def in_stack(self, item):\n",
    "        return self.stack.contains(item)\n",
    "\n",
    "    def clone(self):\n",
    "        cloney = Parser(self.stack.clone())\n",
    "        cloney.arcs = list(self.arcs)\n",
    "        cloney.normed_arcs = set(self.normed_arcs)\n",
    "        # nodes with heads\n",
    "        cloney.children = set(self.children)\n",
    "        cloney.actions = list(self.actions)\n",
    "        return cloney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SHIFT = \"Shift\"\n",
    "REDUCE = \"Reduce\"\n",
    "LARC = \"LArc\"\n",
    "RARC = \"Rarc\"\n",
    "SKIP = \"Skip\"\n",
    "\n",
    "class Oracle(object):\n",
    "    def __init__(self, crels, parser):\n",
    "        self.parser = parser\n",
    "        self.raw_crels = crels\n",
    "        self.crels = norm_arcs(crels)  # type: Set[Tuple[str,str]]\n",
    "        self.mapping = self.build_mappings(crels)\n",
    "\n",
    "    def build_mappings(self, pairs):\n",
    "        mapping = defaultdict(set)\n",
    "        for c, res in pairs:\n",
    "            mapping[c].add(res)\n",
    "            mapping[res].add(c)\n",
    "        return mapping\n",
    "\n",
    "    def should_continue(self, action):\n",
    "        # continue parsing if REDUCE or LARC\n",
    "        return action in (REDUCE, LARC)\n",
    "\n",
    "    def remove_relation(self, a, b):\n",
    "        # as we can force it to execute actions that are invalid, we have to see if this is a valid relation to remove\n",
    "        if a in self.mapping and b in self.mapping[a]:\n",
    "            self.mapping[a].remove(b)\n",
    "            if len(self.mapping[a]) == 0:\n",
    "                del self.mapping[a]\n",
    "            self.mapping[b].remove(a)\n",
    "            if len(self.mapping[b]) == 0:\n",
    "                del self.mapping[b]\n",
    "\n",
    "    def consult(self, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        parser = self.parser\n",
    "        a, b = norm_arc((tos, buffer))\n",
    "        if (a, b) in self.crels:\n",
    "            # TOS has arcs remaining? If so, we need RARC, else LARC\n",
    "            if len(self.mapping[tos]) == 1:\n",
    "                return LARC\n",
    "            else:\n",
    "                return RARC\n",
    "        else:\n",
    "            if buffer not in self.mapping:\n",
    "                return SKIP\n",
    "            # If the buffer has relations further down in the stack, we need to POP the TOS\n",
    "            for item in self.mapping[buffer]:\n",
    "                if item == tos:\n",
    "                    continue\n",
    "                if parser.in_stack(item):\n",
    "                    return REDUCE\n",
    "            # end for\n",
    "            # ELSE\n",
    "            return SHIFT\n",
    "\n",
    "    def execute(self, action, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        parser = self.parser\n",
    "        if action == LARC:\n",
    "            parser.left_arc(buffer)\n",
    "            self.remove_relation(tos, buffer)\n",
    "        elif action == RARC:\n",
    "            parser.right_arc(buffer)\n",
    "            self.remove_relation(tos, buffer)\n",
    "        elif action == REDUCE:\n",
    "            parser.reduce()\n",
    "        elif action == SHIFT:\n",
    "            parser.shift(buffer)\n",
    "        elif action == SKIP:\n",
    "            parser.skip(buffer)\n",
    "        else:\n",
    "            raise Exception(\"Unknown parsing action %s\" % action)\n",
    "        return self.should_continue(action)\n",
    "\n",
    "    def tos(self):\n",
    "        return self.parser.stack.tos()\n",
    "\n",
    "    def is_stack_empty(self):\n",
    "        return self.parser.stack.len() == 0\n",
    "\n",
    "    def clone(self):\n",
    "        cloney = Oracle(set(self.raw_crels), self.parser.clone())\n",
    "        # Need to ensure a deep clone of the mappings dict\n",
    "        cloney.mapping = defaultdict(set)\n",
    "        for key, set_vals in self.mapping.items():\n",
    "            cloney.mapping[key].update(set_vals)\n",
    "        return cloney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_oracle(codes, crels, orcl_fact, verbose=False):\n",
    "    \n",
    "    crels = set(crels)\n",
    "    if verbose:\n",
    "        prn_fun = lambda s=\"\": print(s)\n",
    "    else:\n",
    "        prn_fun = lambda s=\"\": None\n",
    "    \n",
    "    stack = Stack(False)\n",
    "    stack.push(ROOT)\n",
    "    parser = Parser(stack)\n",
    "    oracle = orcl_fact(crels, parser)\n",
    "\n",
    "    prn_fun(\"DEPS\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun()\n",
    "\n",
    "    PAD = 20\n",
    "    LINE = PAD + len(ROOT) + 2 * len(codes) + 1\n",
    "\n",
    "    for buffer in codes:\n",
    "        prn_fun(\"-\" * LINE)\n",
    "        prn_fun(buffer)\n",
    "        prn_fun(\"-\" * LINE)\n",
    "\n",
    "        while True:\n",
    "            tos = stack.tos()\n",
    "            action = oracle.consult(tos, buffer)\n",
    "            if not oracle.execute(action, tos, buffer):\n",
    "                prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "                break\n",
    "\n",
    "            prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "            if stack.len() == 0:\n",
    "                prn_fun(\"Empty stack, stopping\")\n",
    "                break\n",
    "\n",
    "    prn_fun()\n",
    "    prn_fun(\"*\" * LINE)\n",
    "    prn_fun(\"Stack\")\n",
    "    prn_fun(\"\\t\" + str(stack))\n",
    "    deps = parser.get_dependencies()\n",
    "    prn_fun(\"DEPS Actual\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun(\"DEPS Pred\")\n",
    "    for dep in sorted(deps):\n",
    "        prn_fun(\"\\t\" + str(dep))\n",
    "    prn_fun(\"Actions\")\n",
    "    for a in parser.actions:\n",
    "        prn_fun(\"\\t\" + a)\n",
    "    prn_fun()\n",
    "    prn_fun(\"Ordered Match?    \" + str(set(deps) == crels))\n",
    "\n",
    "    ndeps = norm_arcs(deps)\n",
    "    ncrels = norm_arcs(crels)\n",
    "    diff = (ndeps - ncrels).union(ncrels - ndeps)\n",
    "    success = (len(diff) == 0)\n",
    "    prn_fun(\"Un Ordered Match? \" + str(success))\n",
    "    if diff:\n",
    "        prn_fun(diff)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = []\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "#C->B->A\n",
    "test_pairs.append([\n",
    "    (\"C\",\"B\"),\n",
    "    (\"B\",\"A\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"C\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "    (\"C\",\"B\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"B\",\"A\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"C\"),\n",
    "    (\"C\",\"B\"),\n",
    "])\n",
    "\n",
    "# Hard - has to flip relation\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"D\",\"A\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"D\",\"A\"),\n",
    "    (\"B\",\"D\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"E\"),\n",
    "    (\"E\",\"B\"),\n",
    "    (\"B\",\"D\"),\n",
    "    (\"D\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"A\", \"F\"),\n",
    "    (\"A\", \"E\"),\n",
    "])\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"A\", \"F\"),\n",
    "    (\"E\", \"F\"),\n",
    "])\n",
    "\n",
    "oracle_fact = Oracle\n",
    "for pairs in test_pairs:\n",
    "    try:\n",
    "        success = test_oracle(\"ABCDEF\", pairs, oracle_fact, verbose=False)\n",
    "    except:\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        print(\"Error for relations:\")\n",
    "        pprint(pairs)\n",
    "        print()\n",
    "        success = test_oracle(\"ABCDEF\", pairs, oracle_fact, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Parse for Tricker Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Doesn't Handle Cycles</span>\n",
    "- So we remove the condition about only having a single parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "\t('C', 'A')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "R ARC   : A<-B       || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "L ARC   : B->C       || STACK : root|A\n",
      "L ARC   : A->C       || STACK : root\n",
      "L ARC   : A->C       || STACK : root\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "L ARC   : A->C       || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "L ARC   : A->C       || STACK : root\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "L ARC   : A->C       || STACK : root\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "\t('C', 'A')\n",
      "DEPS Pred\n",
      "\t('A', 'C')\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tR ARC   : A<-B\n",
      "\tL ARC   : B->C\n",
      "\tL ARC   : A->C\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[('1', '3'), ('1', '50'), ('3', '50')]\n",
    "#['50', '1', '3']\n",
    "pairs =[\n",
    "    (\"B\",\"A\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"C\",\"A\"),\n",
    "]\n",
    "test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'D')\n",
      "\t('B', 'C')\n",
      "\t('D', 'B')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "SHIFT   : Push B     || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "R ARC   : B<-C       || STACK : root|A|B|C\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "REDUCE  : Pop  C     || STACK : root|A|B\n",
      "L ARC   : B->D       || STACK : root|A\n",
      "L ARC   : A->D       || STACK : root\n",
      "L ARC   : A->D       || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "L ARC   : A->D       || STACK : root\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "L ARC   : A->D       || STACK : root\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('A', 'D')\n",
      "\t('B', 'C')\n",
      "\t('D', 'B')\n",
      "DEPS Pred\n",
      "\t('A', 'D')\n",
      "\t('B', 'D')\n",
      "\t('C', 'B')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tSHIFT   : Push B\n",
      "\tR ARC   : B<-C\n",
      "\tREDUCE  : Pop  C\n",
      "\tL ARC   : B->D\n",
      "\tL ARC   : A->D\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs =[\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "]\n",
    "test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Projective Parse Should Fail Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'C')\n",
      "\t('B', 'E')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "SHIFT   : Push B     || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "REDUCE  : Pop  B     || STACK : root|A\n",
      "L ARC   : A->C       || STACK : root\n",
      "L ARC   : A->C       || STACK : root\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "L ARC   : A->C       || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "SHIFT   : Push E     || STACK : root|E\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "SHIFT   : Push E     || STACK : root|E\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot|E\n",
      "DEPS Actual\n",
      "\t('A', 'C')\n",
      "\t('B', 'E')\n",
      "DEPS Pred\n",
      "\t('A', 'C')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tSHIFT   : Push B\n",
      "\tREDUCE  : Pop  B\n",
      "\tL ARC   : A->C\n",
      "\tSHIFT   : Push E\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? False\n",
      "{('B', 'E')}\n"
     ]
    }
   ],
   "source": [
    "pairs =[\n",
    "    (\"A\",\"C\"),\n",
    "    (\"B\",\"E\"),\n",
    "]\n",
    "try:\n",
    "    success = test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)\n",
    "except Exception as e:\n",
    "    success = False\n",
    "    raise e\n",
    "assert success == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on Real Causal Relations (Limit to 2 or More Relations in a Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(code):\n",
    "    return code.replace(\"Causer:\",\"\").replace(\"Result:\",\"\")\n",
    "\n",
    "def normalize_cr(cr):\n",
    "    return tuple(normalize(cr).split(\"->\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('14', '50')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(\"Causer:14\"),normalize(\"Result:50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('14', '50')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_cr('Causer:14->Result:50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "training_pickled = \"/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "#TODO - don't ignore Anaphor, other and rhetoricals here\n",
    "cr_tags  = list((t for t in tag_freq.keys() if ( \"->\" in t) and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "reg_tags = set((t for t in tag_freq.keys() if ( \"->\" not in t) and (t == \"explicit\" or t[0].isdigit())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8292, 2217, 3006)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "relations = []\n",
    "unq_cr_tags = set(cr_tags)\n",
    "skipped_sent = 0\n",
    "skipped_crels = 0\n",
    "num_sents = 0\n",
    "num_csl = 0\n",
    "\n",
    "diffs = []\n",
    "for essay_ix, essay in enumerate(tagged_essays):\n",
    "    for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "        num_sents += 1\n",
    "        tag_seq = []\n",
    "        un_tags = set()\n",
    "        un_csl  = set()\n",
    "        crel2tags = defaultdict(set)\n",
    "\n",
    "        def add_tag(tag, crel):\n",
    "            un_tags.add(tag)\n",
    "            crel2tags[crel].add(tag)\n",
    "        \n",
    "        has_causal = False\n",
    "        last_tag = None\n",
    "        for i, (wd,tags) in enumerate(taggged_sentence):\n",
    "            rtags = set([normalize(t) for t in tags])\n",
    "            rtags = rtags.intersection(reg_tags)\n",
    "            # Get tag seq\n",
    "            tag = None\n",
    "            if rtags:\n",
    "                tag = max(rtags, key = lambda t: tag_freq[t])\n",
    "                if tag != last_tag and (not tag_seq or tag_seq[-1] != tag):\n",
    "                    tag_seq.append(tag)\n",
    "            last_tag = tag\n",
    "            \n",
    "            csl = unq_cr_tags.intersection(tags)\n",
    "            if not csl:\n",
    "                continue\n",
    "            has_causal = True\n",
    "            for crel in csl:\n",
    "                un_csl.add(crel)\n",
    "                l_causer, r_effect = crel.split(\"->\")\n",
    "                l,r = normalize_cr(crel)\n",
    "                if l_causer in tags:\n",
    "                    add_tag(l, crel)\n",
    "                if r_effect in tags:\n",
    "                    add_tag(r, crel)                \n",
    "                if l in tags:\n",
    "                    add_tag(l, crel)\n",
    "                if r in tags:\n",
    "                    add_tag(r, crel)\n",
    "                    \n",
    "        \n",
    "        num_csl += len(un_csl)\n",
    "        # Don't count sentences without any relations as skipped\n",
    "        if has_causal:        \n",
    "            supported_causal = set()\n",
    "            supported_codes = set()\n",
    "            for crel, tags in crel2tags.items():\n",
    "                if len(tags) < 2:\n",
    "                    l,r = normalize_cr(crel)\n",
    "                    # if l == r then we want to keep these\n",
    "                    if l != r or len(tags) == 0:\n",
    "                        skipped_crels += 1\n",
    "                        continue\n",
    "                supported_causal.add(crel)\n",
    "                supported_codes.update(tags)\n",
    "\n",
    "            if not supported_causal:\n",
    "                skipped_sent += 1\n",
    "                continue\n",
    "            # filter out any tags that were only part of unsupported causal relations\n",
    "            #tag_seq = [tag for tag in tag_seq if tag in supported_codes]\n",
    "            relations.append((essay_ix,sent_ix,supported_causal,tag_seq))\n",
    "            \n",
    "            if len(supported_causal) != len(un_csl):\n",
    "                diffs.append((essay_ix, sent_ix, un_csl, supported_causal))\n",
    "        else:\n",
    "            if un_csl:\n",
    "                diffs.append((essay_ix, sent_ix, un_csl, set()))\n",
    "        \n",
    "num_sents, len(relations), num_csl #skipped_sent, skipped_crels, \n",
    "#(8292, 2217, 3006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7375249500998003"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2217/3006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Unsupported Relations, are the Missing Tags in the Previous or Subsequent Sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Causer:4->Result:14', 'Causer:3->Result:4'}\n",
      "{'Causer:4->Result:14'}\n",
      "the                  []\n",
      "amount               ['4']\n",
      "of                   ['4']\n",
      "co2                  ['4']\n",
      "can                  []\n",
      "threaten             ['14']\n",
      "the                  ['14']\n",
      "health               ['14']\n",
      "of                   ['14']\n",
      "the                  ['14']\n",
      "coral                ['14']\n",
      ".                    []\n",
      "--Previous--\n",
      "as                   []\n",
      "the                  []\n",
      "temperature          ['3']\n",
      "of                   ['3']\n",
      "water                ['3']\n",
      "increases            ['3']\n",
      ".                    []\n",
      "\n",
      "{'Causer:3->Result:6', 'Causer:1->Result:3'}\n",
      "{'Causer:3->Result:6'}\n",
      "corals               ['6']\n",
      "stress               ['6']\n",
      "from                 []\n",
      "sea                  ['3']\n",
      "temperatures         ['3']\n",
      "increasing           ['3']\n",
      ".                    []\n",
      "--Previous--\n",
      "plus                 []\n",
      ",                    []\n",
      "climate              []\n",
      "change               []\n",
      "affects              []\n",
      "coral                ['50']\n",
      "bleaching            ['50']\n",
      ".                    []\n",
      "--Next--\n",
      "due                  []\n",
      "to                   []\n",
      "wind                 ['1']\n",
      "speed                ['1']\n",
      ".                    []\n",
      "\n",
      "{'Causer:4->Result:50', 'Causer:3->Result:4'}\n",
      "{'Causer:3->Result:4'}\n",
      "as                   []\n",
      "water                ['3']\n",
      "temperatures         ['3']\n",
      "increase             ['3']\n",
      "the                  []\n",
      "amount               ['4']\n",
      "of                   ['4']\n",
      "carbon               ['4']\n",
      "dioxide              ['4']\n",
      "in                   ['4']\n",
      "water                ['4']\n",
      "decreases            ['4']\n",
      ".                    []\n",
      "--Previous--\n",
      "this                 []\n",
      "process              ['5b']\n",
      "is                   ['5b']\n",
      "very                 ['5b']\n",
      "sensitive            ['5b']\n",
      "and                  []\n",
      "changes              []\n",
      "due                  []\n",
      "to                   []\n",
      "enviromental         []\n",
      "changes              []\n",
      ".                    []\n",
      "--Next--\n",
      "which                []\n",
      "can                  []\n",
      "also                 []\n",
      "affect               []\n",
      "the                  []\n",
      "coral                []\n",
      "and                  []\n",
      "when                 []\n",
      "the                  []\n",
      "coral                ['50']\n",
      "is                   ['50']\n",
      "bleached             ['50']\n",
      ".                    []\n",
      "\n",
      "{'Causer:4->Result:14', 'Causer:3->Result:4'}\n",
      "{'Causer:3->Result:4'}\n",
      "as                   []\n",
      "water                ['3']\n",
      "temperatures         ['3']\n",
      "increase             ['3']\n",
      ",                    []\n",
      "the                  []\n",
      "amount               ['4']\n",
      "of                   ['4']\n",
      "carbon               ['4']\n",
      "dioxide              ['4']\n",
      "in                   ['4']\n",
      "water                ['4']\n",
      "decreases            ['4']\n",
      ".                    []\n",
      "--Previous--\n",
      "they                 ['3']\n",
      "can                  ['3']\n",
      "even                 ['3']\n",
      "increase             ['3']\n",
      "over                 ['3']\n",
      "10f                  ['3']\n",
      "above                ['3']\n",
      ".                    []\n",
      "--Next--\n",
      "so                   []\n",
      "the                  []\n",
      "changes              []\n",
      "in                   []\n",
      "that                 []\n",
      "threatens            ['14']\n",
      "to                   ['14']\n",
      "keep                 ['14']\n",
      "corals               ['14']\n",
      "healthy              ['14']\n",
      ".                    []\n",
      "\n",
      "{'Causer:12->Result:13', 'Causer:11->Result:12', 'Causer:13->Result:14'}\n",
      "{'Causer:12->Result:13', 'Causer:11->Result:12'}\n",
      "then                 []\n",
      "the                  []\n",
      "storm                ['11']\n",
      "will                 []\n",
      "increase             ['12']\n",
      "the                  ['12']\n",
      "amount               ['12']\n",
      "of                   ['12']\n",
      "fresh                ['12']\n",
      "water                ['12']\n",
      ",                    []\n",
      "which                []\n",
      "causes               []\n",
      "the                  []\n",
      "salinity             ['13']\n",
      "to                   ['13']\n",
      "drop                 ['13']\n",
      ".                    []\n",
      "--Previous--\n",
      "the                  []\n",
      "reason               []\n",
      "for                  []\n",
      "that                 []\n",
      "is                   []\n",
      "because              []\n",
      "corals               []\n",
      "are                  []\n",
      "sensitive            []\n",
      "to                   []\n",
      "how                  []\n",
      "salty                []\n",
      "the                  []\n",
      "water                []\n",
      "is                   []\n",
      ".                    []\n",
      "--Next--\n",
      "which                []\n",
      "then                 []\n",
      "will                 ['14']\n",
      "make                 ['14']\n",
      "it                   ['14']\n",
      "unhealthy            ['14']\n",
      "for                  ['14']\n",
      "the                  ['14']\n",
      "coral                ['14']\n",
      ".                    []\n",
      "\n",
      "{'Causer:12->Result:13', 'Causer:11->Result:12', 'Causer:13->Result:14'}\n",
      "{'Causer:12->Result:13', 'Causer:11->Result:12'}\n",
      "also                 []\n",
      "when                 []\n",
      "there                []\n",
      "is                   []\n",
      "a                    ['11']\n",
      "big                  ['11']\n",
      "storm                ['11']\n",
      "and                  []\n",
      "drops                ['12']\n",
      "fresh                ['12']\n",
      "water                ['12']\n",
      "into                 ['12']\n",
      "the                  ['12']\n",
      "ocean                ['12']\n",
      "the                  []\n",
      "salt                 ['13']\n",
      "decreases            ['13']\n",
      ".                    []\n",
      "--Previous--\n",
      "coral                []\n",
      "needs                []\n",
      "the                  []\n",
      "water                []\n",
      "temperature          []\n",
      "to                   []\n",
      "be                   []\n",
      "between              []\n",
      "70f                  []\n",
      "-                    []\n",
      "85f                  []\n",
      ".                    []\n",
      "--Next--\n",
      "which                []\n",
      "upsets               ['14']\n",
      "the                  ['14']\n",
      "health               ['14']\n",
      "of                   ['14']\n",
      "the                  ['14']\n",
      "coral                ['14']\n",
      ".                    []\n",
      "\n",
      "{'Causer:4->Result:5b', 'Causer:5b->Result:50'}\n",
      "{'Causer:4->Result:5b'}\n",
      "if                   []\n",
      "the                  []\n",
      "co2                  ['4']\n",
      "decreases            ['4']\n",
      "it                   []\n",
      "means                []\n",
      "it                   ['5b']\n",
      "has                  ['5b']\n",
      "less                 ['5b']\n",
      "energy               ['5b']\n",
      ",                    []\n",
      "food                 ['5b']\n",
      "to                   ['5b']\n",
      "give                 ['5b']\n",
      "to                   ['5b']\n",
      "the                  ['5b']\n",
      "coral                ['5b']\n",
      ".                    []\n",
      "--Previous--\n",
      "which                []\n",
      "that                 []\n",
      "leads                []\n",
      "to                   []\n",
      "the                  []\n",
      "amount               ['4']\n",
      "of                   ['4']\n",
      "carbon               ['4']\n",
      "dioxide              ['4']\n",
      "in                   ['4']\n",
      "water                ['4']\n",
      "decreases            ['4']\n",
      ".                    []\n",
      "--Next--\n",
      "leaving              []\n",
      "the                  []\n",
      "coral                ['50']\n",
      "without              ['50']\n",
      "color                ['50']\n",
      ".                    []\n",
      "\n",
      "{'Causer:12->Result:50', 'Causer:11->Result:12'}\n",
      "{'Causer:11->Result:12'}\n",
      "each                 []\n",
      "year                 []\n",
      "the                  []\n",
      "weather              []\n",
      "is                   []\n",
      "not                  []\n",
      "the                  []\n",
      "same                 []\n",
      "so                   []\n",
      "it                   []\n",
      "can                  []\n",
      "cause                []\n",
      "storm                ['11']\n",
      "to                   []\n",
      "let                  ['12']\n",
      "fresh                ['12']\n",
      "water                ['12']\n",
      "rate                 []\n",
      "coral                []\n",
      "reefs                []\n",
      "affect               []\n",
      "them                 []\n",
      ".                    []\n",
      "--Previous--\n",
      "environmental        []\n",
      "factor               []\n",
      "can                  []\n",
      "lead                 []\n",
      "coral                ['50']\n",
      "bleaching            ['50']\n",
      "at                   []\n",
      "different            []\n",
      "rates                []\n",
      ".                    []\n",
      "--Next--\n",
      "causing              []\n",
      "coral                ['50']\n",
      "bleaching            ['50']\n",
      "different            []\n",
      ".                    []\n",
      "\n",
      "{'Causer:13->Result:50', 'Causer:12->Result:13', 'Causer:11->Result:12'}\n",
      "{'Causer:12->Result:13', 'Causer:11->Result:12'}\n",
      "this                 []\n",
      "means                []\n",
      "when                 []\n",
      "storms               ['11']\n",
      "occur                ['11']\n",
      "such                 ['11']\n",
      "as                   ['11']\n",
      "hurricanes           ['11']\n",
      ",                    []\n",
      "or                   ['11']\n",
      "tropical             ['11']\n",
      "storms               ['11']\n",
      ",                    []\n",
      "more                 ['12']\n",
      "water                ['12']\n",
      "is                   ['12']\n",
      "added                ['12']\n",
      "meaning              []\n",
      "less                 ['13']\n",
      "salt                 ['13']\n",
      ".                    []\n",
      "--Previous--\n",
      "coral                []\n",
      "reefs                []\n",
      "are                  []\n",
      "only                 []\n",
      "found                []\n",
      "in                   []\n",
      "shallow              []\n",
      ",                    []\n",
      "clear                []\n",
      ",                    []\n",
      "tropical             []\n",
      "water                []\n",
      ".                    []\n",
      "--Next--\n",
      "as                   []\n",
      "a                    []\n",
      "result               []\n",
      "the                  []\n",
      "corals               ['50']\n",
      "start                ['50']\n",
      "to                   ['50']\n",
      "bleach               ['50']\n",
      "and                  []\n",
      "die                  []\n",
      "off                  []\n",
      ".                    []\n",
      "\n",
      "{'Causer:1->Result:2', 'Causer:1->Result:50'}\n",
      "{'Causer:1->Result:50'}\n",
      "shifting             ['1']\n",
      "trade                ['1']\n",
      "winds                ['1']\n",
      "lead                 []\n",
      "to                   []\n",
      "coral                ['50']\n",
      "bleaching            ['50']\n",
      "because              []\n",
      "\"                    []\n",
      "the                  []\n",
      "trade                ['1']\n",
      "winds                ['1']\n",
      "weaken               ['1']\n",
      "or                   ['1']\n",
      "reverse              ['1']\n",
      "direction            ['1']\n",
      "completely           ['1']\n",
      "to                   ['1']\n",
      "blow                 ['1']\n",
      "from                 ['1']\n",
      "west                 ['1']\n",
      "to                   ['1']\n",
      "east                 ['1']\n",
      ".                    []\n",
      "\"                    []\n",
      "--Next--\n",
      "which                []\n",
      "causes               []\n",
      "warm                 ['2']\n",
      "surface              ['2']\n",
      "waters               ['2']\n",
      "that                 ['2']\n",
      "dragged              ['2']\n",
      "eastward             ['2']\n",
      "to                   ['2']\n",
      "south                ['2']\n",
      "america              ['2']\n",
      ".                    []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def print_sentence(sentence):\n",
    "    for wd, tags in sentence:\n",
    "        print(wd.ljust(20), [t for t in tags if t[0].isdigit()])\n",
    "\n",
    "for essay_ix, sent_ix, un_csl, supported_causal in diffs[0:10]:\n",
    "    sentence = tagged_essays[essay_ix].sentences[sent_ix]\n",
    "    pprint(un_csl)\n",
    "    pprint(supported_causal)\n",
    "    print_sentence(sentence)\n",
    "    if sent_ix > 0:\n",
    "        print(\"--Previous--\")    \n",
    "        print_sentence(tagged_essays[essay_ix].sentences[sent_ix-1])\n",
    "    if sent_ix < len(tagged_essays[essay_ix].sentences)-1:\n",
    "        print(\"--Next--\")    \n",
    "        print_sentence(tagged_essays[essay_ix].sentences[sent_ix+1])\n",
    "\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO \n",
    "- Re-train tagging model, adding tags where reg tag is missing but is included in a causer or result tag. \n",
    "- Also include explicit in the predicted tags.\n",
    "- Need to handle relations where same code -> same code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Errors Below Look Are from Non-Projective Parses\n",
    "**NOTES**\n",
    "With only 4 errors as 4 missed relations, hardly worth worrying about. \n",
    "One solution would be to train a forward and a backward parser, parse the sentence in both directions and merge the deps. In each case that would pick up all deps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 50 50\n",
      "(24, 13, {'Causer:1->Result:50', 'Causer:50->Result:50'}, ['explicit', '1', '50', 'explicit', '50'])\n",
      "\n",
      "493 50 50\n",
      "(189, 4, {'Causer:13->Result:50', 'Causer:50->Result:50'}, ['explicit', '13', 'explicit', '50', 'explicit', '50'])\n",
      "\n",
      "527 50 50\n",
      "(197, 10, {'Causer:5b->Result:50', 'Causer:50->Result:50'}, ['5b', 'explicit', '50', 'explicit', '50'])\n",
      "\n",
      "766 11 11\n",
      "(276, 12, {'Causer:11->Result:11', 'Causer:3->Result:4'}, ['4', '3', 'explicit', '11'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (essay_ix, sent_ix, supported_causal, tag_seq) in enumerate(relations[:]):\n",
    "    supported_causal = sorted(supported_causal)\n",
    "    crels = [normalize_cr(crel) for crel in supported_causal]\n",
    "    for l,r in crels:\n",
    "        if l == r:\n",
    "            print(i, l,r)\n",
    "            print(relations[i])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('balance', set()),\n",
       " ('between', set()),\n",
       " ('co2', {'4', 'Causer:3->Result:4', 'Result', 'Result:4'}),\n",
       " ('and', {'Causer:3->Result:4'}),\n",
       " ('water', {'3', 'Causer', 'Causer:3', 'Causer:3->Result:4'}),\n",
       " ('temperature', {'3', 'Causer', 'Causer:3', 'Causer:3->Result:4'}),\n",
       " ('is', set()),\n",
       " ('also', set()),\n",
       " ('threaten', {'explicit'}),\n",
       " ('by', {'explicit'}),\n",
       " ('extreme',\n",
       "  {'11',\n",
       "   'Causer',\n",
       "   'Causer:11',\n",
       "   'Causer:11->Result:11',\n",
       "   'Result',\n",
       "   'Result:11'}),\n",
       " ('storms',\n",
       "  {'11',\n",
       "   'Causer',\n",
       "   'Causer:11',\n",
       "   'Causer:11->Result:11',\n",
       "   'Result',\n",
       "   'Result:11'}),\n",
       " ('.', set())]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Why is the last one missing the 11->11 relation?\n",
    "tagged_essays[276].sentences[12]\n",
    "#looks to be an unsupported relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for relations: 24 , 13\n",
      "[('1', '50'), ('50', '50')]\n",
      "['explicit', '1', '50', 'explicit', '50']\n",
      "Error for relations: 33 , 3\n",
      "[('1', '50'), ('1', '7'), ('3', '50'), ('3', '7')]\n",
      "['1', '3', 'explicit', '50', 'explicit', '1', '3', '7']\n",
      "Error for relations: 68 , 1\n",
      "[('6', '50'), ('6', '7')]\n",
      "['6', 'explicit', '50', 'explicit', '6', 'explicit', '7']\n",
      "Error for relations: 75 , 2\n",
      "[('11', '12'), ('11', '13'), ('12', '13'), ('13', '14')]\n",
      "['13', 'explicit', '11', 'explicit', '12', 'explicit', '13', 'explicit', '14']\n",
      "Error for relations: 129 , 11\n",
      "[('1', '3'), ('1', '50')]\n",
      "['1', 'explicit', '50', '1', 'explicit', '3']\n",
      "Error for relations: 145 , 2\n",
      "[('1', '3'), ('3', '4'), ('4', '14')]\n",
      "['explicit',\n",
      " '50',\n",
      " 'explicit',\n",
      " '1',\n",
      " 'explicit',\n",
      " '3',\n",
      " 'explicit',\n",
      " '3',\n",
      " 'explicit',\n",
      " '4',\n",
      " 'explicit',\n",
      " '14']\n",
      "Error for relations: 158 , 1\n",
      "[('1', '2')]\n",
      "['1', 'explicit', '1', '2']\n",
      "Error for relations: 174 , 4\n",
      "[('1', '3'), ('3', '7'), ('7', '50')]\n",
      "['1', 'explicit', '1', '3', 'explicit', '7', 'explicit', '50']\n",
      "Error for relations: 182 , 11\n",
      "[('1', '3'), ('1', '50'), ('7', '50')]\n",
      "['50', 'explicit', '1', '3', 'explicit', '1', '7', 'explicit', '50']\n",
      "Error for relations: 189 , 4\n",
      "[('13', '50'), ('50', '50')]\n",
      "['explicit', '13', 'explicit', '50', 'explicit', '50']\n",
      "Error for relations: 197 , 10\n",
      "[('50', '50'), ('5b', '50')]\n",
      "['5b', 'explicit', '50', 'explicit', '50']\n",
      "Error for relations: 213 , 3\n",
      "[('1', '3')]\n",
      "['1', 'explicit', '1', 'explicit', '3']\n",
      "Error for relations: 222 , 6\n",
      "[('3', '4'), ('4', '14')]\n",
      "['3', 'explicit', '3', 'explicit', '4', 'explicit', '14']\n",
      "Error for relations: 234 , 3\n",
      "[('1', '50'), ('3', '50')]\n",
      "['1', '3', 'explicit', '1', 'explicit', '50', 'explicit', '3']\n",
      "Error for relations: 234 , 6\n",
      "[('11', '50'), ('13', '50')]\n",
      "['13', '11', '13', 'explicit', '50']\n",
      "Error for relations: 245 , 5\n",
      "[('11', '13'), ('13', '14')]\n",
      "['13', '11', 'explicit', '13', 'explicit', '14']\n",
      "Error for relations: 253 , 0\n",
      "[('14', '50'), ('6', '14'), ('7', '50')]\n",
      "['50', 'explicit', '6', 'explicit', '14', '50', 'explicit', '7']\n",
      "Error for relations: 268 , 4\n",
      "[('1', '2'), ('1', '3')]\n",
      "['1', 'explicit', '2', '1', 'explicit', '3']\n",
      "Error for relations: 268 , 8\n",
      "[('3', '4'), ('3', '50'), ('4', '5')]\n",
      "['3', 'explicit', '50', '3', 'explicit', '3', 'explicit', '4', 'explicit', '5']\n",
      "Error for relations: 276 , 12\n",
      "[('11', '11'), ('3', '4')]\n",
      "['4', '3', 'explicit', '11']\n",
      "Error for relations: 329 , 3\n",
      "[('13', '14'), ('13', '50'), ('14', '50')]\n",
      "['13', 'explicit', '50', 'explicit', '13', 'explicit', '14']\n",
      "Error for relations: 344 , 1\n",
      "[('3', '50'), ('50', '7')]\n",
      "['50', 'explicit', '3', '50', 'explicit', '7']\n",
      "Error for relations: 353 , 5\n",
      "[('3', '50')]\n",
      "['3', 'explicit', '3', '50']\n",
      "Error for relations: 371 , 9\n",
      "[('11', '12'), ('11', '13'), ('12', '13')]\n",
      "['11', 'explicit', '13', '11', 'explicit', '12', 'explicit', '13']\n",
      "Error for relations: 374 , 3\n",
      "[('1', '3')]\n",
      "['1', 'explicit', '1', 'explicit', '3']\n",
      "Error for relations: 411 , 19\n",
      "[('5b', '50')]\n",
      "['50', 'explicit', '50', '5b']\n",
      "Error for relations: 416 , 0\n",
      "[('1', '3'), ('3', '4'), ('4', '14')]\n",
      "['1', 'explicit', '3', 'explicit', '3', '4', 'explicit', '14']\n",
      "Error for relations: 427 , 2\n",
      "[('1', '4'), ('1', '50'), ('3', '4'), ('3', '50')]\n",
      "['explicit', '1', '3', '4', '50']\n",
      "Error for relations: 433 , 10\n",
      "[('1', '50'), ('3', '50')]\n",
      "['1', '50', 'explicit', '1', '3', '50']\n",
      "Error for relations: 437 , 3\n",
      "[('2', '3')]\n",
      "['explicit', '2', 'explicit', '2', 'explicit', '3']\n",
      "Error for relations: 446 , 7\n",
      "[('11', '13'), ('13', '14')]\n",
      "['explicit', '11', '13', '11', 'explicit', '13', 'explicit', '14']\n",
      "Error for relations: 459 , 2\n",
      "[('1', '14')]\n",
      "['explicit', '1', 'explicit', '1', '14']\n",
      "Error for relations: 462 , 11\n",
      "[('3', '5'), ('3', '50')]\n",
      "['3', 'explicit', '5', '3', 'explicit', '50']\n",
      "Error for relations: 475 , 1\n",
      "[('11', '12'), ('11', '50'), ('12', '13')]\n",
      "['11', 'explicit', '50', '11', 'explicit', '12', 'explicit', '13']\n",
      "Error for relations: 498 , 0\n",
      "[('1', '50'), ('3', '50')]\n",
      "['3', '1', '3', '1', 'explicit', '50']\n",
      "Error for relations: 499 , 1\n",
      "[('1', '50'), ('3', '50')]\n",
      "['1', '50', '1', '3', 'explicit', '50']\n",
      "Error for relations: 532 , 5\n",
      "[('11', '13'), ('11', '3'), ('13', '50')]\n",
      "['13', '11', 'explicit', '3', '13', 'explicit', '50']\n",
      "Error for relations: 546 , 4\n",
      "[('12', '13'), ('13', '14')]\n",
      "['11', '13', 'explicit', '12', 'explicit', '13', 'explicit', '14']\n",
      "Error for relations: 546 , 5\n",
      "[('3', '4'), ('4', '14')]\n",
      "['3', 'explicit', '3', 'explicit', '4', 'explicit', '14']\n",
      "Error for relations: 555 , 7\n",
      "[('11', '12')]\n",
      "['11', '13', 'explicit', '11', '12']\n",
      "Error for relations: 597 , 3\n",
      "[('13', '6'), ('13', '7'), ('3', '6'), ('3', '7'), ('7', '50')]\n",
      "['explicit', '6', '3', '13', 'explicit', '7', 'explicit', '50']\n",
      "Error for relations: 655 , 1\n",
      "[('3', '14'), ('3', '5')]\n",
      "['3', 'explicit', '5', '3', 'explicit', '14']\n",
      "Error for relations: 661 , 8\n",
      "[('3', '4')]\n",
      "['3', 'explicit', '3', '4']\n",
      "Error for relations: 683 , 6\n",
      "[('3', '4'), ('3', '5')]\n",
      "['3', 'explicit', '5', 'explicit', '3', '4']\n",
      "Error for relations: 694 , 8\n",
      "[('14', '50'), ('6', '14'), ('7', '50')]\n",
      "['50', 'explicit', '6', 'explicit', '14', '50', 'explicit', '7']\n",
      "Error for relations: 707 , 1\n",
      "[('1', '3'), ('3', '4')]\n",
      "['1', 'explicit', '3', '1', 'explicit', '3', 'explicit', '4']\n",
      "Error for relations: 710 , 0\n",
      "[('13', '50'), ('7', '50')]\n",
      "['50', 'explicit', '13', '50', 'explicit', '7']\n",
      "Error for relations: 712 , 2\n",
      "[('7', '50')]\n",
      "['50', 'explicit', '50', '7']\n",
      "Error for relations: 779 , 2\n",
      "[('1', '3'), ('3', '5'), ('3', '50')]\n",
      "['3', 'explicit', '5', '3', '1', 'explicit', '3', 'explicit', '50']\n",
      "Error for relations: 823 , 9\n",
      "[('13', '14'), ('14', '50')]\n",
      "['explicit', '13', '14', 'explicit', '14', '50']\n",
      "Error for relations: 823 , 11\n",
      "[('1', '3'), ('3', '4'), ('4', '14')]\n",
      "['explicit',\n",
      " '1',\n",
      " 'explicit',\n",
      " '3',\n",
      " 'explicit',\n",
      " '3',\n",
      " 'explicit',\n",
      " '4',\n",
      " 'explicit',\n",
      " '14']\n",
      "Error for relations: 824 , 1\n",
      "[('1', '3'), ('1', '50')]\n",
      "['50', 'explicit', '1', 'explicit', '1', 'explicit', '3']\n",
      "Error for relations: 868 , 4\n",
      "[('5', '50')]\n",
      "['5', 'explicit', '5', '50']\n",
      "Error for relations: 869 , 3\n",
      "[('3', '4')]\n",
      "['3', 'explicit', '3', '4']\n",
      "Error for relations: 873 , 4\n",
      "[('1', '50')]\n",
      "['1', 'explicit', '1', '50', 'explicit', '1', '50']\n",
      "Error for relations: 875 , 0\n",
      "[('1', '2'), ('2', '3'), ('6', '7'), ('7', '50')]\n",
      "['50',\n",
      " '6',\n",
      " '1',\n",
      " 'explicit',\n",
      " '2',\n",
      " 'explicit',\n",
      " '3',\n",
      " 'explicit',\n",
      " '6',\n",
      " '7',\n",
      " 'explicit',\n",
      " '50']\n",
      "Error for relations: 890 , 2\n",
      "[('12', '11'), ('13', '11'), ('13', '14')]\n",
      "['12', '13', 'explicit', '11', 'explicit', '14']\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "exs = []\n",
    "for e_ix,s_ix, supported_causal, tag_seq in relations[:]:\n",
    "    supported_causal = sorted(supported_causal)\n",
    "    crels = [normalize_cr(crel) for crel in supported_causal]\n",
    "\n",
    "    try:\n",
    "        success = test_oracle(tag_seq, crels, Oracle, verbose=False)\n",
    "    except Exception as e:\n",
    "        exs.append(e)\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        errors += 1\n",
    "        print(\"Error for relations:\", e_ix, \",\", s_ix)\n",
    "        pprint(crels)\n",
    "        pprint(tag_seq)\n",
    "        #print()\n",
    "        #success = test_oracle(tag_seq, crels, Oracle, verbose=True)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_relations_for(tagged_sentence, tag_freq, reg_tags, cr_tags):    \n",
    "    most_common_tag = [None] # seed with None\n",
    "    tag_seq = []\n",
    "    \n",
    "    crel_child_tags = defaultdict(set)    \n",
    "    for i, (wd,tags) in enumerate(taggged_sentence):\n",
    "        rtags = set([normalize(t) for t in tags])\n",
    "        rtags = rtags.intersection(reg_tags)\n",
    "        # Get tag seq\n",
    "        tag = None\n",
    "        if rtags:\n",
    "            tag = max(rtags, key = lambda t: tag_freq[t])\n",
    "            if tag != most_common_tag[-1]:\n",
    "                # often there are single word gaps, skip over these\n",
    "                if len(most_common_tag) < 3 or tag != most_common_tag[-2]: # at least 2 regular tags                    \n",
    "                    tag_seq.append((tag,i))\n",
    "        most_common_tag.append(tag)\n",
    "        \n",
    "        # to have child tags, need a tag sequence and a current valid regular tag\n",
    "        if not tag or len(tag_seq) == 0:\n",
    "            continue\n",
    "            \n",
    "        crels = cr_tags.intersection(tags)\n",
    "        for crel in crels:\n",
    "            l,r = normalize_cr(crel) \n",
    "            last_pair = tag_seq[-1]\n",
    "            last_tag, tag_ix = last_pair\n",
    "            if last_tag != tag:\n",
    "                raise Exception(\"Tags don't match % s\" % str((i,last_tag,tag)))                \n",
    "            if tag in (l,r):\n",
    "                crel_child_tags[crel].add(last_pair)\n",
    "    return tag_seq, crel_child_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('50', 1)\n",
      "('explicit', 6)\n",
      "('7', 9)\n",
      "******************************\n",
      "Causer:7->Result:50\n",
      "('7', 9)\n",
      "('50', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#normalize_cr(\"Causer:5->Result:10\")\n",
    "\n",
    "e_ix = 72\n",
    "s_ix = 2\n",
    "sentence = tagged_essays[e_ix].sentences[s_ix]\n",
    "tag_seq, crel_children = get_tags_relations_for(sentence, tag_freq, reg_tags, set(cr_tags))\n",
    "for pair in tag_seq:\n",
    "    print(pair)\n",
    "print(\"*\" * 30)\n",
    "for crel, kids in crel_children.items():\n",
    "    print(crel)\n",
    "    for k in kids:\n",
    "        print(str(k))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sentence_tags(tagged_sentence, tag_filter):\n",
    "    for i, (wd,tags) in enumerate(taggged_sentence):\n",
    "        tags = tags.intersection(tag_filter)\n",
    "        stags = \"\"\n",
    "        if tags:\n",
    "            stags = \",\".join(tags)\n",
    "        print(str(i).ljust(3),wd.ljust(30), stags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   during                         \n",
      "1   bleaching                      50\n",
      "2   ,                              \n",
      "3   corals                         50\n",
      "4   turn                           50\n",
      "5   white                          50\n",
      "6   due                            explicit\n",
      "7   to                             explicit\n",
      "8   the                            \n",
      "9   ejection                       7\n",
      "10  or                             7\n",
      "11  death                          7\n",
      "12  ,                              \n",
      "13  of                             7\n",
      "14  the                            7\n",
      "15  zooxanthellae                  7\n",
      "16  algae                          7\n",
      "17  .                              \n"
     ]
    }
   ],
   "source": [
    "print_sentence_tags(sentence, reg_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('11', '12')\n",
      "\t('11', '13')\n",
      "\t('12', '13')\n",
      "\t('13', '14')\n",
      "\n",
      "-------------------------------------------\n",
      "13\n",
      "-------------------------------------------\n",
      "SHIFT   : Push 13    || STACK : root|13\n",
      "-------------------------------------------\n",
      "explicit\n",
      "-------------------------------------------\n",
      "SKIP    : item explicit || STACK : root|13\n",
      "-------------------------------------------\n",
      "11\n",
      "-------------------------------------------\n",
      "R ARC   : 13<-11     || STACK : root|13|11\n",
      "-------------------------------------------\n",
      "explicit\n",
      "-------------------------------------------\n",
      "SKIP    : item explicit || STACK : root|13|11\n",
      "-------------------------------------------\n",
      "12\n",
      "-------------------------------------------\n",
      "L ARC   : 11->12     || STACK : root|13\n",
      "R ARC   : 13<-12     || STACK : root|13|12\n",
      "-------------------------------------------\n",
      "explicit\n",
      "-------------------------------------------\n",
      "SKIP    : item explicit || STACK : root|13|12\n",
      "-------------------------------------------\n",
      "13\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Arc already processed ('12', '13')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-4f67c5cc6de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcrels\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'12'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'13'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'13'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'13'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'14'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtag_seq\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'13'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'13'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'14'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-c73b6ba97e6e>\u001b[0m in \u001b[0;36mtest_oracle\u001b[0;34m(codes, crels, orcl_fact, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mprn_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" || STACK : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-66ba0f4dc949>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, action, tos, buffer)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRARC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREDUCE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-674fb5aa7864>\u001b[0m in \u001b[0;36mright_arc\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0marc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mn_arc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mn_arc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_arcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Arc already processed %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_arc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_arcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_arc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Arc already processed ('12', '13')"
     ]
    }
   ],
   "source": [
    "crels     = [('11', '12'), ('11', '13'), ('12', '13'), ('13', '14')]\n",
    "tag_seq   = ['13', 'explicit', '11', 'explicit', '12', 'explicit', '13', 'explicit', '14']\n",
    "test_oracle(tag_seq, crels, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('1', '3')\n",
      "\t('1', '50')\n",
      "\n",
      "-------------------------------------\n",
      "1\n",
      "-------------------------------------\n",
      "SHIFT   : Push 1     || STACK : root|1\n",
      "-------------------------------------\n",
      "explicit\n",
      "-------------------------------------\n",
      "SKIP    : item explicit || STACK : root|1\n",
      "-------------------------------------\n",
      "50\n",
      "-------------------------------------\n",
      "R ARC   : 1<-50      || STACK : root|1|50\n",
      "-------------------------------------\n",
      "1\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Arc already processed ('1', '50')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-82a2d5d6c5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcrels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explicit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_oracle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-c73b6ba97e6e>\u001b[0m in \u001b[0;36mtest_oracle\u001b[0;34m(codes, crels, orcl_fact, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mprn_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" || STACK : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-66ba0f4dc949>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, action, tos, buffer)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRARC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREDUCE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-674fb5aa7864>\u001b[0m in \u001b[0;36mright_arc\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0marc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mn_arc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_arc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mn_arc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_arcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Arc already processed %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_arc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormed_arcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_arc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Arc already processed ('1', '50')"
     ]
    }
   ],
   "source": [
    "crels = [('1', '3'), ('1', '50')]\n",
    "tag_seq = ['1', 'explicit', '50', '1', 'explicit', '3']\n",
    "test_oracle(tag_seq, crels, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">NEED to determine if all errors are non-projective<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('5', '50')\n",
      "\n",
      "-----------------------------\n",
      "5\n",
      "-----------------------------\n",
      "SHIFT   : Push 5     || STACK : root|5\n",
      "-----------------------------\n",
      "50\n",
      "-----------------------------\n",
      "L ARC   : 5->50      || STACK : root\n",
      "L ARC   : 5->50      || STACK : root\n",
      "\n",
      "*****************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('5', '50')\n",
      "DEPS Pred\n",
      "\t('5', '50')\n",
      "Actions\n",
      "\tSHIFT   : Push 5\n",
      "\tL ARC   : 5->50\n",
      "\n",
      "Ordered Match?    True\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_oracle2(['5', '50'], [('5', '50')], Oracle2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for relations:\n",
      "[('1', '50'), ('50', '50')]\n",
      "['1', '50']\n",
      "Error for relations:\n",
      "[('1', '50'), ('1', '7'), ('3', '50'), ('3', '7')]\n",
      "['1', '3', '50', '1', '3', '7']\n",
      "Error for relations:\n",
      "[('6', '50'), ('6', '7')]\n",
      "['6', '50', '6', '7']\n",
      "Error for relations:\n",
      "[('11', '12'), ('11', '13'), ('12', '13'), ('13', '14')]\n",
      "['13', '11', '12', '13', '14']\n",
      "Error for relations:\n",
      "[('1', '3'), ('1', '50')]\n",
      "['1', '50', '1', '3']\n",
      "Error for relations:\n",
      "[('1', '3'), ('1', '50'), ('7', '50')]\n",
      "['50', '1', '3', '1', '7', '50']\n",
      "Error for relations:\n",
      "[('13', '50'), ('50', '50')]\n",
      "['13', '50']\n",
      "Error for relations:\n",
      "[('50', '50'), ('5b', '50')]\n",
      "['5b', '50']\n",
      "Error for relations:\n",
      "[('14', '50'), ('6', '14'), ('7', '50')]\n",
      "['50', '6', '14', '50', '7']\n",
      "Error for relations:\n",
      "[('1', '2'), ('1', '3')]\n",
      "['1', '2', '1', '3']\n",
      "Error for relations:\n",
      "[('3', '4'), ('3', '50'), ('4', '5')]\n",
      "['3', '50', '3', '4', '5']\n",
      "Error for relations:\n",
      "[('11', '11'), ('3', '4')]\n",
      "['4', '3', '11']\n",
      "Error for relations:\n",
      "[('13', '14'), ('13', '50'), ('14', '50')]\n",
      "['13', '50', '13', '14']\n",
      "Error for relations:\n",
      "[('3', '50'), ('50', '7')]\n",
      "['50', '3', '50', '7']\n",
      "Error for relations:\n",
      "[('11', '12'), ('11', '13'), ('12', '13')]\n",
      "['11', '13', '11', '12', '13']\n",
      "Error for relations:\n",
      "[('1', '4'), ('1', '50'), ('3', '4'), ('3', '50')]\n",
      "['1', '3', '4', '50']\n",
      "Error for relations:\n",
      "[('3', '5'), ('3', '50')]\n",
      "['3', '5', '3', '50']\n",
      "Error for relations:\n",
      "[('11', '12'), ('11', '50'), ('12', '13')]\n",
      "['11', '50', '11', '12', '13']\n",
      "Error for relations:\n",
      "[('13', '6'), ('13', '7'), ('3', '6'), ('3', '7'), ('7', '50')]\n",
      "['6', '3', '13', '7', '50']\n",
      "Error for relations:\n",
      "[('3', '14'), ('3', '5')]\n",
      "['3', '5', '3', '14']\n",
      "Error for relations:\n",
      "[('3', '4'), ('3', '5')]\n",
      "['3', '5', '3', '4']\n",
      "Error for relations:\n",
      "[('14', '50'), ('6', '14'), ('7', '50')]\n",
      "['50', '6', '14', '50', '14', '50', '7']\n",
      "Error for relations:\n",
      "[('1', '3'), ('3', '4')]\n",
      "['1', '3', '1', '3', '4']\n",
      "Error for relations:\n",
      "[('13', '50'), ('7', '50')]\n",
      "['50', '13', '50', '7']\n",
      "Error for relations:\n",
      "[('1', '3'), ('3', '5'), ('3', '50')]\n",
      "['3', '5', '1', '3', '50']\n",
      "Error for relations:\n",
      "[('12', '11'), ('13', '11'), ('13', '14')]\n",
      "['12', '13', '11', '14']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = 0\n",
    "exs = []\n",
    "for supported_causal, tag_seq in relations[:]:\n",
    "    supported_causal = sorted(supported_causal)\n",
    "    crels = [normalize_cr(crel) for crel in supported_causal]\n",
    "\n",
    "    try:\n",
    "        success = test_oracle2(tag_seq, crels, Oracle2, verbose=False)\n",
    "    except Exception as e:\n",
    "        exs.append(e)\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        errors += 1\n",
    "        print(\"Error for relations:\")\n",
    "        pprint(crels)\n",
    "        pprint(tag_seq)\n",
    "        #print()\n",
    "        #success = test_oracle(tag_seq, crels, Oracle, verbose=True)\n",
    "        #break\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
