{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def test_oracle(codes, crels, orcl_fact, verbose=False):\n",
    "    \n",
    "    crels = set(crels)\n",
    "    if verbose:\n",
    "        prn_fun = lambda s=\"\": print(s)\n",
    "    else:\n",
    "        prn_fun = lambda s=\"\": None\n",
    "    \n",
    "    stack = Stack(False)\n",
    "    stack.push(ROOT)\n",
    "    parser = Parser(stack)\n",
    "    oracle = orcl_fact(crels, parser)\n",
    "\n",
    "    prn_fun(\"DEPS\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun()\n",
    "\n",
    "    PAD = 20\n",
    "    LINE = PAD + len(ROOT) + 2 * len(codes) + 1\n",
    "\n",
    "    for buffer in codes:\n",
    "        prn_fun(\"-\" * LINE)\n",
    "        prn_fun(buffer)\n",
    "        prn_fun(\"-\" * LINE)\n",
    "\n",
    "        while True:\n",
    "            tos = stack.tos()\n",
    "            if not oracle.consult(tos, buffer):\n",
    "                prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "                break\n",
    "\n",
    "            prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "            if stack.len() == 0:\n",
    "                prn_fun(\"Empty stack, stopping\")\n",
    "                break\n",
    "\n",
    "    prn_fun()\n",
    "    prn_fun(\"*\" * LINE)\n",
    "    prn_fun(\"Stack\")\n",
    "    prn_fun(\"\\t\" + str(stack))\n",
    "    deps = parser.get_dependencies()\n",
    "    prn_fun(\"DEPS Actual\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun(\"DEPS Pred\")\n",
    "    for dep in sorted(deps):\n",
    "        prn_fun(\"\\t\" + str(dep))\n",
    "    prn_fun(\"Actions\")\n",
    "    for a in parser.actions:\n",
    "        prn_fun(\"\\t\" + a)\n",
    "    prn_fun()\n",
    "    prn_fun(\"Ordered Match?    \" + str(set(deps) == crels))\n",
    "\n",
    "    ndeps = norm_arcs(deps)\n",
    "    ncrels = norm_arcs(crels)\n",
    "    diff = (ndeps - ncrels).union(ncrels - ndeps)\n",
    "    success = (len(diff) == 0)\n",
    "    prn_fun(\"Un Ordered Match? \" + str(success))\n",
    "    if diff:\n",
    "        prn_fun(diff)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stack(object):\n",
    "    def __init__(self, verbose=False):    \n",
    "        self.stack = []\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def tos(self):\n",
    "        if self.len() == 0:\n",
    "            return None\n",
    "        #assert self.len() > 0, \"Can't peek when stack is empty\"\n",
    "        return self.stack[-1]\n",
    "    \n",
    "    def pop(self):\n",
    "        assert self.len() > 0, \"Can't pop when stack is empty\"\n",
    "        item = self.stack.pop()\n",
    "        if self.verbose:\n",
    "            print(\"POPPING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "        return item\n",
    "    \n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "        if self.verbose:\n",
    "            print(\"PUSHING: %s\" % item)\n",
    "            print(\"LEN:     %i\" % len(self.stack))\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.stack)\n",
    "\n",
    "    def contains(self, item):\n",
    "        return item in self.stack\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"|\".join(self.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT = \"root\"\n",
    "\n",
    "def norm_arc(arc):\n",
    "    return tuple(sorted(arc))\n",
    "\n",
    "def norm_arcs(arcs):\n",
    "    return set(map(norm_arc, arcs))\n",
    "\n",
    "class Parser(object):\n",
    "    def __init__(self, stack):\n",
    "        self.stack = stack\n",
    "        self.arcs = []\n",
    "        self.normed_arcs = set()\n",
    "        # nodes with heads\n",
    "        self.children = set()\n",
    "        self.actions = []\n",
    "        \n",
    "    def get_dependencies(self):\n",
    "        return [(l,r) for (l,r) in self.arcs if r != ROOT and l != ROOT]\n",
    "        \n",
    "    def left_arc(self, buffer):\n",
    "        tos = self.stack.pop()\n",
    "        #Pre-condition\n",
    "        #assert self.has_head(tos) == False\n",
    "        arc = (tos,buffer)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(arc)\n",
    "        self.children.add(tos)\n",
    "        self.actions.append(\"L ARC   : \" + tos + \"->\" + buffer)\n",
    "        \n",
    "    def right_arc(self, buffer):\n",
    "        tos = self.stack.tos()\n",
    "        #normalize arc\n",
    "        arc = (buffer,tos)\n",
    "        n_arc = norm_arc(arc)\n",
    "        assert n_arc not in self.normed_arcs, \"Arc already processed %s\" % (n_arc)\n",
    "        self.arcs.append(arc)\n",
    "        self.normed_arcs.add(n_arc)\n",
    "        self.actions.append(\"R ARC   : \" + tos + \"<-\" + buffer)\n",
    "        self.children.add(buffer)\n",
    "        self.stack.push(buffer)\n",
    "        \n",
    "    def reduce(self):\n",
    "        tos = self.stack.pop()\n",
    "        #assert self.has_head(tos) == True\n",
    "        self.actions.append(\"REDUCE  : Pop  %s\" % tos)\n",
    "        \n",
    "    def shift(self, buffer):\n",
    "        self.stack.push(buffer)\n",
    "        self.actions.append(\"SHIFT   : Push %s\" % buffer)\n",
    "    \n",
    "    def skip(self, buffer):\n",
    "        self.actions.append(\"SKIP    : item %s\" % buffer)\n",
    "    \n",
    "    def has_head(self, item):\n",
    "        return item in self.children\n",
    "    \n",
    "    def in_stack(self, item):\n",
    "        return self.stack.contains(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SHIFT = \"Shift\"\n",
    "REDUCE = \"Reduce\"\n",
    "LARC = \"LArc\"\n",
    "RARC = \"Rarc\"\n",
    "SKIP = \"Skip\"\n",
    "\n",
    "class Oracle(object):\n",
    "    \n",
    "    def __init__(self, crels, parser):\n",
    "        self.parser = parser\n",
    "        self.crels = norm_arcs(crels)\n",
    "        self.mapping = self.build_mappings(crels)\n",
    "    \n",
    "    def build_mappings(self, pairs):\n",
    "        mapping = defaultdict(set)\n",
    "        for c,res in pairs:\n",
    "            mapping[c].add(res)\n",
    "            mapping[res].add(c)\n",
    "        return mapping\n",
    "\n",
    "    def cont(self, action):\n",
    "        # continue parsing if REDUCE or LARC\n",
    "        return action in (REDUCE,LARC)\n",
    "    \n",
    "    def remove_relation(self, a,b):\n",
    "        self.mapping[a].remove(b)\n",
    "        if len(self.mapping[a]) == 0:\n",
    "            del self.mapping[a]\n",
    "        self.mapping[b].remove(a)\n",
    "        if len(self.mapping[b]) == 0:\n",
    "            del self.mapping[b]\n",
    "    \n",
    "    def consult(self, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        parser = self.parser\n",
    "        a,b = norm_arc((tos, buffer))\n",
    "        if (a,b) in self.crels:\n",
    "            # TOS has arcs remaining? If so, we need RARC, else LARC\n",
    "            if len(self.mapping[tos]) == 1:\n",
    "                parser.left_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(LARC)\n",
    "            else:\n",
    "                parser.right_arc(buffer)\n",
    "                self.remove_relation(tos, buffer)\n",
    "                return self.cont(RARC)\n",
    "        else:\n",
    "            if buffer not in self.mapping:\n",
    "                parser.skip(buffer)\n",
    "                return self.cont(SKIP)\n",
    "            # If the buffer has relations further down in the stack, we need to POP the TOS\n",
    "            for item in self.mapping[buffer]:\n",
    "                if item == tos:\n",
    "                    continue\n",
    "                if parser.in_stack(item):\n",
    "                    parser.reduce()\n",
    "                    return self.cont(REDUCE)\n",
    "            #end for\n",
    "            #ELSE\n",
    "            parser.shift(buffer)\n",
    "            return self.cont(SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pairs = []\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "#C->B->A\n",
    "test_pairs.append([\n",
    "    (\"C\",\"B\"),\n",
    "    (\"B\",\"A\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"C\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"B\"),\n",
    "    (\"C\",\"B\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"B\",\"A\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"C\"),\n",
    "    (\"C\",\"B\"),\n",
    "])\n",
    "\n",
    "# Hard - has to flip relation\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"D\",\"A\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"D\",\"A\"),\n",
    "    (\"B\",\"D\"),\n",
    "    (\"B\",\"C\"),\n",
    "])\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"E\"),\n",
    "    (\"E\",\"B\"),\n",
    "    (\"B\",\"D\"),\n",
    "    (\"D\",\"C\"),\n",
    "])\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"A\", \"F\"),\n",
    "    (\"A\", \"E\"),\n",
    "])\n",
    "\n",
    "test_pairs.append([\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"A\", \"F\"),\n",
    "    (\"E\", \"F\"),\n",
    "])\n",
    "\n",
    "oracle_fact = Oracle\n",
    "for pairs in test_pairs:\n",
    "    try:\n",
    "        success = test_oracle(\"ABCDEF\", pairs, oracle_fact, verbose=False)\n",
    "    except:\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        print(\"Error for relations:\")\n",
    "        pprint(pairs)\n",
    "        print()\n",
    "        success = test_oracle(\"ABCDEF\", pairs, oracle_fact, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Parse for Tricker Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Doesn't Handle Cycles</span>\n",
    "- So we remove the condition about only having a single parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "\t('C', 'A')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "R ARC   : A<-B       || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "L ARC   : B->C       || STACK : root|A\n",
      "L ARC   : A->C       || STACK : root\n",
      "SKIP    : item C     || STACK : root\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "SKIP    : item D     || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "SKIP    : item E     || STACK : root\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "SKIP    : item F     || STACK : root\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "\t('C', 'A')\n",
      "DEPS Pred\n",
      "\t('A', 'C')\n",
      "\t('B', 'A')\n",
      "\t('B', 'C')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tR ARC   : A<-B\n",
      "\tL ARC   : B->C\n",
      "\tL ARC   : A->C\n",
      "\tSKIP    : item C\n",
      "\tSKIP    : item D\n",
      "\tSKIP    : item E\n",
      "\tSKIP    : item F\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[('1', '3'), ('1', '50'), ('3', '50')]\n",
    "#['50', '1', '3']\n",
    "pairs =[\n",
    "    (\"B\",\"A\"),\n",
    "    (\"B\",\"C\"),\n",
    "    (\"C\",\"A\"),\n",
    "]\n",
    "test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'D')\n",
      "\t('B', 'C')\n",
      "\t('D', 'B')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "SHIFT   : Push B     || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "R ARC   : B<-C       || STACK : root|A|B|C\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "REDUCE  : Pop  C     || STACK : root|A|B\n",
      "L ARC   : B->D       || STACK : root|A\n",
      "L ARC   : A->D       || STACK : root\n",
      "SKIP    : item D     || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "SKIP    : item E     || STACK : root\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "SKIP    : item F     || STACK : root\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('A', 'D')\n",
      "\t('B', 'C')\n",
      "\t('D', 'B')\n",
      "DEPS Pred\n",
      "\t('A', 'D')\n",
      "\t('B', 'D')\n",
      "\t('C', 'B')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tSHIFT   : Push B\n",
      "\tR ARC   : B<-C\n",
      "\tREDUCE  : Pop  C\n",
      "\tL ARC   : B->D\n",
      "\tL ARC   : A->D\n",
      "\tSKIP    : item D\n",
      "\tSKIP    : item E\n",
      "\tSKIP    : item F\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs =[\n",
    "    (\"A\",\"D\"),\n",
    "    (\"D\",\"B\"),\n",
    "    (\"B\",\"C\"),\n",
    "]\n",
    "test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Projective Parse Should Fail Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('A', 'C')\n",
      "\t('B', 'E')\n",
      "\n",
      "-------------------------------------\n",
      "A\n",
      "-------------------------------------\n",
      "SHIFT   : Push A     || STACK : root|A\n",
      "-------------------------------------\n",
      "B\n",
      "-------------------------------------\n",
      "SHIFT   : Push B     || STACK : root|A|B\n",
      "-------------------------------------\n",
      "C\n",
      "-------------------------------------\n",
      "REDUCE  : Pop  B     || STACK : root|A\n",
      "L ARC   : A->C       || STACK : root\n",
      "SKIP    : item C     || STACK : root\n",
      "-------------------------------------\n",
      "D\n",
      "-------------------------------------\n",
      "SKIP    : item D     || STACK : root\n",
      "-------------------------------------\n",
      "E\n",
      "-------------------------------------\n",
      "SHIFT   : Push E     || STACK : root|E\n",
      "-------------------------------------\n",
      "F\n",
      "-------------------------------------\n",
      "SKIP    : item F     || STACK : root|E\n",
      "\n",
      "*************************************\n",
      "Stack\n",
      "\troot|E\n",
      "DEPS Actual\n",
      "\t('A', 'C')\n",
      "\t('B', 'E')\n",
      "DEPS Pred\n",
      "\t('A', 'C')\n",
      "Actions\n",
      "\tSHIFT   : Push A\n",
      "\tSHIFT   : Push B\n",
      "\tREDUCE  : Pop  B\n",
      "\tL ARC   : A->C\n",
      "\tSKIP    : item C\n",
      "\tSKIP    : item D\n",
      "\tSHIFT   : Push E\n",
      "\tSKIP    : item F\n",
      "\n",
      "Ordered Match?    False\n",
      "Un Ordered Match? False\n",
      "{('B', 'E')}\n"
     ]
    }
   ],
   "source": [
    "pairs =[\n",
    "    (\"A\",\"C\"),\n",
    "    (\"B\",\"E\"),\n",
    "]\n",
    "try:\n",
    "    success = test_oracle(\"ABCDEF\", pairs, Oracle, verbose=True)\n",
    "except Exception as e:\n",
    "    success = False\n",
    "    raise e\n",
    "assert success == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on Real Causal Relations (Limit to 2 or More Relations in a Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_cr(cr):\n",
    "    return tuple(cr.replace(\"Causer:\",\"\").replace(\"Result:\",\"\").split(\"->\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('14', '50')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_cr('Causer:14->Result:50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "training_pickled = \"/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "#TODO - don't ignore Anaphor, other and rhetoricals here\n",
    "cr_tags = list((t for t in tag_freq.keys() if ( \"->\" in t) and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8292, 2217, 86, 141)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "relations = []\n",
    "unq_cr_tags = set(cr_tags)\n",
    "skipped_sent = 0\n",
    "skipped_crels = 0\n",
    "num_sents = 0\n",
    "for essay_ix, essay in enumerate(tagged_essays):\n",
    "    for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "        num_sents += 1\n",
    "        tag_seq = []\n",
    "        un_tags = set()\n",
    "        crel2tags = defaultdict(set)\n",
    "        def add_tag(tag, crel):\n",
    "            if tag not in un_tags:\n",
    "                tag_seq.append(tag)\n",
    "                un_tags.add(tag)\n",
    "            crel2tags[crel].add(tag)\n",
    "        \n",
    "        has_causal = False\n",
    "        for i, (wd,tags) in enumerate(taggged_sentence):\n",
    "            csl = unq_cr_tags.intersection(tags)\n",
    "            if not csl:\n",
    "                continue\n",
    "            has_causal = True\n",
    "            for crel in csl:\n",
    "                l_causer, r_effect = crel.split(\"->\")\n",
    "                l,r = normalize_cr(crel)\n",
    "                if l_causer in tags:\n",
    "                    add_tag(l, crel)\n",
    "                if r_effect in tags:\n",
    "                    add_tag(r, crel)                \n",
    "                if l in tags:\n",
    "                    add_tag(l, crel)\n",
    "                if r in tags:\n",
    "                    add_tag(r, crel)\n",
    "        \n",
    "        # Don't count sentences without any relations as skipped\n",
    "        if not has_causal:\n",
    "            continue\n",
    "        \n",
    "        supported_causal = set()\n",
    "        supported_codes = set()\n",
    "        for crel, tags in crel2tags.items():\n",
    "            if len(tags) < 2:\n",
    "                skipped_crels += 1\n",
    "                continue\n",
    "            supported_causal.add(crel)\n",
    "            supported_codes.update(tags)\n",
    "        \n",
    "        if not supported_causal:\n",
    "            skipped_sent += 1\n",
    "            continue\n",
    "        # filter out any tags that were only part of unsupported causal relations\n",
    "        tag_seq = [tag for tag in tag_seq if tag in supported_codes]\n",
    "        relations.append((supported_causal,tag_seq))\n",
    "        \n",
    "num_sents, len(relations), skipped_sent, skipped_crels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Errors Below Look Are from Non-Projective Parses\n",
    "**NOTES**\n",
    "With only 4 errors as 4 missed relations, hardly worth worrying about. \n",
    "One solution would be to train a forward and a backward parser, parse the sentence in both directions and merge the deps. In each case that would pick up all deps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for relations:\n",
      "[('1', '50'), ('1', '7'), ('3', '50'), ('3', '7')]\n",
      "['1', '3', '50', '7']\n",
      "Error for relations:\n",
      "[('1', '4'), ('1', '50'), ('3', '4'), ('3', '50')]\n",
      "['1', '3', '4', '50']\n",
      "Error for relations:\n",
      "[('13', '6'), ('13', '7'), ('3', '6'), ('3', '7'), ('7', '50')]\n",
      "['6', '3', '13', '7', '50']\n",
      "Error for relations:\n",
      "[('12', '11'), ('13', '11'), ('13', '14')]\n",
      "['12', '13', '11', '14']\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "exs = []\n",
    "for supported_causal, tag_seq in relations[:]:\n",
    "    supported_causal = sorted(supported_causal)\n",
    "    crels = [normalize_cr(crel) for crel in supported_causal]\n",
    "\n",
    "    try:\n",
    "        success = test_oracle(tag_seq, crels, Oracle, verbose=False)\n",
    "    except Exception as e:\n",
    "        exs.append(e)\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        errors += 1\n",
    "        print(\"Error for relations:\")\n",
    "        pprint(crels)\n",
    "        pprint(tag_seq)\n",
    "        #print()\n",
    "        #success = test_oracle(tag_seq, crels, Oracle, verbose=True)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">NEED to determine if all errors are non-projective<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a New Oracle That Can be Consulted Without Acting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "SHIFT = \"Shift\"\n",
    "REDUCE = \"Reduce\"\n",
    "LARC = \"LArc\"\n",
    "RARC = \"Rarc\"\n",
    "SKIP = \"Skip\"\n",
    "\n",
    "class Oracle2(object):\n",
    "    \n",
    "    def __init__(self, crels, parser):\n",
    "        self.parser = parser\n",
    "        self.crels = norm_arcs(crels)\n",
    "        self.mapping = self.build_mappings(crels)\n",
    "    \n",
    "    def build_mappings(self, pairs):\n",
    "        mapping = defaultdict(set)\n",
    "        for c,res in pairs:\n",
    "            mapping[c].add(res)\n",
    "            mapping[res].add(c)\n",
    "        return mapping\n",
    "\n",
    "    def should_continue(self, action):\n",
    "        # continue parsing if REDUCE or LARC\n",
    "        return action in (REDUCE,LARC)\n",
    "    \n",
    "    def remove_relation(self, a,b):\n",
    "        self.mapping[a].remove(b)\n",
    "        if len(self.mapping[a]) == 0:\n",
    "            del self.mapping[a]\n",
    "        self.mapping[b].remove(a)\n",
    "        if len(self.mapping[b]) == 0:\n",
    "            del self.mapping[b]\n",
    "    \n",
    "    def consult(self, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        parser = self.parser\n",
    "        a,b = norm_arc((tos, buffer))\n",
    "        if (a,b) in self.crels:\n",
    "            # TOS has arcs remaining? If so, we need RARC, else LARC\n",
    "            if len(self.mapping[tos]) == 1:\n",
    "                return LARC\n",
    "            else:\n",
    "                return RARC\n",
    "        else:\n",
    "            if buffer not in self.mapping:\n",
    "                return SKIP\n",
    "            # If the buffer has relations further down in the stack, we need to POP the TOS\n",
    "            for item in self.mapping[buffer]:\n",
    "                if item == tos:\n",
    "                    continue\n",
    "                if parser.in_stack(item):\n",
    "                    return REDUCE\n",
    "            #end for\n",
    "            #ELSE\n",
    "            return SHIFT\n",
    "        \n",
    "    def execute(self, action, tos, buffer):\n",
    "        \"\"\"\n",
    "        Performs optimal decision for parser\n",
    "        If true, continue processing, else Consume Buffer\n",
    "        \"\"\"\n",
    "        parser = self.parser\n",
    "        if action == LARC:\n",
    "            parser.left_arc(buffer)\n",
    "            self.remove_relation(tos, buffer)\n",
    "        elif action == RARC:\n",
    "            parser.right_arc(buffer)\n",
    "            self.remove_relation(tos, buffer)\n",
    "        elif action == REDUCE:\n",
    "            parser.reduce()\n",
    "        elif action == SHIFT:\n",
    "            parser.shift(buffer)\n",
    "        elif action == SKIP:\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(\"Unknown parsing action %s\" % action)\n",
    "        return self.should_continue(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def test_oracle2(codes, crels, orcl_fact, verbose=False):\n",
    "    \n",
    "    crels = set(crels)\n",
    "    if verbose:\n",
    "        prn_fun = lambda s=\"\": print(s)\n",
    "    else:\n",
    "        prn_fun = lambda s=\"\": None\n",
    "    \n",
    "    stack = Stack(False)\n",
    "    stack.push(ROOT)\n",
    "    parser = Parser(stack)\n",
    "    oracle = orcl_fact(crels, parser)\n",
    "\n",
    "    prn_fun(\"DEPS\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun()\n",
    "\n",
    "    PAD = 20\n",
    "    LINE = PAD + len(ROOT) + 2 * len(codes) + 1\n",
    "\n",
    "    for buffer in codes:\n",
    "        prn_fun(\"-\" * LINE)\n",
    "        prn_fun(buffer)\n",
    "        prn_fun(\"-\" * LINE)\n",
    "\n",
    "        while True:\n",
    "            tos = stack.tos()\n",
    "            action = oracle.consult(tos, buffer)\n",
    "            if not oracle.execute(action, tos, buffer):\n",
    "                prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "                break\n",
    "\n",
    "            prn_fun(parser.actions[-1].ljust(PAD) + \" || STACK : \" + str(stack))\n",
    "            if stack.len() == 0:\n",
    "                prn_fun(\"Empty stack, stopping\")\n",
    "                break\n",
    "\n",
    "    prn_fun()\n",
    "    prn_fun(\"*\" * LINE)\n",
    "    prn_fun(\"Stack\")\n",
    "    prn_fun(\"\\t\" + str(stack))\n",
    "    deps = parser.get_dependencies()\n",
    "    prn_fun(\"DEPS Actual\")\n",
    "    for crel in sorted(crels):\n",
    "        prn_fun(\"\\t\" + str(crel))\n",
    "    prn_fun(\"DEPS Pred\")\n",
    "    for dep in sorted(deps):\n",
    "        prn_fun(\"\\t\" + str(dep))\n",
    "    prn_fun(\"Actions\")\n",
    "    for a in parser.actions:\n",
    "        prn_fun(\"\\t\" + a)\n",
    "    prn_fun()\n",
    "    prn_fun(\"Ordered Match?    \" + str(set(deps) == crels))\n",
    "\n",
    "    ndeps = norm_arcs(deps)\n",
    "    ncrels = norm_arcs(crels)\n",
    "    diff = (ndeps - ncrels).union(ncrels - ndeps)\n",
    "    success = (len(diff) == 0)\n",
    "    prn_fun(\"Un Ordered Match? \" + str(success))\n",
    "    if diff:\n",
    "        prn_fun(diff)\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPS\n",
      "\t('5', '50')\n",
      "\n",
      "-----------------------------\n",
      "5\n",
      "-----------------------------\n",
      "SHIFT   : Push 5     || STACK : root|5\n",
      "-----------------------------\n",
      "50\n",
      "-----------------------------\n",
      "L ARC   : 5->50      || STACK : root\n",
      "L ARC   : 5->50      || STACK : root\n",
      "\n",
      "*****************************\n",
      "Stack\n",
      "\troot\n",
      "DEPS Actual\n",
      "\t('5', '50')\n",
      "DEPS Pred\n",
      "\t('5', '50')\n",
      "Actions\n",
      "\tSHIFT   : Push 5\n",
      "\tL ARC   : 5->50\n",
      "\n",
      "Ordered Match?    True\n",
      "Un Ordered Match? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_oracle2(['5', '50'], [('5', '50')], Oracle2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for relations:\n",
      "[('1', '50'), ('1', '7'), ('3', '50'), ('3', '7')]\n",
      "['1', '3', '50', '7']\n",
      "Error for relations:\n",
      "[('1', '4'), ('1', '50'), ('3', '4'), ('3', '50')]\n",
      "['1', '3', '4', '50']\n",
      "Error for relations:\n",
      "[('13', '6'), ('13', '7'), ('3', '6'), ('3', '7'), ('7', '50')]\n",
      "['6', '3', '13', '7', '50']\n",
      "Error for relations:\n",
      "[('12', '11'), ('13', '11'), ('13', '14')]\n",
      "['12', '13', '11', '14']\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "exs = []\n",
    "for supported_causal, tag_seq in relations[:]:\n",
    "    supported_causal = sorted(supported_causal)\n",
    "    crels = [normalize_cr(crel) for crel in supported_causal]\n",
    "\n",
    "    try:\n",
    "        success = test_oracle2(tag_seq, crels, Oracle2, verbose=False)\n",
    "    except Exception as e:\n",
    "        exs.append(e)\n",
    "        success = False\n",
    "        \n",
    "    if not success:\n",
    "        errors += 1\n",
    "        print(\"Error for relations:\")\n",
    "        pprint(crels)\n",
    "        pprint(tag_seq)\n",
    "        #print()\n",
    "        #success = test_oracle(tag_seq, crels, Oracle, verbose=True)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
