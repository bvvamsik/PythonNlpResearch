{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params\n",
    "ROOT_FOLDER = \"/Users/simon.hughes/Google Drive/PhD/Data/CoralBleaching/PhraseExtractionAnalysis\"\n",
    "\n",
    "DOCS_FOLDER = \"%s/ProcessedDocs\" % ROOT_FOLDER\n",
    "FILE_MASK = \".*\\.txt\"\n",
    "\n",
    "MIN_DOC_FREQ = 10\n",
    "MAX_PHRASE_LEN = 10\n",
    "STOP_WORDS_FILE = \"%s/en_stop_words.txt\" % ROOT_FOLDER\n",
    "PHRASES_FILE    = \"%s/Phrases.txt\" % ROOT_FOLDER\n",
    "PHRASE_FREQ_FILE = \"%s/phrase_freq.txt\" % ROOT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_files(folder, regex, remove_empty = False):\n",
    "    \"\"\"\n",
    "    Find all files matching the [regex] pattern in [folder]\n",
    "\n",
    "    folder  :   string\n",
    "                    folder to search (not recursive)\n",
    "    regex   :   string (NOT regex object)\n",
    "                    pattern to match\n",
    "    \"\"\"\n",
    "    files = os.listdir(folder)\n",
    "    matches = [os.path.abspath(os.path.join(folder, f))\n",
    "               for f in files\n",
    "               if re.search(regex, f, re.IGNORECASE)]\n",
    "\n",
    "    if remove_empty:\n",
    "        matches = [f for f in matches if os.path.getsize(f) > 0]\n",
    "    matches.sort()\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093 files found in /Users/simon.hughes/Google Drive/PhD/Data/CoralBleaching/PhraseExtractionAnalysis/ProcessedDocs\n",
      "Loading 1093 documents took 0.548434972763 seconds\n"
     ]
    }
   ],
   "source": [
    "import os, re, time\n",
    "start = time.time()\n",
    "\n",
    "files = find_files(DOCS_FOLDER, FILE_MASK, True)\n",
    "print(\"%s files found in %s\" % (len(files), DOCS_FOLDER))\n",
    "documents = []\n",
    "for i, fname in enumerate(files):\n",
    "    with open(fname) as f:\n",
    "        contents = f.read()\n",
    "        documents.append(contents.split(\"\\n\"))\n",
    "end = time.time()\n",
    "print(\"Loading %i documents took %s seconds\" % (len(files), str(end - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Documents Into a List of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1093, 10112, 10112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IterableFP import flatten\n",
    "flattened = flatten(documents)\n",
    "len(documents), sum(map(len,documents)), len(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write into a Single File to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_file = ROOT_FOLDER + \"/merged_documents.txt\"\n",
    "with open(merged_file, \"w+\") as f:\n",
    "    for sent in flattened:\n",
    "        f.write(\"{sent}\\n\".format(sent=sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Skipgram model\n",
    "model = fasttext.skipgram(merged_file, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bucket',\n",
       " 'cosine_similarity',\n",
       " 'dim',\n",
       " 'encoding',\n",
       " 'epoch',\n",
       " 'loss_name',\n",
       " 'lr_update_rate',\n",
       " 'maxn',\n",
       " 'min_count',\n",
       " 'minn',\n",
       " 'model_name',\n",
       " 'neg',\n",
       " 't',\n",
       " 'word_ngrams',\n",
       " 'words',\n",
       " 'ws']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[att for att in dir(model) if att[0] != \"_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['secondly',\n",
       " 'all',\n",
       " 'surrounded',\n",
       " 'customary',\n",
       " 'skeleton',\n",
       " 'chain',\n",
       " 'zooxantheallae',\n",
       " 'caused',\n",
       " 'lack',\n",
       " 'results']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(str,model.words))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"u'zooxantheallae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zooxanthelle', 100)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sorted(map(str,model.words))\n",
    "vectors = [ model[wd] for wd in words]\n",
    "words[-1], len(vectors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 100)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_unit(vec):\n",
    "    a = np.asarray(vec)\n",
    "    norm = np.linalg.norm(a)\n",
    "    return a / norm\n",
    "\n",
    "unit_vects = [to_unit(v) for v in vectors]\n",
    "npvects = np.asarray(unit_vects)\n",
    "npvects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_mat = np.dot(npvects, npvects.T)\n",
    "sort = np.argsort(sim_mat, 1)\n",
    "npwords = np.asarray(words)\n",
    "\n",
    "def sim_oov(word, n):\n",
    "    print(\"OOV: \" + word)\n",
    "    vect = to_unit(np.asarray(model[word]))\n",
    "    sims = np.asarray([np.dot(vect, v) for v in npvects])\n",
    "    sort = np.argsort(sims)\n",
    "    best_ixs = sort[::-1][:n]\n",
    "    return zip(list(npwords[best_ixs]), sims[best_ixs])\n",
    "\n",
    "def sim(word, n):\n",
    "    found = False\n",
    "    for ix, wd in enumerate(words):\n",
    "        if wd == word:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        return sim_oov(word, n)\n",
    "    \n",
    "    best_ixs = sort[ix][::-1][1:1+n]\n",
    "    sims = []\n",
    "    for bix in best_ixs:\n",
    "        sims.append(sim_mat[ix, bix])\n",
    "    return zip(list(npwords[best_ixs]), sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['begins',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dioxide', 0.98619950633326869),\n",
       " ('h2o', 0.96418850774736065),\n",
       " ('h20', 0.93600624330409432),\n",
       " ('combine', 0.92501390725069399),\n",
       " ('sunlight', 0.92361746602342687),\n",
       " ('o2', 0.91614789155348852),\n",
       " ('co2', 0.91537846575742943),\n",
       " ('uses', 0.89975905284668867),\n",
       " ('perform', 0.89127001041832687),\n",
       " ('sun', 0.88131955612913482),\n",
       " ('oxygen', 0.87667874229120557),\n",
       " ('energy', 0.87654803077455057),\n",
       " ('undergo', 0.87645247346046096),\n",
       " ('forms', 0.87040642972755777),\n",
       " ('glucose', 0.85853073001284541)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(\"carbon\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV: CO2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('carbon', 0.13456267074009276),\n",
       " ('dioxide', 0.1331747726512979),\n",
       " ('combine', 0.11780791362204424),\n",
       " ('region', 0.1159234558747855),\n",
       " ('increases', 0.10892794568463748),\n",
       " ('co2', 0.10845458176318787),\n",
       " ('normal', 0.10821249078154474),\n",
       " ('uses', 0.10746493251727182),\n",
       " ('combination', 0.10497513351146462),\n",
       " ('decreases', 0.10124439334279565),\n",
       " ('h2o', 0.10029915998011496),\n",
       " ('sugars', 0.10004220878036442),\n",
       " ('information', 0.099676239341521686),\n",
       " ('formation', 0.099559469696993405),\n",
       " ('f', 0.095265474336958228)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(\"CO2\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('building', 0.8777039612138563),\n",
       " ('reefs', 0.83572360524295131),\n",
       " ('85o', 0.81726598841211051),\n",
       " ('sensitive', 0.81512361039371029),\n",
       " ('receive', 0.81279670545082605),\n",
       " ('85f', 0.80730541539214118),\n",
       " ('85of', 0.80297436802084809),\n",
       " ('00', 0.80037764887466178),\n",
       " ('need', 0.79395965516832434),\n",
       " ('reefbase', 0.78395979147477257),\n",
       " ('degrees', 0.7772631882226595),\n",
       " ('process', 0.76893028551598241),\n",
       " ('degree', 0.7669855115819828),\n",
       " ('recieve', 0.76680169161120881),\n",
       " ('work', 0.75328544035764622)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(\"reef\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turns', 0.991513863250301),\n",
       " ('turn', 0.96825131707259848),\n",
       " ('turning', 0.91270043611615925),\n",
       " ('leaves', 0.89751763502791682),\n",
       " ('bleach', 0.89398285270311129),\n",
       " ('due', 0.8939353581564583),\n",
       " ('bleached', 0.8919246513078517),\n",
       " ('begin', 0.8914034486879544),\n",
       " ('dies', 0.88919053746041932),\n",
       " ('die', 0.88137499947020959),\n",
       " ('leave', 0.88048577449405563),\n",
       " ('turned', 0.87790464345089358),\n",
       " ('death', 0.87499876747401273),\n",
       " ('loose', 0.87462611749150787),\n",
       " ('dead', 0.87156491447809825)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(\"white\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
