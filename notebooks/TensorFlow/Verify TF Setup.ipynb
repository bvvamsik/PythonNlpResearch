{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Verify Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/anaconda3/envs/tensorflow_gpu/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CuDNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#see https://www.tensorflow.org/versions/r0.11/get_started/os_setup#prepare_environment_for_mac_os_x\n",
    "$ sudo mv include/cudnn.h /Developer/NVIDIA/CUDA-8.0/include/\n",
    "$ sudo mv lib/libcudnn* /Developer/NVIDIA/CUDA-8.0/lib\n",
    "$ sudo ln -s /Developer/NVIDIA/CUDA-8.0/lib/libcudnn* /usr/local/cuda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Developer/NVIDIA/CUDA-8.0/samples/bin/x86_64/darwin/release/deviceQuery Starting...\n",
      "\n",
      " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"GeForce GT 750M\"\n",
      "  CUDA Driver Version / Runtime Version          8.0 / 8.0\n",
      "  CUDA Capability Major/Minor version number:    3.0\n",
      "  Total amount of global memory:                 2048 MBytes (2147024896 bytes)\n",
      "  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores\n",
      "  GPU Max Clock rate:                            926 MHz (0.93 GHz)\n",
      "  Memory Clock rate:                             2508 Mhz\n",
      "  Memory Bus Width:                              128-bit\n",
      "  L2 Cache Size:                                 262144 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total number of registers available per block: 65536\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per multiprocessor:  2048\n",
      "  Maximum number of threads per block:           1024\n",
      "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n",
      "  Run time limit on kernels:                     Yes\n",
      "  Integrated GPU sharing Host Memory:            No\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support:                        Disabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n",
      "  Compute Mode:\n",
      "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 750M\n",
      "Result = PASS\n"
     ]
    }
   ],
   "source": [
    "#To get details about NVidia setup (from compiled samples):\n",
    "!/Developer/NVIDIA/CUDA-8.0/samples/bin/x86_64/darwin/release/deviceQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Segfaults on Mac OSX When Running It with the GPU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Python 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 20:51:01)\n",
    "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> import tensorflow\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.8.0.dylib locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.5.dylib locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.8.0.dylib locally\n",
    "Segmentation fault: 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fix is Below - Missing A Required Library File"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TO get it working on the GPU, had to do this\n",
    "> ln -s /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib\n",
    "See https://github.com/tensorflow/tensorflow/issues/3263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/anaconda3/envs/tensorflow_gpu/bin/python\n",
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "#this will verify GPU device useage.need to run from interpreter and not jupyter\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <span style=\"color:green\">Seems to work</span>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
