{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mcb\u001b[m\u001b[m \u001b[1m\u001b[36msc\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"/Users/simon.hughes/data/tensorflow/syntaxnet/tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_folder = \"Training\"\n",
    "#target_folder = \"Test\"\n",
    "\n",
    "# From (essay text) and To Files for the seq2seq model\n",
    "training_file           = \"/Users/simon.hughes/data/tensorflow/syntaxnet/tagger/cb/training.cnll\"\n",
    "tuning_file             = \"/Users/simon.hughes/data/tensorflow/syntaxnet/tagger/cb/tuning.cnll\"\n",
    "test_file               = \"/Users/simon.hughes/data/tensorflow/syntaxnet/tagger/cb/test.cnll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "(902, 'files found')\n",
      "902 essays processed\n",
      "(226, 'files found')\n",
      "226 essays processed\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + target_folder + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "essays = load_bratt_essays(training_folder)\n",
    "test_essays = load_bratt_essays(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def process_essays(essays):\n",
    "    sentences, sent_tags = [], []\n",
    "    wd_freq, tag_freq = defaultdict(int), defaultdict(int)\n",
    "    for essay_ix, essay in enumerate(essays):\n",
    "        for sent_ix, taggged_sentence in enumerate(essay.tagged_sentences):\n",
    "            t_sentence = []\n",
    "            sentences.append(t_sentence)\n",
    "            t_tag_seq = []\n",
    "            sent_tags.append(t_tag_seq)\n",
    "            for word_ix, (wd, t) in enumerate(taggged_sentence):\n",
    "                t_sentence.append(wd)\n",
    "                t_tag_seq.append(t)\n",
    "                wd_freq[wd]+=1\n",
    "                for tag in t:\n",
    "                    tag_freq[tag] +=1\n",
    "    return sentences, sent_tags, wd_freq, tag_freq\n",
    "sentences, sent_tags, wd_freq, tag_freq = process_essays(essays)\n",
    "test_sentences, test_tags, _, _ = process_essays(test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '11', '12', '13', '14', '2', '3', '4', '5', '50', '5b', '6', '7'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_tags = set((t for t in tag_freq.keys() if t[0].isdigit()))\n",
    "regular_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_reg_tags(sent_tags):\n",
    "    regular_tag_seq = []\n",
    "    for tag_seq in sent_tags:\n",
    "        r_tag_seq = []\n",
    "        regular_tag_seq.append(r_tag_seq)\n",
    "        # for each set of tags in sent\n",
    "        for tag_set in tag_seq:\n",
    "            tag_set = set((t for t in tag_set if t in regular_tags))\n",
    "            r_tag_seq.append(tag_set)\n",
    "    return regular_tag_seq\n",
    "regular_tag_seq = to_reg_tags(sent_tags)\n",
    "test_regular_tag_seq = to_reg_tags(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_most_freq_tags(regular_tag_seq):\n",
    "    most_freq_tags = []\n",
    "    None_Tag = \"None\"\n",
    "    # for each sentence\n",
    "    for tag_seq in regular_tag_seq:\n",
    "        most_freq = []\n",
    "        most_freq_tags.append(most_freq)\n",
    "        # for each set of tags in sent\n",
    "        for tag_set in tag_seq:\n",
    "            tag_set = set((t for t in tag_set if t in regular_tags))\n",
    "            if len(tag_set) == 0:\n",
    "                most_freq.append(None_Tag)\n",
    "            else:\n",
    "                tag = max(tag_set, key = lambda t:tag_freq[t])\n",
    "                most_freq.append(tag)\n",
    "    return most_freq_tags\n",
    "\n",
    "most_freq_tags = to_most_freq_tags(regular_tag_seq)\n",
    "test_most_freq_tags = to_most_freq_tags(test_regular_tag_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8292, 8292, 8292)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(most_freq_tags), len(regular_tag_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ix, (sent, tags, mfreq_tags) in enumerate(zip(sentences, most_freq_tags, regular_tag_seq)):\n",
    "    assert len(sent) == len(tags) == len(mfreq_tags), \"Lengths differ at %i\" % ix\n",
    "for ix, (sent, tags, mfreq_tags) in enumerate(zip(test_sentences, test_most_freq_tags, test_regular_tag_seq)):\n",
    "    assert len(sent) == len(tags) == len(mfreq_tags), \"Lengths differ at %i\" % ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(fname, sentences, tags):\n",
    "    with open(fname, \"w+\") as f:\n",
    "        for sent, tag_seq in zip(sentences,tags):\n",
    "            i = 1\n",
    "            for wd, t in zip(sent, tag_seq):\n",
    "                if not t:\n",
    "                    tag = \"None\"\n",
    "                else:\n",
    "                    tag = \"Code_\" + t\n",
    "                #tag = \"NOUN\"\n",
    "                # see here for CONLL format (needs at least 8 tab sep cols), hyphen for unknown\n",
    "                #    http://ufal.mff.cuni.cz/conll2009-st/task-description.html\n",
    "                # see here for explanation of coarse and fine tags: \n",
    "                #    http://mwetoolkit.sourceforge.net/PHITE.php?sitesig=MWE&page=MWE_070_File_types&subpage=MWE_010_CONLL\n",
    "                # Column 4 below is coarse POS tag, column 5 is fine grained\n",
    "                f.write(\"{id}\\t{word}\\t{dash}\\t{dash}\\t{pos}\\t{dash}\\t{dash}\\t{dash}\\t{dash}\\t{dash}\\n\".\\\n",
    "                        format(id=i, word=wd, dash=\"_\", pos=tag))\n",
    "                i+=1\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "num_test = int(0.2 * len(sentences))\n",
    "num_train = len(sentences) - num_test\n",
    "train_sent, test_sent = sentences[:num_train], sentences[num_train:]\n",
    "train_sent, test_sent = sentences[:num_train], sentences[num_train:]\n",
    "train_tags, test_tags = most_freq_tags[:num_train], most_freq_tags[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_to_file(training_file, train_sent, train_tags)\n",
    "write_to_file(tuning_file,   test_sent,  test_tags)\n",
    "write_to_file(test_file,     test_sentences, test_most_freq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
